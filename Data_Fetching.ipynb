{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "import urllib, urllib.request\n",
    "import mysql.connector\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'total': 21,\n 'offset': 0,\n 'next': 10,\n 'data': [{'paperId': 'fc95099a18816f9b79e202154f6073aba780b711',\n   'title': 'Integrating e-commerce and data mining: architecture and challenges'},\n  {'paperId': '7a0f291e2ea475e5c0dfd1497549e8dbba81c577',\n   'title': 'Integrating E-Commerce & Data Mining Architecture Challenges'},\n  {'paperId': '0f494865fdc6cf6d1b4a8bdfd8ee40e07642f6a8',\n   'title': 'E-Commerce and Data Mining: Architecture and Challenges'},\n  {'paperId': '0789c1934194a2abf9cfe5d6d603b1190b648dee',\n   'title': 'Knowledge Management in E-commerce: A Data Mining Perspective'},\n  {'paperId': 'd3f1edc86326306bd4b46565acc6dcd8e596dd25',\n   'title': 'Void Mark E-Commerce Application'},\n  {'paperId': '1cc8410934c27733a2119c378e98b46551a69d9d',\n   'title': 'Big Data Mining: A Comprehensive Analysis'},\n  {'paperId': '7b51e757b388f0261066ba676f41a878040bfd55',\n   'title': 'A Study of Various Varieties of Distributed Data Mining Architectures'},\n  {'paperId': '0428dc9c0fcd61dca17c3b4b522cf6f80327d63f',\n   'title': 'Web Data Mining and Applications in Business Intelligence and Counter-Terrorism'},\n  {'paperId': '212c93a7f0dbba99c81d7687ae91f4643458e9f2',\n   'title': 'Managing and Mining Multimedia Databases'},\n  {'paperId': 'fad8f7125f1a380eac7ce8c64e7971b0ea36518c',\n   'title': 'Collaborative Commerce: Portals for Decision Support and Knowledge Management'}]}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get general data\n",
    "link = \"https://api.semanticscholar.org/graph/v1/paper/search?query=Integrating E Commerce and Data Mining: Architecture and Challenges\"\n",
    "headers = {\"x-api-key\": \"M7HSjQNeTfai6l7JUiDZB8XYc85BHnHt3R0NXSEd\"}\n",
    "response = requests.get(link, headers=headers)\n",
    "response.json()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paperId': '781ef2bbb48f9ce81f8cc949c3a8a55033e6ced8', 'url': 'https://www.semanticscholar.org/paper/781ef2bbb48f9ce81f8cc949c3a8a55033e6ced8', 'year': 2021, 'referenceCount': 0, 'citationCount': 112, 'publicationTypes': None, 'journal': {'name': 'Sociedade & Natureza'}, 'authors': [{'authorId': '144791575', 'name': 'R. Rosa'}, {'authorId': '40403988', 'name': 'Samuel do Carmo Lima'}, {'authorId': '134857638', 'name': 'W. Assunção'}]}\n"
     ]
    }
   ],
   "source": [
    "# Get Paper data\n",
    "paper_link = \"https://api.semanticscholar.org/graph/v1/paper/781ef2bbb48f9ce81f8cc949c3a8a55033e6ced8?fields=url,year,referenceCount,citationCount,publicationTypes,journal,authors\"\n",
    "response2 = requests.get(paper_link, headers=headers)\n",
    "print(response2.json())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'authorId': '10007273',\n 'url': 'https://www.semanticscholar.org/author/10007273'}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Author data\n",
    "author_link = \"https://api.semanticscholar.org/graph/v1/author/10007273?fields=url\"\n",
    "response3 = requests.get(author_link, headers=headers)\n",
    "response3.json()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fetch data with \"Artificial Intelligence\" as search query from 2018"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "YEAR_START = 2020\n",
    "YEAR_END = 2020\n",
    "STEP_SIZE = 100\n",
    "CATEGORY = \"cs.CV\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Establish database connection\n",
    "cnx = mysql.connector.connect(user='david', password='daviddung1993',\n",
    "                              host='127.0.0.1',\n",
    "                              database='computervision')\n",
    "cursor = cnx.cursor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def store_authors(author_infomration, paperID):\n",
    "    for author in author_infomration:\n",
    "        affiliations = \"\"\n",
    "        params = ()\n",
    "        if len(author.keys()) == 2:\n",
    "            params = (author[\"authorId\"], author[\"name\"], affiliations, None, None)\n",
    "        else:\n",
    "            if author[\"affiliations\"]:\n",
    "                affiliations = author[\"affiliations\"][0]\n",
    "            params = (author[\"authorId\"], author[\"name\"], affiliations, author[\"paperCount\"], author[\"hIndex\"])\n",
    "        insert_author = (\"INSERT INTO Authors VALUES (%s,%s,%s,%s,%s)\")\n",
    "        insert_authoredBy = (\"INSERT INTO authoredBy VALUES (%s,%s)\")\n",
    "        try:\n",
    "            cursor.execute(insert_author, params)\n",
    "        except mysql.connector.IntegrityError as err:\n",
    "            #print(\"Author exists already\")\n",
    "            pass\n",
    "        try:\n",
    "            cursor.execute(insert_authoredBy, (paperID, author[\"authorId\"]))\n",
    "        except mysql.connector.IntegrityError as err:\n",
    "            #print(\"AuthordByEntry exists already\")\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def store_paper(archive_url, paper_response, isLeaf):\n",
    "    isConference = False\n",
    "    isJournalArticle = False\n",
    "    isReview = False\n",
    "    journal = ''\n",
    "    if not paper_response['paperId']:\n",
    "        paper_response['paperId'] = '11111' + uuid.uuid4().hex\n",
    "    if paper_response[\"publicationTypes\"]:\n",
    "        if \"JournalArticle\" in paper_response[\"publicationTypes\"]:\n",
    "            isJournalArticle = True\n",
    "        if \"Conference\" in paper_response[\"publicationTypes\"]:\n",
    "            isConference = True\n",
    "        if \"Review\" in paper_response[\"publicationTypes\"]:\n",
    "            isReview = True\n",
    "    if paper_response[\"journal\"]:\n",
    "        if \"name\" in paper_response[\"journal\"]:\n",
    "            journal = paper_response[\"journal\"][\"name\"]\n",
    "    params = (paper_response['paperId'], paper_response['title'], archive_url, paper_response['year'], CATEGORY, isReview, isConference, isJournalArticle,paper_response['referenceCount'], paper_response['citationCount'], journal, isLeaf, paper_response['url'])\n",
    "    insert_paper = (\"INSERT INTO Papers VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\")\n",
    "    try:\n",
    "        cursor.execute(insert_paper, params)\n",
    "        return True\n",
    "    except mysql.connector.IntegrityError as err:\n",
    "        check_if_leaf = (\"SELECT Leaf FROM Papers WHERE PaperID = %s\")\n",
    "        cursor.execute(check_if_leaf, [paper_response['paperId']])\n",
    "        isLeafPaper = cursor.fetchone()[0]\n",
    "        if isLeafPaper == isLeaf:\n",
    "            return False\n",
    "        update_leaf = \"UPDATE Papers SET Leaf = %s WHERE PaperID = %s\"\n",
    "        cursor.execute(update_leaf, (isLeaf,paper_response['paperId']))\n",
    "    except Exception as err:\n",
    "        print(params)\n",
    "        print(err)\n",
    "        raise ValueError\n",
    "\n",
    "def store_reference(paperId, referenced_by):\n",
    "    try:\n",
    "        insert_reference = (\"INSERT INTO referencedBy VALUES (%s,%s,0)\")\n",
    "        cursor.execute(insert_reference, (paperId, referenced_by))\n",
    "    except mysql.connector.IntegrityError as err:\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "0/15321\n",
      "100/15321\n",
      "200/15321\n",
      "sleeping\n",
      "300/15321\n",
      "400/15321\n",
      "500/15321\n",
      "600/15321\n",
      "700/15321\n",
      "800/15321\n",
      "900/15321\n",
      "1000/15321\n",
      "sleeping\n",
      "1100/15321\n",
      "sleeping\n",
      "1200/15321\n",
      "1300/15321\n",
      "1400/15321\n",
      "1500/15321\n",
      "1600/15321\n",
      "1700/15321\n",
      "1800/15321\n",
      "1900/15321\n",
      "sleeping\n",
      "2000/15321\n",
      "2100/15321\n",
      "2200/15321\n",
      "sleeping\n",
      "2300/15321\n",
      "2400/15321\n",
      "2500/15321\n",
      "2600/15321\n",
      "2700/15321\n",
      "2800/15321\n",
      "2900/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "3000/15321\n",
      "3100/15321\n",
      "3200/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "3300/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "3400/15321\n",
      "3500/15321\n",
      "sleeping\n",
      "sleeping\n",
      "3600/15321\n",
      "3700/15321\n",
      "sleeping\n",
      "3800/15321\n",
      "sleeping\n",
      "sleeping\n",
      "3900/15321\n",
      "sleeping\n",
      "sleeping\n",
      "4000/15321\n",
      "4100/15321\n",
      "4200/15321\n",
      "4300/15321\n",
      "sleeping\n",
      "4400/15321\n",
      "4500/15321\n",
      "4600/15321\n",
      "4700/15321\n",
      "sleeping\n",
      "sleeping\n",
      "4800/15321\n",
      "4900/15321\n",
      "sleeping\n",
      "5000/15321\n",
      "sleeping\n",
      "sleeping\n",
      "5100/15321\n",
      "5200/15321\n",
      "sleeping\n",
      "sleeping\n",
      "5300/15321\n",
      "5400/15321\n",
      "sleeping\n",
      "5500/15321\n",
      "sleeping\n",
      "sleeping\n",
      "5600/15321\n",
      "5700/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "5800/15321\n",
      "sleeping\n",
      "5900/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "6000/15321\n",
      "6100/15321\n",
      "6200/15321\n",
      "sleeping\n",
      "6300/15321\n",
      "6400/15321\n",
      "6500/15321\n",
      "sleeping\n",
      "sleeping\n",
      "6600/15321\n",
      "sleeping\n",
      "6700/15321\n",
      "6800/15321\n",
      "sleeping\n",
      "6900/15321\n",
      "sleeping\n",
      "sleeping\n",
      "7000/15321\n",
      "sleeping\n",
      "7100/15321\n",
      "7200/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "7300/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "7400/15321\n",
      "7500/15321\n",
      "sleeping\n",
      "sleeping\n",
      "7600/15321\n",
      "7700/15321\n",
      "sleeping\n",
      "7800/15321\n",
      "7900/15321\n",
      "8000/15321\n",
      "sleeping\n",
      "8100/15321\n",
      "sleeping\n",
      "8200/15321\n",
      "sleeping\n",
      "sleeping\n",
      "8300/15321\n",
      "8400/15321\n",
      "8500/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "8600/15321\n",
      "8700/15321\n",
      "sleeping\n",
      "sleeping\n",
      "8800/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "8900/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "9000/15321\n",
      "sleeping\n",
      "9100/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "9200/15321\n",
      "9300/15321\n",
      "sleeping\n",
      "sleeping\n",
      "9400/15321\n",
      "9500/15321\n",
      "sleeping\n",
      "9600/15321\n",
      "9700/15321\n",
      "9800/15321\n",
      "sleeping\n",
      "sleeping\n",
      "9900/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "10000/15321\n",
      "10100/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "10200/15321\n",
      "10300/15321\n",
      "sleeping\n",
      "10400/15321\n",
      "10500/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "10600/15321\n",
      "10700/15321\n",
      "sleeping\n",
      "10800/15321\n",
      "10900/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "11000/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "11100/15321\n",
      "sleeping\n",
      "11200/15321\n",
      "11300/15321\n",
      "sleeping\n",
      "sleeping\n",
      "11400/15321\n",
      "sleeping\n",
      "sleeping\n",
      "11500/15321\n",
      "11600/15321\n",
      "11700/15321\n",
      "11800/15321\n",
      "11900/15321\n",
      "12000/15321\n",
      "sleeping\n",
      "12100/15321\n",
      "sleeping\n",
      "12200/15321\n",
      "12300/15321\n",
      "12400/15321\n",
      "12500/15321\n",
      "sleeping\n",
      "sleeping\n",
      "12600/15321\n",
      "12700/15321\n",
      "sleeping\n",
      "12800/15321\n",
      "sleeping\n",
      "12900/15321\n",
      "13000/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "13100/15321\n",
      "13200/15321\n",
      "13300/15321\n",
      "sleeping\n",
      "13400/15321\n",
      "13500/15321\n",
      "13600/15321\n",
      "sleeping\n",
      "sleeping\n",
      "13700/15321\n",
      "13800/15321\n",
      "sleeping\n",
      "sleeping\n",
      "13900/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "14000/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "14100/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "14200/15321\n",
      "sleeping\n",
      "14300/15321\n",
      "sleeping\n",
      "14400/15321\n",
      "14500/15321\n",
      "14600/15321\n",
      "14700/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "14800/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "14900/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "15000/15321\n",
      "sleeping\n",
      "sleeping\n",
      "15100/15321\n",
      "15200/15321\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "sleeping\n",
      "15300/15321\n"
     ]
    }
   ],
   "source": [
    "for i in range(YEAR_END - YEAR_START + 1):\n",
    "    year_temp = YEAR_START + i\n",
    "    print(year_temp)\n",
    "    current_index = 0\n",
    "    while True:\n",
    "        # Get title of all entries in a year from arxiv\n",
    "        try:\n",
    "            arxiv_query = f'https://export.arxiv.org/api/query?search_query=cat:cs.CV+AND+submittedDate:[{year_temp}01010630+TO+{year_temp}12311645]&sortBy=submittedDate&start={current_index}&max_results={STEP_SIZE}'\n",
    "            data = urllib.request.urlopen(arxiv_query)\n",
    "            data_xml = data.read().decode('utf-8')\n",
    "            data_dict = xmltodict.parse(data_xml)\n",
    "\n",
    "            total_entries = int(data_dict['feed']['opensearch:totalResults']['#text'])\n",
    "            entries = data_dict['feed']['entry']\n",
    "            print(f\"{current_index}/{total_entries}\")\n",
    "            current_index += STEP_SIZE\n",
    "            # Fetch information for papers from semantic scholar\n",
    "            for entry in entries:\n",
    "                start = time.time()\n",
    "                archive_link = entry[\"id\"]\n",
    "                entry_title = entry[\"title\"].replace(\"-\", \" \").replace(\"\\n\", \"\")\n",
    "                semantic_scholar_query = f\"https://api.semanticscholar.org/graph/v1/paper/search?query={entry_title}\"\n",
    "                response = requests.get(semantic_scholar_query, headers=headers).json()\n",
    "                if not response[\"total\"]:\n",
    "                    continue\n",
    "                else:\n",
    "                    # Store papers' information in database\n",
    "                    paperId = response[\"data\"][0][\"paperId\"]\n",
    "                    paper_url = f\"https://api.semanticscholar.org/graph/v1/paper/{paperId}?fields=url,year,referenceCount,citationCount,publicationTypes,journal,authors,title,references.url,references.title,references.year,references.referenceCount,references.citationCount,references.authors,references.journal,references.publicationTypes,authors.name,authors.affiliations,authors.paperCount,authors.hIndex\"\n",
    "                    paper_response = requests.get(paper_url, headers=headers).json()\n",
    "                    success = store_paper(archive_link, paper_response, False)\n",
    "                    if not success:\n",
    "                        continue\n",
    "                    store_authors(paper_response['authors'], paperId)\n",
    "                    # Store references' information in database\n",
    "                    for reference in paper_response[\"references\"]:\n",
    "                        store_paper(None, reference, True)\n",
    "                        store_reference(reference[\"paperId\"], paperId)\n",
    "                        if reference[\"authors\"]:\n",
    "                            #print(reference[\"authors\"])\n",
    "                            store_authors(reference[\"authors\"], reference[\"paperId\"])\n",
    "            cnx.commit()\n",
    "        except KeyError:\n",
    "            print(\"sleeping\")\n",
    "            time.sleep(3)\n",
    "        if current_index > total_entries:\n",
    "            break\n",
    "    clear_output(wait=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnx.commit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "cnx.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "add_employee = (\"SELECT p. FROM Papers p,referencedBy r, Papers p2 WHERE \")\n",
    "try:\n",
    "    cursor.execute(add_employee, [\"d8ed6678758f9200bd23fcf11dd733c8f4d9d71c\"])\n",
    "except mysql.connector.IntegrityError as err:\n",
    "    print(\"entry exists already\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchone()[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halo\n"
     ]
    }
   ],
   "source": [
    "print(\"halo\")\n",
    "clear_output(wait=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "x = None\n",
    "if x:\n",
    "    print(\"hallo\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
