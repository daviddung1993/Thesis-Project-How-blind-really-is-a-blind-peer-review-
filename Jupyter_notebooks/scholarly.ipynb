{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scholarly import scholarly, ProxyGenerator\n",
    "from fp.fp import FreeProxy\n",
    "import requests\n",
    "import mysql.connector\n",
    "import textdistance\n",
    "import time\n",
    "import random\n",
    "import xmltodict\n",
    "import urllib, urllib.request\n",
    "from webcrawler.researchgate import IeeeCrawler, ResearchGateCrawler, SpringerCrawler, PubMedCrawler\n",
    "import selenium as se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user='david', password='daviddung1993',\n",
    "                              host='127.0.0.1',\n",
    "                              database='computervision')\n",
    "cursor = cnx.cursor()\n",
    "headers = {\"x-api-key\": \"M7HSjQNeTfai6l7JUiDZB8XYc85BHnHt3R0NXSEd\"}\n",
    "#pg = ProxyGenerator()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "research_crawler = ResearchGateCrawler()\n",
    "springer_crawler = SpringerCrawler()\n",
    "pubmed_crawler = PubMedCrawler()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<selenium.webdriver.chrome.options.Options at 0x7f2fd93d2b60>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.webdriver.ChromeOptions()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doi = research_crawler.extract_doi(\"Bayesian semi-parametric ROC analysis\", \"Erkanli\")\n",
    "pubmed_crawler.make_request(doi)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'10.1002/sim.2496'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "done = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftPOSIT: Simultaneous Pose and Correspondence Determination\n",
      "A Spectral/Spatial CBIR System for Hyperspectral Images\n",
      "Improved FCM Algorithm for Clustering on Web Usage Mining\n",
      "Dimensionality in image analysis\n",
      "Appearance-Based Gaze Estimation Using Visual Saliency\n",
      "The Henstock Integral and the Black-Scholes Theory of Derivative Asset Pricing\n",
      "Cheap and Fast – But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks\n",
      "Globally Convergent Dual MAP LP Relaxation Solvers using Fenchel-Young Margins\n",
      "Ultrahigh Dimensional Feature Selection: Beyond The Linear Model\n",
      "A Secure Semi-fragile Watermarking Algorithm for Image Authentication in the Wavelet Domain of JPEG2000\n",
      "Clustering for edge-cost minimization (extended abstract)\n",
      "An Efficient Method for Gradient-Based Adaptation of Hyperparameters in SVM Models\n",
      "Retrieval of Images Using Mean-Shift and Gaussian Mixtures Based on Weighted Color Histograms\n",
      "Model-Based Event Detection in Wireless Sensor Networks\n",
      "View synthesis techniques for 3D video\n",
      "Mean Shift Segmentation - Evaluation of Optimization Techniques\n",
      "Population analysis of the cingulum bundle using the tubular surface model for schizophrenia detection\n",
      "Two-frame structure from motion using optical flow probability distributions for unmanned air vehicle obstacle avoidance\n",
      "NOSER: An algorithm for solving the inverse conductivity problem\n",
      "Facial Features for Template Matching Based Face Recognition\n",
      "Regularity for solutions of the total variation denoising problem\n",
      "Optimal Solutions for Sparse Principal Component Analysis\n",
      "A comparison of methods for non-rigid 3D shape retrieval\n",
      "A Phase Field Method for Joint Denoising, Edge Detection, and Motion Estimation in Image Sequence Processing\n",
      "Spectral Relaxation for K-means Clustering\n",
      "A probabilistic framework for semi-supervised clustering\n",
      "A new graph cut-based multiple active contour algorithm without initial contours and seed points\n",
      "Jacobi Angles for Simultaneous Diagonalization\n",
      "Prior Knowledge, Random Walks and Human Skeletal Muscle Segmentation\n",
      "Tree consistency and bounds on the performance of the max-product algorithm and its generalizations\n",
      "A swapping-based refinement of orthogonal matching pursuit strategies\n",
      "Adaptive image interpolation based on local gradient features\n",
      "Feature-based syntactic and metric shape recognition\n",
      "A Streaming Parallel Decision Tree Algorithm\n",
      "An algorithmic overview of surface registration techniques for medical imaging\n",
      "Reading Digits in Natural Images with Unsupervised Feature Learning\n",
      "Diagonal Based Feature Extraction for Handwritten Alphabets Recognition System using Neural Network\n",
      "Normalized Compression Distance of Multisets with Applications\n",
      "A simple segmentation approach for unconstrained cursive handwritten words in conjunction with neural network\n",
      "Optimal Structure from Motion: Local Ambiguities and Global Estimates\n",
      "Derivation and evaluation of improved tracking filter for use in dense multitarget environments\n",
      "Semi-coupled dictionary learning with applications to image super-resolution and photo-sketch synthesis\n",
      "Support Vector Machines for Texture Classification\n",
      "Face recognition based on Log-Gabor filter binary transformation\n",
      "Computer perception of curved objects using a television camera\n",
      "Computer Vision on Mars\n",
      "Activity Recognition from Call Detail Record: Relation Between Mobile Behavior Pattern and Social Attribute Using Hierarchical Conditional Random Fields\n",
      "Auto-SOM: Recursive Parameter Estimation for Guidance of Self-Organizing Feature Maps\n",
      "On MMSE Estimation: A Linear Model Under Gaussian Mixture Statistics\n",
      "Interior Gradient and Proximal Methods for Convex and Conic Optimization\n",
      "Local Directional Pattern (LDP) for face recognition\n",
      "Laplacian mesh optimization\n",
      "Artificial Ant Colonies in Digital Image Habitats - A Mass Behaviour Effect Study on Pattern Recognition\n",
      "Image reconstruction using symmetric convolution and discrete trigonometric transforms\n",
      "Explaining brightness illusions using spatial filtering and local response normalization\n",
      "Computer aided detection via asymmetric cascade of sparse hyperplane classifiers\n",
      "Multicanonical ensemble: A new approach to simulate first-order phase transitions.\n",
      "Efficient Selection of Disambiguating Actions for Stereo Vision\n",
      "The Molecular Biology of Memory Storage: A Dialogue Between Genes and Synapses\n",
      "Probabilistic Index Maps for Modeling Natural Signals\n",
      "Learning with Distance Substitution Kernels\n",
      "Solving Structured Sparsity Regularization with Proximal Methods\n",
      "SVM based ASM for facial landmarks location\n",
      "Finding trails\n",
      "A Kinect-based system for physical rehabilitation: a pilot study for young adults with motor disabilities.\n",
      "PyBrain\n",
      "Analysis of textual images using the Hough transform\n",
      "Rapid signer adaptation for continuous sign language recognition using a combined approach of eigenvoices, MLLR, and MAP\n",
      "Irrevocable Cryptographic Key Generation from Cancelable Fingerprint Templates: An Enhanced and Effective Scheme\n",
      "Cancer Statistics, 2007\n"
     ]
    }
   ],
   "source": [
    "done_file =  open(\"rg_done.txt\",\"r\")\n",
    "\n",
    "lines_done = done_file.readlines()\n",
    "for idx, line in enumerate(lines_done):\n",
    "    try:\n",
    "        if idx % 10 == 10:\n",
    "            print(idx)\n",
    "        manual =  open(\"manual.txt\",\"r+\")\n",
    "        title = line[:-1]\n",
    "        if title in done:\n",
    "            continue\n",
    "        print(title)\n",
    "        done.append(title)\n",
    "        cursor.execute(\"select distinct a.AuthorID, a.Name from Papers p,authoredBy b,Authors a where p.Title=%s and p.PaperID = b.PaperID and b.AuthoredByID not in (SELECT AuthorID from affiliatedTo) and b.AuthoredByID = a.AuthorID\",[title])\n",
    "        authors = cursor.fetchall()\n",
    "        if not authors:\n",
    "            continue\n",
    "        first_name = authors[0][1].split()[-1]\n",
    "        doi = research_crawler.extract_doi(title,first_name)\n",
    "        affiliations = springer_crawler.make_request(doi)\n",
    "        time.sleep(1)\n",
    "        if not affiliations:\n",
    "            affiliations = pubmed_crawler.make_request(doi)\n",
    "            if not affiliations:\n",
    "                continue\n",
    "\n",
    "        for affiliation in affiliations:\n",
    "            manual.write(\":\".join(affiliation))\n",
    "            manual.close()\n",
    "    except:\n",
    "        continue\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "[('2957517', 'Tijmen Tieleman'), ('1695689', 'Grace Hinton')]"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "b'<!DOCTYPE html\\n\\tPUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\\n\\t \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en-US\" xml:lang=\"en-US\">\\n<head>\\n<title>Any ID converter</title>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-1\" />\\n</head>\\n<body bgcolor=\"#F8F8F8\">\\n<h1>Any ID converter</h1><hr /><form method=\"get\" action=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/\" enctype=\"multipart/form-data\"><p><textarea name=\"ids\"  rows=\"15\" cols=\"60\"></textarea> <br /> <br /> Convert: <select name=\"idtype\" >\\n<option value=\"pmcid\">pmcid</option>\\n<option selected=\"selected\" value=\"pmid\">pmid</option>\\n<option value=\"mid\">mid</option>\\n<option value=\"doi\">doi</option>\\n</select> <br /> Output:&nbsp;&nbsp; <select name=\"format\" >\\n<option value=\"xml\">xml</option>\\n<option selected=\"selected\" value=\"html\">html</option>\\n<option value=\"json\">json</option>\\n<option value=\"csv\">csv</option>\\n</select> <br /> Show Versions:&nbsp;&nbsp; <select name=\"versions\" >\\n<option selected=\"selected\" value=\"yes\">yes</option>\\n<option value=\"no\">no</option>\\n</select> <br /> Show AIID:&nbsp;&nbsp; <select name=\"showaiid\" >\\n<option value=\"yes\">yes</option>\\n<option selected=\"selected\" value=\"no\">no</option>\\n</select> <br /> Tool:&nbsp;&nbsp; <input type=\"text\" name=\"tool\" value=\"my_tool\" size=\"50\" maxlength=\"80\" /> <br /> E-Mail:&nbsp;&nbsp; <input type=\"text\" name=\"email\" value=\"my_email@example.com\" size=\"50\" maxlength=\"80\" /></p><input type=\"submit\" name=\".submit\" value=\"Submit\" /><p><h2>Examples:</h2> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=PMC14901,PMC14902&amp;tool=my_tool&amp;email=my_email@example.com\">https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=PMC14901,PMC14902&tool=my_tool&email=my_email@example.com</a> <br /> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=PMC14901,PMC14902&amp;idtype=pmcid&amp;tool=my_tool&amp;email=my_email@example.com\">https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=PMC14901,PMC14902&idtype=pmcid&tool=my_tool&email=my_email@example.com</a> <br /> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=10848627,10848628\">https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=10848627,10848628</a> <br /> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=NIHMS334455&amp;format=json&amp;versions=no&amp;tool=my_tool&amp;email=my_email@example.com\">https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=NIHMS334455&format=json&versions=no&tool=my_tool&email=my_email@example.com</a> <br /> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=PMC3283037.2&amp;showaiid=yes&amp;tool=my_tool&amp;email=my_email@example.com\">https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=PMC3283037.2&showaiid=yes&tool=my_tool&email=my_email@example.com</a> <br /> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=PMC3283037.2&amp;format=csv&amp;tool=my_tool&amp;email=my_email@example.com\">https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=PMC3283037.2&format=csv&tool=my_tool&email=my_email@example.com</a> <br /> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=3283037.2&amp;idtype=pmcid&amp;tool=my_tool\">https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=3283037.2&idtype=pmcid&tool=my_tool</a> <br /> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=pMc3283037&amp;my_email@example.com\">https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=pMc3283037&my_email@example.com</a> <br /> <a href=\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=10.1130/0091-7613(1995)023%3C0004%3ARDDTLD%3E2.3.CO;2\">https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids=10.1130/0091-7613(1995)023%3C0004%3ARDDTLD%3E2.3.CO;2</a> <br /></p></form>\\n</body>\\n</html>'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/.\").content"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = requests.get(\"http://list.didsoft.com/get?email=david.le@inovex.de&pass=m75h35&pid=http3000&showcountry=no\").content.decode(\"utf-8\")\n",
    "proxy_list = response.split(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "x = requests.get(\"https://api.springernature.com/openaccess/jats?q=doi:10.1186/s13326-022-00280-6&api_key=4d550573ce69005bbdb3fc40e70a3b2c\").content\n",
    "#x = requests.get(\"https://api.springernature.com/openaccess/jats?q=doi:10.1117/12.525746&api_key=4d550573ce69005bbdb3fc40e70a3b2c\").content"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "a = xmltodict.parse(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "{'response': {'apiMessage': 'This XML was provided by Springer Nature',\n  'query': 'doi:10.1186/s13326-022-00280-6',\n  'apiKey': '4d550573ce69005bbdb3fc40e70a3b2c',\n  'result': {'total': '1',\n   'start': '1',\n   'pageLength': '10',\n   'recordsDisplayed': '1'},\n  'records': {'article': {'@dtd-version': '1.2',\n    '@article-type': 'research-article',\n    '@xml:lang': 'en',\n    '@xmlns:mml': 'http://www.w3.org/1998/Math/MathML',\n    '@xmlns:xlink': 'http://www.w3.org/1999/xlink',\n    'front': {'journal-meta': {'journal-id': {'@journal-id-type': 'publisher-id',\n       '#text': '13326'},\n      'journal-title-group': {'journal-title': 'Journal of Biomedical Semantics',\n       'abbrev-journal-title': {'@abbrev-type': 'publisher',\n        '#text': 'J Biomed Semant'}},\n      'issn': {'@pub-type': 'epub', '#text': '2041-1480'},\n      'publisher': {'publisher-name': 'BioMed Central',\n       'publisher-loc': 'London'}},\n     'article-meta': {'article-id': [{'@pub-id-type': 'publisher-id',\n        '#text': 's13326-022-00280-6'},\n       {'@pub-id-type': 'manuscript', '#text': '280'},\n       {'@pub-id-type': 'doi', '#text': '10.1186/s13326-022-00280-6'}],\n      'article-categories': {'subj-group': {'@subj-group-type': 'heading',\n        'subject': 'Research'}},\n      'title-group': {'article-title': {'@xml:lang': 'en',\n        '#text': 'We are not ready yet: limitations of state-of-the-art disease named entity recognizers'}},\n      'contrib-group': {'contrib': [{'@contrib-type': 'author',\n         '@corresp': 'yes',\n         '@id': 'Au1',\n         'contrib-id': {'@contrib-id-type': 'orcid',\n          '#text': 'http://orcid.org/0000-0002-6356-6760'},\n         'name': {'surname': 'Kühnel', 'given-names': 'Lisa'},\n         'address': {'email': 'kuehnel@zbmed.de'},\n         'xref': [{'@ref-type': 'aff', '@rid': 'Aff1', '#text': '1'},\n          {'@ref-type': 'aff', '@rid': 'Aff2', '#text': '2'},\n          {'@ref-type': 'corresp',\n           '@rid': 'IDs13326022002806_cor1',\n           '#text': 'a'}]},\n        {'@contrib-type': 'author',\n         '@id': 'Au2',\n         'name': {'surname': 'Fluck', 'given-names': 'Juliane'},\n         'address': {'email': 'fluck@zbmed.de'},\n         'xref': [{'@ref-type': 'aff', '@rid': 'Aff1', '#text': '1'},\n          {'@ref-type': 'aff', '@rid': 'Aff3', '#text': '3'}]}],\n       'aff': [{'@id': 'Aff1',\n         'label': '1',\n         'institution-wrap': {'institution-id': [{'@institution-id-type': 'GRID',\n            '#text': 'grid.461646.7'},\n           {'@institution-id-type': 'ISNI', '#text': '0000 0001 2167 4053'}],\n          'institution': {'@content-type': 'org-name',\n           '#text': 'ZB MED - Information Centre for Life Sciences'}},\n         'addr-line': [{'@content-type': 'street',\n           '#text': 'Gleueler Str. 60'},\n          {'@content-type': 'city', '#text': 'Cologne'}],\n         'country': {'@country': 'DE', '#text': 'Germany'}},\n        {'@id': 'Aff2',\n         'label': '2',\n         'institution-wrap': {'institution-id': [{'@institution-id-type': 'GRID',\n            '#text': 'grid.7491.b'},\n           {'@institution-id-type': 'ISNI', '#text': '0000 0001 0944 9128'}],\n          'institution': {'@content-type': 'org-name',\n           '#text': 'Graduate School DILS, Bielefeld Institute for Bioinformatics Infrastructure (BIBI), Faculty of Technology, Bielefeld University'}},\n         'addr-line': [{'@content-type': 'street',\n           '#text': 'Postfach 10 01 31'},\n          {'@content-type': 'postcode', '#text': '33501'},\n          {'@content-type': 'city', '#text': 'Bielefeld'}],\n         'country': {'@country': 'DE', '#text': 'Germany'}},\n        {'@id': 'Aff3',\n         'label': '3',\n         'institution-wrap': {'institution-id': [{'@institution-id-type': 'GRID',\n            '#text': 'grid.10388.32'},\n           {'@institution-id-type': 'ISNI', '#text': '0000 0001 2240 3300'}],\n          'institution': {'@content-type': 'org-name',\n           '#text': 'Institute of Geodesy and Geoinformation, Agricultural Faculty, University of Bonn'}},\n         'addr-line': [{'@content-type': 'street', '#text': 'Nussallee 1'},\n          {'@content-type': 'postcode', '#text': '53115'},\n          {'@content-type': 'city', '#text': 'Bonn'}],\n         'country': {'@country': 'DE', '#text': 'Germany'}}]},\n      'author-notes': {'corresp': {'@id': 'IDs13326022002806_cor1',\n        'label': 'a',\n        'email': 'kuehnel@zbmed.de'}},\n      'pub-date': [{'@date-type': 'pub',\n        '@publication-format': 'electronic',\n        'day': '27',\n        'month': '10',\n        'year': '2022'},\n       {'@date-type': 'collection',\n        '@publication-format': 'electronic',\n        'month': '12',\n        'year': '2022'}],\n      'volume': '13',\n      'issue': {'@seq': '26', '#text': '1'},\n      'elocation-id': '26',\n      'history': {'date': [{'@date-type': 'registration',\n         'day': '14',\n         'month': '10',\n         'year': '2022'},\n        {'@date-type': 'received', 'day': '26', 'month': '7', 'year': '2021'},\n        {'@date-type': 'accepted', 'day': '12', 'month': '10', 'year': '2022'},\n        {'@date-type': 'online', 'day': '27', 'month': '10', 'year': '2022'}]},\n      'permissions': {'copyright-statement': {'@content-type': 'compact',\n        '#text': '© The Author(s) 2022'},\n       'copyright-year': '2022',\n       'copyright-holder': 'The Author(s)',\n       'license': {'@license-type': 'open-access',\n        '@xlink:href': 'http://creativecommons.org/licenses/by/4.0/',\n        'license-p': {'bold': 'Open Access',\n         'ext-link': [{'@xlink:href': 'http://creativecommons.org/licenses/by/4.0/',\n           '@ext-link-type': 'uri',\n           '#text': 'http://creativecommons.org/licenses/by/4.0/'},\n          {'@xlink:href': 'http://creativecommons.org/publicdomain/zero/1.0/',\n           '@ext-link-type': 'uri',\n           '#text': 'http://creativecommons.org/publicdomain/zero/1.0/'}],\n         '#text': \"This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit . The Creative Commons Public Domain Dedication waiver () applies to the data made available in this article, unless otherwise stated in a credit line to the data.\"}}},\n      'abstract': {'@xml:lang': 'en',\n       '@id': 'Abs1',\n       'title': 'Abstract',\n       'sec': [{'@id': 'ASec1',\n         'title': 'Background',\n         'p': {'@id': 'Par1',\n          '#text': 'Intense research has been done in the area of biomedical natural language processing. Since the breakthrough of transfer learning-based methods, BERT models are used in a variety of biomedical and clinical applications. For the available data sets, these models show excellent results - partly exceeding the inter-annotator agreements. However, biomedical named entity recognition applied on COVID-19 preprints shows a performance drop compared to the results on test data. The question arises how well trained models are able to predict on completely new data, i.e. to generalize.'}},\n        {'@id': 'ASec2',\n         'title': 'Results',\n         'p': {'@id': 'Par2',\n          '#text': 'Based on the example of disease named entity recognition, we investigate the robustness of different machine learning-based methods - thereof transfer learning - and show that current state-of-the-art methods work well for a given training and the corresponding test set but experience a significant lack of generalization when applying to new data.'}},\n        {'@id': 'ASec3',\n         'title': 'Conclusions',\n         'p': {'@id': 'Par3',\n          '#text': 'We argue that there is a need for larger annotated data sets for training and testing. Therefore, we foresee the curation of further data sets and, moreover, the investigation of continual learning processes for machine learning-based models.'}}]},\n      'kwd-group': {'@xml:lang': 'en',\n       'title': 'Keywords',\n       'kwd': ['Text mining', 'bioNLP', 'BERT', 'Manual Curation']},\n      'funding-group': {'award-group': {'funding-source': {'institution-wrap': {'institution': 'Deutsche Zentralbibliothek für Medizin (ZBMED) (3430)'}}}},\n      'custom-meta-group': {'custom-meta': [{'meta-name': 'publisher-imprint-name',\n         'meta-value': 'BioMed Central'},\n        {'meta-name': 'volume-issue-count', 'meta-value': '1'},\n        {'meta-name': 'issue-article-count', 'meta-value': '26'},\n        {'meta-name': 'issue-toc-levels', 'meta-value': '0'},\n        {'meta-name': 'issue-pricelist-year', 'meta-value': '2022'},\n        {'meta-name': 'issue-copyright-holder', 'meta-value': 'The Author(s)'},\n        {'meta-name': 'issue-copyright-year', 'meta-value': '2022'},\n        {'meta-name': 'article-contains-esm', 'meta-value': 'No'},\n        {'meta-name': 'article-numbering-style', 'meta-value': 'Unnumbered'},\n        {'meta-name': 'article-registration-date-year', 'meta-value': '2022'},\n        {'meta-name': 'article-registration-date-month', 'meta-value': '10'},\n        {'meta-name': 'article-registration-date-day', 'meta-value': '14'},\n        {'meta-name': 'article-toc-levels', 'meta-value': '0'},\n        {'meta-name': 'toc-levels', 'meta-value': '0'},\n        {'meta-name': 'volume-type', 'meta-value': 'Regular'},\n        {'meta-name': 'journal-product', 'meta-value': 'ArchiveJournal'},\n        {'meta-name': 'numbering-style', 'meta-value': 'Unnumbered'},\n        {'meta-name': 'article-grants-type', 'meta-value': 'OpenChoice'},\n        {'meta-name': 'metadata-grant', 'meta-value': 'OpenAccess'},\n        {'meta-name': 'abstract-grant', 'meta-value': 'OpenAccess'},\n        {'meta-name': 'bodypdf-grant', 'meta-value': 'OpenAccess'},\n        {'meta-name': 'bodyhtml-grant', 'meta-value': 'OpenAccess'},\n        {'meta-name': 'bibliography-grant', 'meta-value': 'OpenAccess'},\n        {'meta-name': 'esm-grant', 'meta-value': 'OpenAccess'},\n        {'meta-name': 'online-first', 'meta-value': 'false'},\n        {'meta-name': 'pdf-file-reference',\n         'meta-value': 'BodyRef/PDF/13326_2022_Article_280.pdf'},\n        {'meta-name': 'pdf-type', 'meta-value': 'Typeset'},\n        {'meta-name': 'target-type', 'meta-value': 'OnlinePDF'},\n        {'meta-name': 'issue-type', 'meta-value': 'Regular'},\n        {'meta-name': 'article-type', 'meta-value': 'OriginalPaper'},\n        {'meta-name': 'journal-subject-primary', 'meta-value': 'Mathematics'},\n        {'meta-name': 'journal-subject-secondary', 'meta-value': 'Algorithms'},\n        {'meta-name': 'journal-subject-secondary',\n         'meta-value': 'Computer Appl. in Life Sciences'},\n        {'meta-name': 'journal-subject-secondary',\n         'meta-value': 'Data Mining and Knowledge Discovery'},\n        {'meta-name': 'journal-subject-secondary',\n         'meta-value': 'Computational Biology/Bioinformatics'},\n        {'meta-name': 'journal-subject-secondary',\n         'meta-value': 'Bioinformatics'},\n        {'meta-name': 'journal-subject-secondary',\n         'meta-value': 'Combinatorial Libraries'},\n        {'meta-name': 'journal-subject-collection',\n         'meta-value': 'Mathematics and Statistics'},\n        {'meta-name': 'open-access', 'meta-value': 'true'}]}}},\n    'body': {'sec': [{'@id': 'Sec1',\n       'title': 'Background',\n       'p': [{'@id': 'Par15',\n         '#text': 'The amount of freely available, electronic data increased enormously in the biomedical field. Automatic information extraction methods have become indispensable and intense research has been done in the past. Whereas most text mining tasks were achieved with the help of rule-based systems in the beginning, mainly machine learning methods are used nowadays. The latter are strongly dependent on large amounts of curated data. However, manual curation is a complex and time consuming task, at least in the biomedical field, that needs to be done by domain experts. Hence, the availability of such high-quality data sets is strongly limited.'},\n        {'@id': 'Par16',\n         'italic': ['i2b2 NLP Shared Tasks',\n          'Critical Assessment of Information Extraction systems in Biology (BioCreAtivE)',\n          'et al.'],\n         'xref': [{'@ref-type': 'bibr', '@rid': 'CR1', '#text': '1'},\n          {'@ref-type': 'bibr', '@rid': 'CR2', '#text': '2'},\n          {'@ref-type': 'bibr', '@rid': 'CR3', '#text': '3'},\n          {'@ref-type': 'bibr', '@rid': 'CR4', '#text': '4'},\n          {'@ref-type': 'bibr', '@rid': 'CR5', '#text': '5'},\n          {'@ref-type': 'bibr', '@rid': 'CR6', '#text': '6'},\n          {'@ref-type': 'bibr', '@rid': 'CR7', '#text': '7'},\n          {'@ref-type': 'bibr', '@rid': 'CR8', '#text': '8'}],\n         '#text': 'In the area of biomedical named entity recognition (NER), most data sets have been released for shared tasks and challenges open for the community. To name two examples, the national NLP clinical challenges (n2c2), formerly known as , provide curated clinical data to researchers []; the organization  organizes challenges for biological natural language processing (NLP) tasks and therefore also releases annotated data. In terms of disease entity recognition, to the best of our knowledge, two publicly available literature data sets exist that are commonly used: the National Center for Biotechnology Information (NCBI) Disease corpus [] and the BioCreative V Chemical Disease Relation Task (BC5CDR) Disease corpus []. Both of the mentioned disease data sets follow the same annotation guidelines which are necessary to ensure consistency in annotations. These guidelines have been published together with the NCBI Disease corpus [] and are also used for the more recent one (BC5CDR)[]. Moreover, there are a few further data sets that contain disease named entities but were originally developed for related tasks, such as relation extraction. For example, Bagewadi  developed a corpus for the extraction of microRNA (miRNA) mentions and their relationships - thereof diseases []. The authors developed their own, simple annotation guidelines which state that disease terms are restricted to nouns, hence adjective terms are ignored. Moreover, the BioNLP13 Cancer Genetics (CG) data set is developed as event extraction corpus and contains annotated cancer-related disease terms []. Next to the existing corpora, we recently annotated 50 COVID-19 related articles with disease mentions [].'},\n        {'@id': 'Par17',\n         'italic': ['support vector machines',\n          'hidden markov models',\n          'conditional random fields'],\n         'xref': {'@ref-type': 'bibr', '@rid': 'CR9', '#text': '9'},\n         '#text': 'Methodologically, the machine learning-based approaches applied to NLP have changed over time. First, methods like ,  or , which all belong to the class of supervised algorithms, were often superior compared to rule based approaches. For those techniques, so-called features are needed to describe the input data. Examples of used features include general linguistic features (e.g. part-of-speech (POS) tags, stems), orthographic features (e.g. punctuation character, capitalized word) or dictionary look-up features. Later, so-called word embeddings -\\xa0vector representations of words, usually learned over large collections of unlabeled data with the help of neural networks -\\xa0replaced this feature engineering process []. These vectors are usually pre-trained with the objective to build a general language model, i.e. to predict the next word in a sequence. This principle can be understood as providing the neural network with prior knowledge about the nature of words and sentences - i.e. their semantics and syntax.'},\n        {'@id': 'Par18',\n         'xref': [{'@ref-type': 'bibr', '@rid': 'CR10', '#text': '10'},\n          {'@ref-type': 'bibr', '@rid': 'CR10', '#text': '10'},\n          {'@ref-type': 'bibr', '@rid': 'CR11', '#text': '11'}],\n         '#text': 'The aforementioned methods are all feature-based approaches: pre-trained representations (word embeddings) are included as features for a task-specific architecture []. More recently, so-called fine-tuning approaches have gained interest, which exploit a mechanism known as transfer learning. An already trained model is used as starting point to be trained on a new task. In case of NLP, the model is pre-trained on a general language understanding task and then fine-tuned on a specific NLP task like NER or relation extraction. With this shift in text mining methodologies, the complexity of the workflow is drastically reduced compared to rule- and feature-based approaches. Rule-based approaches require several pre-processing steps as for instance part-of-speech tagging, tokenization and sentence detection. Feature-based approaches rely on at least two different architectures, i.e. the creation of features and their inclusion into a (different) model. In contrast, fine-tuning based approaches only define one network architecture that is applicable to several different downstream tasks. The most popular network architecture is the bidirectional encoder representation\\xa0from transformers (BERT) [] that has been adapted to the biomedical area, called BioBERT [], and shows state-of-the-art results for several different NLP tasks, thereof disease NER .'},\n        {'@id': 'Par19',\n         'xref': [{'@ref-type': 'bibr', '@rid': 'CR8', '#text': '8'},\n          {'@ref-type': 'bibr', '@rid': 'CR12', '#text': '12'},\n          {'@ref-type': 'fn', '@rid': 'Fn1', '#text': '1'},\n          {'@ref-type': 'bibr', '@rid': 'CR8', '#text': '8'}],\n         '#text': 'Based on the needs during the current COVID-19 pandemic, we set up the text mining-based semantic search engine preVIEW that automatically indexes preprints from several different sources [, ]. To recognize several entity classes (thereof diseases), we integrated publicly available ML-based models which show promising results of F1-scores above 85% for disease name recognition. Unfortunately, we realized a significant drop in performance when evaluated on a newly annotated COVID-19 preprint data set. With the implementation of an additional post-processing step that especially focuses on the recognition of COVID-19 related terms, their mapping to the new identifier and the removal of false positive entities that refer to the virus instead of the disease, we could achieve good results for this specific corpus [].'},\n        {'@id': 'Par20',\n         '#text': 'These findings encouraged us to examine this performance reduction phenomenon in more detail - based on known data heavily used by the community: To the best of our knowledge, all recently developed systems for the recognition of diseases are trained and evaluated on either the NCBI or the BC5CDR corpus, on both of them separately or on the combination of these data sets. The question arises whether the models trained on these data sets are robust and applicable to real world applications.'},\n        {'@id': 'Par21',\n         'italic': ['A', 'B', 'cross evaluation'],\n         'xref': [{'@ref-type': 'bibr', '@rid': 'CR6', '#text': '6'},\n          {'@ref-type': 'bibr', '@rid': 'CR7', '#text': '7'},\n          {'@ref-type': 'bibr', '@rid': 'CR4', '#text': '4'}],\n         '#text': 'In the current work, we investigate the similarities and differences of the two data sets and, in addition, compare them to a random PubMed data set in order to analyze the characteristics/bias of the different corpora. We also examine different NER algorithms – both transfer learning- and non transfer learning-based methods – and compare the performance of the algorithms trained on data set  and tested on the data set . That is, we train a model explicitly on only one corpus and use the test sets of other corpora to obtain an independent evaluation of the quality of the model in terms of its ability to generalize. This is referred to as  in the following. Additionally, we determine the performance of two of the algorithms trained on a merged corpus of both data sets (combined learning). Moreover, we evaluate the methods on the three above mentioned independent data sets: The first was developed for finding relationships between miRNAs and different biomedical entities, thereof diseases []. The corpus will be named miRNA-disease corpus in the following. Secondly, we evaluate the models on the BioNLP13-CG corpus which contains cancer-related disease terms []. Finally, we will use our own developed corpus which consists of 50 COVID-19 related articles that contain disease mentions (referred to as COVID Disease corpus in the following). Whereas, the latter relies on the annotation guidelines released with the NCBI corpus [], the two other corpora come with their own annotation guidelines.'}]},\n      {'@id': 'Sec2',\n       '@sec-type': 'results',\n       'title': 'Results',\n       'p': {'@id': 'Par22',\n        '#text': 'This section is subdivided into three different parts. First, we describe the results of the corpora comparison analyses. Afterwards, the results of the cross evaluations are described and finally we present the results of the combined learning approach.'},\n       'sec': [{'@id': 'Sec3',\n         'title': 'Semantic and linguistic comparison of data sets',\n         'p': [{'@id': 'Par23',\n           'xref': {'@rid': 'Fig1', '@ref-type': 'fig', '#text': '1'},\n           'fig': {'@id': 'Fig1',\n            'label': 'Fig. 1',\n            'caption': {'@xml:lang': 'en',\n             'p': 'Semantic comparison of the NCBI and BC5CDR corpora on disease mention and concept level. The training sets are compared to their corresponding test sets. Additionally, the two different training sets are compared to the test sets of the respective other corpus'},\n            'graphic': {'@specific-use': 'HTML',\n             '@mime-subtype': 'PNG',\n             '@xlink:href': 'MediaObjects/13326_2022_280_Fig1_HTML.png'}},\n           '#text': 'In a first step, we analyzed and compared the two main disease NER data sets (i.e. NCBI and BC5CDR data sets) in detail. We determined the overlap of both mentions and concepts between the training and the corresponding test set. The overlap between NCBI training and its test set reaches 70% on concept level, compared to an overlap of 60% between BC5CDR training and test set. Second, we determined the “cross-similarity”, i.e. the similarity of the training set of the NCBI corpus and the test set of the BC5CDR corpus and vice versa. The overlap between NCBI training set and BC5CDR test set only reaches 32% on the concept level and for the opposite case a value of 24% is reached. An overview of all results, also on the mention level, is given in Fig.\\xa0. On the mention level, the overlap is lower within a corpus but we can also observe a drastic drop of cross similarity.'},\n          {'@id': 'Par24',\n           'italic': 'scattertext',\n           'xref': [{'@ref-type': 'bibr', '@rid': 'CR13', '#text': '13'},\n            {'@rid': 'Fig2', '@ref-type': 'fig', '#text': '2'},\n            {'@rid': 'Fig2', '@ref-type': 'fig', '#text': '2'},\n            {'@rid': 'Fig2', '@ref-type': 'fig', '#text': '2'},\n            {'@rid': 'Fig2', '@ref-type': 'fig', '#text': '2'}],\n           'fig': {'@id': 'Fig2',\n            'label': 'Fig. 2',\n            'caption': {'@xml:lang': 'en',\n             'p': {'italic': 'scattertext',\n              '#text': 'Comparison of the data sets with . On each axis, the frequency of a term is shown for the given documents. In Fig. 2a, the BC5CDR training set is compared to its given test set whereas in Fig. 2b, the BC5CDR training set is compared to the NCBI training set. In Figs. 2c and 2d, the BC5CDR training set and the NCBI training set are compared against a randomly chosen PubMed corpus of similar size'}},\n            'graphic': {'@specific-use': 'HTML',\n             '@mime-subtype': 'PNG',\n             '@xlink:href': 'MediaObjects/13326_2022_280_Fig2_HTML.png'}},\n           '#text': 'Moreover, we compared the linguistic variability of the different corpora using the visualization tool  []. In Fig. a, we compared the BC5CDR training corpus to its corresponding test set. It shows a positive, linear relationship, indicating that the same words (or words with similar meaning) occur with similar frequency. In contrast, we do not see a relationship between the BC5CDR training set and the NCBI training set as the points are scattered throughout the whole plot (see Fig. b). This means, that terms that occur often in the BC5CDR training set occur rarely in the NCBI training set and vice versa. Finally, we compared both, the NCBI and the BC5CDR corpus, to the random PubMed corpus and received similar results (see Figs. c and d): in both cases also no linear trend can be seen but a widely distributed scatterplot. Whereas this might be expected for the BC5CDR corpus, as it only covers a specific domain (i.e. cardiovascular, neurological, renal and hepatic toxicity and their role in drug development), the NCBI corpus is intended to represent entire PubMed and the result is therefore rather unexpected.'}]},\n        {'@id': 'Sec4',\n         'title': 'Cross Evaluation of NER models',\n         'p': [{'@id': 'Par25',\n           'xref': [{'@rid': 'Tab1', '@ref-type': 'table', '#text': '1'},\n            {'@rid': 'Sec10', '@ref-type': 'sec', '#text': '5.2'},\n            {'@rid': 'Fig3', '@ref-type': 'fig', '#text': '3'},\n            {'@rid': 'Tab2', '@ref-type': 'table', '#text': '2'}],\n           'italic': 'disease-all',\n           '#text': 'In summary, we tested six different state-of-the-art machine learning algorithms, namely BioBERT, scispaCy, TaggerOne, DNorm, Stanza and HUNER. Whereas we trained BioBERT and HUNER in this study, we applied the other algorithms “as is”. An overview about the models can be seen in Table\\xa0. The algorithms are further described in Section . All trained models are evaluated on both available test sets (NCBI and BC5CDR Disease). As can be seen in Fig.\\xa0, the cross evaluation results in a significant drop for all used models. Whereas the BioBERT model trained on the NCBI training corpus achieves an F1-score of about 87% on the corresponding test set, it drops to 68% for the BC5CDR Disease test set. Similarly, the BioBERT model trained on the BC5CDR training set reaches an F1-score of 83% on the corresponding test set, the cross-evaluation, however, results in an F1-score of 69%. The highest difference is determined for the TaggerOne model trained on the NCBI training set. Whereas an F1-score of 83% for the corresponding test set is achieved, only 52% are reached for the BC5CDR test set. Vice versa, for the TaggerOne model trained on the BC5CDR corpus, we realize a 20% drop for the cross-evaluation. For trained DNorm, scispaCy, HUNER and Stanza models, the same trend has been determined. However, a slightly higher F1-score was determined for the HUNER model fine-tuned on the BC5CDR corpus: the F1-score amounts to 73.7% for the NCBI test set. This could be explained by the fact that the HUNER  model that we used was, amongst others, pre-trained on the NCBI training corpus. Detailed results - including precision and recall - can be seen in Table\\xa0. Interestingly, even though both precision and recall decrease, for all cross evaluations the drop of the recall is bigger than the drop of precision. For example, for BioBERT trained on the NCBI corpus, the recall drops by 22.34% whereas the precision drops by 18.52%. For TaggerOne trained on BC5CDR, the drop in precision amounts to 15.29%, and the difference in recall is 24.29%.'},\n          {'@id': 'Par26',\n           'xref': {'@rid': 'Tab3', '@ref-type': 'table', '#text': '3'},\n           'table-wrap': {'@id': 'Tab1',\n            'label': 'Table 1',\n            'caption': {'@xml:lang': 'en',\n             'p': 'Overview of used training data sets for the respective algorithms'},\n            'table': {'@frame': 'hsides',\n             '@rules': 'groups',\n             'thead': {'tr': [{'th': [{'@align': 'left', 'p': 'Training set'},\n                 {'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'Algorithm'},\n                 {'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left'}]},\n               {'th': [{'@align': 'left'},\n                 {'@align': 'left', 'p': 'BioBERT'},\n                 {'@align': 'left', 'p': 'scispaCy'},\n                 {'@align': 'left', 'p': 'DNorm'},\n                 {'@align': 'left', 'p': 'TaggerOne'},\n                 {'@align': 'left', 'p': 'HUNER'},\n                 {'@align': 'left', 'p': 'Stanza'}]}]},\n             'tbody': {'tr': [{'td': [{'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq1',\n                    'alternatives': {'mml:math': {'@id': 'IEq1_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq1_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq1.gif'}}}}},\n                 {'@align': 'left'},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq2',\n                    'alternatives': {'mml:math': {'@id': 'IEq2_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq2_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq2.gif'}}}}},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq3',\n                    'alternatives': {'mml:math': {'@id': 'IEq3_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq3_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq3.gif'}}}}},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq4',\n                    'alternatives': {'mml:math': {'@id': 'IEq4_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq4_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq4.gif'}}}}},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq5',\n                    'alternatives': {'mml:math': {'@id': 'IEq5_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq5_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq5.gif'}}}}}]},\n               {'td': [{'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq6',\n                    'alternatives': {'mml:math': {'@id': 'IEq6_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq6_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq6.gif'}}}}},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq7',\n                    'alternatives': {'mml:math': {'@id': 'IEq7_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq7_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq7.gif'}}}}},\n                 {'@align': 'left'},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq8',\n                    'alternatives': {'mml:math': {'@id': 'IEq8_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq8_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq8.gif'}}}}},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq9',\n                    'alternatives': {'mml:math': {'@id': 'IEq9_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq9_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq9.gif'}}}}},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq10',\n                    'alternatives': {'mml:math': {'@id': 'IEq10_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq10_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq10.gif'}}}}}]},\n               {'td': [{'@align': 'left', 'p': 'NCBI+BC5CDR'},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq11',\n                    'alternatives': {'mml:math': {'@id': 'IEq11_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq11_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq11.gif'}}}}},\n                 {'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq12',\n                    'alternatives': {'mml:math': {'@id': 'IEq12_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq12_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq12.gif'}}}}},\n                 {'@align': 'left'},\n                 {'@align': 'left'}]},\n               {'td': [{'@align': 'left', 'p': 'miRNA-Disease'},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq13',\n                    'alternatives': {'mml:math': {'@id': 'IEq13_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq13_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq13.gif'}}}}},\n                 {'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left'}]},\n               {'td': [{'@align': 'left', 'p': 'BioNLP13-CG'},\n                 {'@align': 'left',\n                  'p': {'inline-formula': {'@id': 'IEq14',\n                    'alternatives': {'mml:math': {'@id': 'IEq14_Math',\n                      'mml:mo': {'@stretchy': 'false', '#text': '✓'}},\n                     'tex-math': {'@id': 'IEq14_TeX',\n                      '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\checkmark$$\\\\end{document}'},\n                     'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq14.gif'}}}}},\n                 {'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left'}]}]}}},\n           '#text': 'In addition, we evaluated the BioBERT models on three further related corpora that contain disease entities. As reference model, we use BioBERT trained on the respective training data set (if available). The results can be seen in Table\\xa0. The BioBERT model trained on the miRNA-disease data set achieves an F1-score of approximately 80% on the corresponding test set. Both the NCBI and BC5CDR model perform only around 4% worse on the miRNA-disease test set. However, the BioBERT model trained on the NCBI corpus achieves only an F1-score of 61% on the BioNLP13-CG test set (in contrast to 86% when trained on the corresponding training set). An even worse F1-score can be seen when evaluating both the NCBI and BC5CDR model on the COVID-disease data set where F1-scores of 36% and 23% are achieved, respectively. This is mainly caused by the fact that the trained models are not able to predict newly evolved diseases, such as COVID-19.'},\n          {'@id': 'Par27',\n           'table-wrap': {'@id': 'Tab2',\n            'label': 'Table 2',\n            'caption': {'@xml:lang': 'en',\n             'p': 'Precision, recall and F1-score for both the corresponding test set and the respective other test set (i.e., cross evaluation)'},\n            'table': {'@frame': 'hsides',\n             '@rules': 'groups',\n             'thead': {'tr': {'th': [{'@align': 'left', 'p': 'Algorithm'},\n                {'@align': 'left', 'p': 'Train set'},\n                {'@align': 'left', 'p': 'Test set'},\n                {'@align': 'left', 'p': 'Precision[%]'},\n                {'@align': 'left', 'p': 'Recall[%]'},\n                {'@align': 'left', 'p': 'F1-Score[%]'}]}},\n             'tbody': {'tr': [{'td': [{'@align': 'left', 'p': 'BioBERT'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '84.62'},\n                 {'@align': 'left', 'p': '90.09'},\n                 {'@align': 'left', 'p': '87.27'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '69.77'},\n                 {'@align': 'left', 'p': '67.75'},\n                 {'@align': 'left', 'p': '68.75'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '73.63'},\n                 {'@align': 'left', 'p': '63.19'},\n                 {'@align': 'left', 'p': '68.01'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '82.07'},\n                 {'@align': 'left', 'p': '85.39'},\n                 {'@align': 'left', 'p': '83.07'}]},\n               {'td': [{'@align': 'left', 'p': 'TaggerOne'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '83.46'},\n                 {'@align': 'left', 'p': '82.66'},\n                 {'@align': 'left', 'p': '83.06'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '70.01'},\n                 {'@align': 'left', 'p': '40.75'},\n                 {'@align': 'left', 'p': '51.51'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '68.30'},\n                 {'@align': 'left', 'p': '56.38'},\n                 {'@align': 'left', 'p': '61.77'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '83.59'},\n                 {'@align': 'left', 'p': '80.67'},\n                 {'@align': 'left', 'p': '82.11'}]},\n               {'td': [{'@align': 'left', 'p': 'scispaCy'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '65.65'},\n                 {'@align': 'left', 'p': '57.49'},\n                 {'@align': 'left', 'p': '61.30'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '76.20'},\n                 {'@align': 'left', 'p': '75.22'},\n                 {'@align': 'left', 'p': '75.71'}]},\n               {'td': [{'@align': 'left', 'p': 'DNorm'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '80.80'},\n                 {'@align': 'left', 'p': '81.90'},\n                 {'@align': 'left', 'p': '81.35'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '65.73'},\n                 {'@align': 'left', 'p': '50.29'},\n                 {'@align': 'left', 'p': '56.98'}]},\n               {'td': [{'@align': 'left', 'p': 'Stanza'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '86.65'},\n                 {'@align': 'left', 'p': '88.54'},\n                 {'@align': 'left', 'p': '87.58'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '70.24'},\n                 {'@align': 'left', 'p': '57.78'},\n                 {'@align': 'left', 'p': '63.40'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '75.57'},\n                 {'@align': 'left', 'p': '62.50'},\n                 {'@align': 'left', 'p': '68.42'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '82.85'},\n                 {'@align': 'left', 'p': '84.95'},\n                 {'@align': 'left', 'p': '83.88'}]},\n               {'td': [{'@align': 'left', 'p': 'HUNER'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '83.82'},\n                 {'@align': 'left', 'p': '86.35'},\n                 {'@align': 'left', 'p': '85.07'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '70.20'},\n                 {'@align': 'left', 'p': '64.92'},\n                 {'@align': 'left', 'p': '67.46'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '77.84'},\n                 {'@align': 'left', 'p': '69.90'},\n                 {'@align': 'left', 'p': '73.66'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '83.07'},\n                 {'@align': 'left', 'p': '83.52'},\n                 {'@align': 'left', 'p': '83.30'}]}]}}}},\n          {'@id': 'Par28',\n           'table-wrap': {'@id': 'Tab3',\n            'label': 'Table 3',\n            'caption': {'@xml:lang': 'en',\n             'p': 'Further cross evaluation results of BioBERT using related corpora'},\n            'table': {'@frame': 'hsides',\n             '@rules': 'groups',\n             'thead': {'tr': {'th': [{'@align': 'left', 'p': 'Train set'},\n                {'@align': 'left', 'p': 'Test set'},\n                {'@align': 'left', 'p': 'Precision[%]'},\n                {'@align': 'left', 'p': 'Recall[%]'},\n                {'@align': 'left', 'p': 'F1-Score[%]'}]}},\n             'tbody': {'tr': [{'td': [{'@align': 'left', 'p': 'MiRNA-disease'},\n                 {'@align': 'left', 'p': 'MiRNA-disease'},\n                 {'@align': 'left', 'p': '78.63'},\n                 {'@align': 'left', 'p': '80.60'},\n                 {'@align': 'left', 'p': '79.60'}]},\n               {'td': [{'@align': 'left', 'p': 'BioNLP13-CG'},\n                 {'@align': 'left', 'p': 'BioNLP13-CG'},\n                 {'@align': 'left', 'p': '86.01'},\n                 {'@align': 'left', 'p': '86.47'},\n                 {'@align': 'left', 'p': '86.24'}]},\n               {'td': [{'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': 'MiRNA-disease'},\n                 {'@align': 'left', 'p': '71.96'},\n                 {'@align': 'left', 'p': '81.53'},\n                 {'@align': 'left', 'p': '76.45'}]},\n               {'td': [{'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': 'MiRNA-disease'},\n                 {'@align': 'left', 'p': '72.74'},\n                 {'@align': 'left', 'p': '80.59'},\n                 {'@align': 'left', 'p': '76.47'}]},\n               {'td': [{'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': 'BioNLP-CG'},\n                 {'@align': 'left', 'p': '50.14'},\n                 {'@align': 'left', 'p': '79.09'},\n                 {'@align': 'left', 'p': '61.37'}]},\n               {'td': [{'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': 'BioNLP-CG'},\n                 {'@align': 'left', 'p': '48.60'},\n                 {'@align': 'left', 'p': '75.19'},\n                 {'@align': 'left', 'p': '59.05'}]},\n               {'td': [{'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': 'COVID Disease'},\n                 {'@align': 'left', 'p': '46.24'},\n                 {'@align': 'left', 'p': '29.66'},\n                 {'@align': 'left', 'p': '36.13'}]},\n               {'td': [{'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': 'COVID Disease'},\n                 {'@align': 'left', 'p': '30.64'},\n                 {'@align': 'left', 'p': '18.28'},\n                 {'@align': 'left', 'p': '22.89'}]}]}}}}]},\n        {'@id': 'Sec5',\n         'title': 'Learning on combined data set',\n         'p': [{'@id': 'Par29',\n           'xref': [{'@rid': 'Tab4', '@ref-type': 'table', '#text': '4'},\n            {'@rid': 'Fig3', '@ref-type': 'fig', '#text': '3'}],\n           'fig': {'@id': 'Fig3',\n            'label': 'Fig. 3',\n            'caption': {'@xml:lang': 'en',\n             'p': 'NER results for all tested ML algorithms. The F1-score is shown for the test set that belongs to the training set (corresponding test set) and to the test set of the respective other data set'},\n            'graphic': {'@specific-use': 'HTML',\n             '@mime-subtype': 'PNG',\n             '@xlink:href': 'MediaObjects/13326_2022_280_Fig3_HTML.png'}},\n           '#text': 'Finally, we trained a BioBERT model on both NCBI and BC5CDR training data sets simultaneously and also evaluated this on both corresponding test data sets. Also for TaggerOne such a combined model is provided that we evaluated. As can be seen in Table , the results are similarly high for both test data sets. For BioBERT, the result on the NCBI test set is only 0.07% worse than the model only trained on NCBI; the result on the BC5CDR test set is even the same (see Fig. ).'},\n          {'@id': 'Par30',\n           'table-wrap': {'@id': 'Tab4',\n            'label': 'Table 4',\n            'caption': {'@xml:lang': 'en',\n             'p': 'Evaluation of models trained on combined NCBI and BC5CDR data set'},\n            'table': {'@frame': 'hsides',\n             '@rules': 'groups',\n             'thead': {'tr': {'th': [{'@align': 'left', 'p': 'Algorithm'},\n                {'@align': 'left', 'p': 'Test set'},\n                {'@align': 'left', 'p': 'Precision[%]'},\n                {'@align': 'left', 'p': 'Recall[%]'},\n                {'@align': 'left', 'p': 'F1-Score[%]'}]}},\n             'tbody': {'tr': [{'td': [{'@align': 'left', 'p': 'TaggerOne'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '81.86'},\n                 {'@align': 'left', 'p': '80.23'},\n                 {'@align': 'left', 'p': '81.04'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '79.61'},\n                 {'@align': 'left', 'p': '77.69'},\n                 {'@align': 'left', 'p': '78.64'}]},\n               {'td': [{'@align': 'left', 'p': 'BioBERT'},\n                 {'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '85.19'},\n                 {'@align': 'left', 'p': '88.74'},\n                 {'@align': 'left', 'p': '86.93'}]},\n               {'td': [{'@align': 'left'},\n                 {'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '82.07'},\n                 {'@align': 'left', 'p': '85.21'},\n                 {'@align': 'left', 'p': '83.61'}]}]}}}}]}]},\n      {'@id': 'Sec6',\n       '@sec-type': 'discussion',\n       'title': 'Discussion',\n       'p': [{'@id': 'Par31',\n         'xref': [{'@ref-type': 'bibr', '@rid': 'CR11', '#text': '11'},\n          {'@ref-type': 'bibr', '@rid': 'CR14', '#text': '14'},\n          {'@ref-type': 'bibr', '@rid': 'CR16', '#text': '16'}],\n         '#text': 'In order to find relevant information in literature and hence to generate new knowledge, text mining methods have become indispensable because of the ever growing amount of electronic data. Therefore, a lot of research has been done in the area of bioNLP and current state-of-the-art algorithms show promising results on the available data sets. BERT is on everyone’s lips and used in a variety of biomedical and clinical applications [, –].'},\n        {'@id': 'Par32',\n         'xref': [{'@rid': 'Fig2', '@ref-type': 'fig', '#text': '2'},\n          {'@ref-type': 'bibr', '@rid': 'CR17', '#text': '17'}],\n         '#text': 'Because we integrated NER models into a semantic search engine and realized a drop in performance when evaluating an algorithm on a new data set, we started to question the robustness of current state-of-the-art methods. Therefore, in this work, we investigated the robustness of different machine learning-based algorithms on the task of disease named entity recognition. We chose this example because two different manually curated data sets are publicly available that are of similar size, basically follow the same annotation guidelines and are often used independently to develop and evaluate new methods. Assuming that the annotated disease corpora are large enough to train a model which generalizes and, in such a way is able to predict on new data, we evaluated the individually trained models on each other’s test set without further adjustment or training to test this hypothesis. Our analysis shows that none of the six tested algorithms performs nearly as good on cross evaluation as on the corresponding test set. Instead, we experience a significant drop in performance - on average 19% in terms of F1-score. To our mind, this can have the following two reasons: (1) the models can be overfitted towards the training data sets or (2) one such available corpus is simply not enough to learn this kind of complex biomedical NLP task. As we showed in our scatterplots, the content of the two used data sets strongly differ in content and wording and none of them represent the PubMed database (see Fig. ). The specific content of a corpus is strongly dependent on the selection criteria, i.e. based on which strategy the abstracts were included. For example, the BC5CDR corpus was randomly selected from the CTD-Pfizer corpus [] that contains 88,000 manually chosen and curated articles (abstracts) to investigate the potential involvement of pharmaceutical drugs in cardiovascular, neurological, renal and hepatic toxicity. Therefore, the BC5CDR corpus is focused on drugs and their role in toxicity.'},\n        {'@id': 'Par33',\n         '#text': 'To further investigate the models’ generalization ability, we used three additional data sets, originally developed for related tasks such as relation or event extraction. Whereas the drop in performance is relatively low for the miRNA-disease data set, we experience again a high drop for the BioNLP13-CG corpus. The lowest F1-score (amounting to 36% and 23% for the NCBI and BC5CDR models, respectively) is achieved for the COVID Disease data set that consists of relatively recent COVID-19 related articles.'},\n        {'@id': 'Par34',\n         'italic': 'catastrophic forgetting',\n         'xref': [{'@ref-type': 'bibr', '@rid': 'CR18', '#text': '18'},\n          {'@ref-type': 'bibr', '@rid': 'CR19', '#text': '19'},\n          {'@ref-type': 'bibr', '@rid': 'CR20', '#text': '20'}],\n         '#text': 'As the BioBERT model trained on both the NCBI and the BC5CDR training sets reaches nearly the same results as each model trained on only one data set, the model is able to predict well on more variable test data if the training data set covers a similar variance. Therefore, the question arises when the model would be “ready” for real world applications - i.e. when we would have enough representative data. The model needs to be further tested on manually curated data that again covers a different area. However, such experiments are hampered by a lack of high-quality labeled data. Therefore, we foresee to set up a crowd sourcing-based approach in the near future and want to test the capabilities of transfer learning-based approaches for an active learning setup. Sequential fine-tuning of BioBERT models (i.e. re-training) experiences a mechanism known as  - the model forgets previously gathered knowledge and is biased towards the last data set []. Recently, so-called Adapter modules have been proposed that can be used for sequential learning of different tasks [, ]. However, it remains open how such methods perform on exactly the same – but highly variable and complex – task (i.e. disease NER in our case).'}]},\n      {'@id': 'Sec7',\n       '@sec-type': 'conclusions',\n       'title': 'Conclusions',\n       'p': {'@id': 'Par35',\n        '#text': 'Even though current transfer learning-based state-of-the-art methods for bioNLP show excellent results on the given training and corresponding test data, our analysis showed that those models are - against our expectations - not yet ready for real world applications because of a lack of generalization capabilities. Named entity recognition in the biomedical domain is much more complex than solving tasks on general domain knowledge, such as the recognition of persons or organizations. Moreover, a continual learning process is of great importance as the science progresses not only continuously but also rapidly. Therefore, in our future work, we foresee both the manual annotation of further data sets and the investigation of continual learning capabilities on this task in order to be able to solve real world cases.'}},\n      {'@id': 'Sec8',\n       '@sec-type': 'materials|methods',\n       'title': 'Materials and Methods',\n       'p': {'@id': 'Par36',\n        '#text': 'In the following, we first describe the used data sets. Afterwards, all six used algorithms are shortly described.'},\n       'sec': [{'@id': 'Sec9',\n         'title': 'Data sets',\n         'p': [{'@id': 'Par37',\n           'xref': {'@ref-type': 'bibr', '@rid': 'CR21', '#text': '21'},\n           '#text': 'In the following section, we first describe the two main disease NER data sets (NCBI and BC5CDR) that follow the same annotation guidelines and are of comparable size. Thereafter, the three additional data sets are described. Thereof only one of the data sets follows the same annotation guidelines. The NCBI and BC5CDR corpora both consist of PubMed abstracts with manually curated disease annotations. The NCBI corpus with detailed annotation guidelines was released first. For the generation of the BC5CDR corpus, the previously published NCBI disease guidelines were re-used. The authors stated that “whenever possible, we will follow closely the guidelines of constructing NCBI disease corpus for annotating disease mentions” [].'},\n          {'@id': 'Par38',\n           'xref': [{'@ref-type': 'bibr', '@rid': 'CR2', '#text': '2'},\n            {'@rid': 'Sec11', '@ref-type': 'sec', '#text': '5.3'},\n            {'@ref-type': 'bibr', '@rid': 'CR2', '#text': '2'}],\n           '#text': 'The NCBI Disease corpus was released by the National Center for Biotechnology Information (NCBI) and is “fully annotated at the mention and concept level to serve as a research resource for the biomedical natural language processing community” []. It contains 739 PubMed abstracts with a total of 6,892 disease mentions, annotated by a total of 14 annotators. Two annotators were given the same data so that a double-annotation could be performed. The inter-annotator agreement was determined by means of the F1-score (see Section ) for each pair of annotators. The average F1-score amounts to 88% [].'},\n          {'@id': 'Par39',\n           'xref': [{'@ref-type': 'bibr', '@rid': 'CR3', '#text': '3'},\n            {'@ref-type': 'bibr', '@rid': 'CR22', '#text': '22'},\n            {'@ref-type': 'bibr', '@rid': 'CR3', '#text': '3'}],\n           '#text': 'The BioCreative V Chemical Disease Relation (BC5CDR) was released by the organization BioCreative. The BC5CDR corpus contains 1,500 abstracts including disease and chemical annotations at mention level as well as their interactions (relations). In total, the data set contains 12,848 disease mentions []. For the present work, only the corpus containing disease mentions is used. Here, the inter-annotator agreement has been determined by means of the Jaccard distance. The Jaccard index divides the overlap of both sets (annotations) by the number in either set []. To determine the Jaccard distance, the index needs to be subtracted from one. The inter-annotator agreement amounts to 87.49% [].'},\n          {'@id': 'Par40',\n           'xref': {'@rid': 'Tab5', '@ref-type': 'table', '#text': '5'},\n           'table-wrap': {'@id': 'Tab5',\n            'label': 'Table 5',\n            'caption': {'@xml:lang': 'en',\n             'p': 'Statistics of used disease entity recognition data sets'},\n            'table': {'@frame': 'hsides',\n             '@rules': 'groups',\n             'thead': {'tr': {'th': [{'@align': 'left'},\n                {'@align': 'left', 'p': 'Data set'},\n                {'@align': 'left', 'p': 'NCBI'},\n                {'@align': 'left', 'p': 'BC5CDR'},\n                {'@align': 'left', 'p': 'miRNA-disease'},\n                {'@align': 'left', 'p': 'COVID Disease'},\n                {'@align': 'left', 'p': 'BioNLP13-CG'}]}},\n             'tbody': {'tr': [{'td': [{'@align': 'left',\n                  'p': 'Size (# Abstracts)'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': '593'},\n                 {'@align': 'left', 'p': '500'},\n                 {'@align': 'left', 'p': '201'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '300'}]},\n               {'td': [{'@align': 'left', 'p': 'Unique mentions'},\n                 {'@align': 'left', 'p': 'training'},\n                 {'@align': 'left', 'p': '1614'},\n                 {'@align': 'left', 'p': '1445'},\n                 {'@align': 'left', 'p': '461'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '349'}]},\n               {'td': [{'@align': 'left', 'p': 'Unique concepts'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': '632'},\n                 {'@align': 'left', 'p': '649'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '-'}]},\n               {'td': [{'@align': 'left', 'p': 'Size (# Abstracts)'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': '100'},\n                 {'@align': 'left', 'p': '500'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '200'}]},\n               {'td': [{'@align': 'left', 'p': 'Unique mentions'},\n                 {'@align': 'left', 'p': 'development'},\n                 {'@align': 'left', 'p': '343'},\n                 {'@align': 'left', 'p': '1343'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '154'}]},\n               {'td': [{'@align': 'left', 'p': 'Unique concepts'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': '170'},\n                 {'@align': 'left', 'p': '589'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '-'}]},\n               {'td': [{'@align': 'left', 'p': 'Size (# Abstracts)'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': '100'},\n                 {'@align': 'left', 'p': '500'},\n                 {'@align': 'left', 'p': '100'},\n                 {'@align': 'left', 'p': '50'},\n                 {'@align': 'left', 'p': '100'}]},\n               {'td': [{'@align': 'left', 'p': 'Unique mentions'},\n                 {'@align': 'left', 'p': 'test'},\n                 {'@align': 'left', 'p': '407'},\n                 {'@align': 'left', 'p': '1432'},\n                 {'@align': 'left', 'p': '224'},\n                 {'@align': 'left', 'p': '68'},\n                 {'@align': 'left', 'p': '260'}]},\n               {'td': [{'@align': 'left', 'p': 'Unique concepts'},\n                 {'@align': 'left'},\n                 {'@align': 'left', 'p': '192'},\n                 {'@align': 'left', 'p': '640'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '-'},\n                 {'@align': 'left', 'p': '-'}]}]}}},\n           '#text': 'The NCBI training data set consists of 593 abstracts and the BC5CDR training data set consists of 500. In terms of unique mentions and concepts, they are also very similar. Whereas the NCBI training set contains 632 unique concepts, 649 can be found in the BC5CDR training set. In the test sets, huge differences can be found concerning the amount. The NCBI Disease test set only consists of 100 abstracts, the BC5CDR test set, however, consists of 500 abstracts as well. Therefore, the latter contains significantly more unique mentions and concepts. A detailed overview can be seen in Table .'},\n          {'@id': 'Par41',\n           'italic': 'scattertext',\n           'xref': {'@ref-type': 'bibr', '@rid': 'CR13', '#text': '13'},\n           '#text': 'In our work, we analyze and compare these data sets on different levels: on mention level, on concept level and based on the whole corpus. For the latter, we apply the tool  to visualize the linguistic variations []. In addition, we use the randomly generated PubMed corpus to perform a linguistic variation analysis between the annotated corpora and PubMed. This corpus was generated by randomly choosing 500 abstracts from all PubMed abstracts with a publication date between 1990 and 2021 (a total of 23,631,092 articles).'},\n          {'@id': 'Par42',\n           'xref': [{'@ref-type': 'bibr', '@rid': 'CR6', '#text': '6'},\n            {'@ref-type': 'bibr', '@rid': 'CR7', '#text': '7'},\n            {'@ref-type': 'bibr', '@rid': 'CR12', '#text': '12'}],\n           '#text': 'As three further, related data sets, we use the miRNA-disease corpus [], the BioNLP13-CG corpus [] and the COVID Disease corpus []. The miRNA-disease data set is split into training and test set. The training set consists of 200 abstracts, the test set consists of 100. The training set contains a total of 461 unique disease mentions, whereas the test set contains 224. In contrast to the NCBI and BC5CDR corpora, for this corpus, different, more simplified annotation guidelines were released that for example restrict the annotation to nouns. The BioNLP13-CG corpus consists of a total of 600 abstracts, split into training, development and test set. The test set contains 260 unique mentions. The COVID Disease data set is the smallest, consisting of 50 annotated abstracts. It has been developed as an independent test set for disease named entity models for COVID-19 related articles. Due its focus on COVID-19, it only contains 68 unique mentions.'}]},\n        {'@id': 'Sec10',\n         'title': 'NER Algorithms',\n         'p': [{'@id': 'Par43',\n           '#text': 'We investigated six different publicly available algorithms for disease named entity recognition in this work, that will be described in the following. Whereas we trained BioBERT and HUNER in this study, we applied the other algorithms “as is”. We provide an overview about the sources in the Availability Section. The applied algorithms will be described in the following.'},\n          {'@id': 'Par44',\n           'xref': [{'@ref-type': 'bibr', '@rid': 'CR11', '#text': '11'},\n            {'@ref-type': 'bibr', '@rid': 'CR10', '#text': '10'},\n            {'@ref-type': 'bibr', '@rid': 'CR11', '#text': '11'},\n            {'@ref-type': 'bibr', '@rid': 'CR23', '#text': '23'},\n            {'@rid': 'Tab6', '@ref-type': 'table', '#text': '6'},\n            {'@rid': 'Tab6', '@ref-type': 'table', '#text': '6'}],\n           'italic': ['BioBERT-Base v1.0 (+ PubMed 200K + PMC 270K)',\n            'et al.',\n            'Transformers'],\n           'table-wrap': {'@id': 'Tab6',\n            'label': 'Table 6',\n            'caption': {'@xml:lang': 'en',\n             'p': 'Hyperparameters used for fine-tuning BioBERT'},\n            'table': {'@frame': 'hsides',\n             '@rules': 'groups',\n             'thead': {'tr': {'th': [{'@align': 'left', 'p': 'Corpus'},\n                {'@align': 'left', 'p': 'Batch size'},\n                {'@align': 'left', 'p': 'Learning rate'},\n                {'@align': 'left', 'p': '# of epochs'}]}},\n             'tbody': {'tr': [{'td': [{'@align': 'left', 'p': 'NCBI'},\n                 {'@align': 'left', 'p': '32'},\n                 {'@align': 'left', 'p': '5e-5'},\n                 {'@align': 'left', 'p': '7'}]},\n               {'td': [{'@align': 'left', 'p': 'BC5CDR'},\n                 {'@align': 'left', 'p': '32'},\n                 {'@align': 'left', 'p': '3e-5'},\n                 {'@align': 'left', 'p': '4'}]},\n               {'td': [{'@align': 'left', 'p': 'NCBI + BC5CDR'},\n                 {'@align': 'left', 'p': '32'},\n                 {'@align': 'left', 'p': '5e-5'},\n                 {'@align': 'left', 'p': '4'}]},\n               {'td': [{'@align': 'left', 'p': 'BioNL13-CG'},\n                 {'@align': 'left', 'p': '32'},\n                 {'@align': 'left', 'p': '5e-5'},\n                 {'@align': 'left', 'p': '3'}]},\n               {'td': [{'@align': 'left', 'p': 'miRNA-Disease'},\n                 {'@align': 'left', 'p': '32'},\n                 {'@align': 'left', 'p': '5e-5'},\n                 {'@align': 'left', 'p': '3'}]}]}}},\n           '#text': 'BioBERT [] is based on Bidirectional Encoder Representations from Transformers (BERT) []. As pre-trained model, we used  published by Lee  []. For fine-tuning, we used the library  [] and pytorch. In total, we trained five different models. First, we used the NCBI and BC5CDR training corpora and trained them both individually and on the combination on them. For the latter setting, the batches were shuffled randomly to avoid a higher influence of one data set over the other. The training parameters, investigated via cross-validation, can be seen in Table . Additionally, we used default parameters to train two further models on the miRNA-disease and BioNLP13-CG corpora (see also Table\\xa0).'},\n          {'@id': 'Par45',\n           'xref': {'@ref-type': 'bibr', '@rid': 'CR24', '#text': '24'},\n           '#text': 'scipaCy is based on the python library spaCy [] that includes tools for text processing in several different languages. The text processing steps include for example sentence detection, tokenization, POS tagging or NER. Therefore, a convolutional neural network is used. scispaCy is trained on top of spacy for POS tagging, dependency parsing and NER using biomedical training data. The authors provide a model trained on the BC5CDR corpus to recognize diseases and chemicals. We used this model and filtered out the chemical annotations.'},\n          {'@id': 'Par46',\n           'xref': [{'@ref-type': 'bibr', '@rid': 'CR25', '#text': '25'},\n            {'@ref-type': 'bibr', '@rid': 'CR26', '#text': '26'}],\n           '#text': 'DNorm is a disease recognition and normalization tool []. It is a serial algorithm which uses first the entity recognition tool BANNER [] based on conditional random fields (CRFs) which is followed by an abbreviation detection tool and a normalizer. Normalization is learned following a pairwise learning to rank approach. We apply the provided model trained on the NCBI Disease corpus.'},\n          {'@id': 'Par47',\n           'xref': {'@ref-type': 'bibr', '@rid': 'CR27', '#text': '27'},\n           '#text': 'TaggerOne is a joint named entity recognition and normalization model consisting of “a semi-Markov structured linear classifier, with a rich feature approach for NER and supervised semantic indexing for normalization” []. The authors provide three different models: one trained on the NCBI Disease corpus, one trained on the BC5CDR Disease corpus and one trained on both of them simultaneously.'},\n          {'@id': 'Par48',\n           'xref': [{'@ref-type': 'bibr', '@rid': 'CR28', '#text': '28'},\n            {'@ref-type': 'bibr', '@rid': 'CR29', '#text': '29'}],\n           'italic': 'et al.',\n           '#text': 'Stanza is a python package that allows the building of machine learning-based NLP pipelines (including for example tokenizers or POS-tagger but also NER modules) for 70 different languages []. Zhang  published biomedical and clinical English model packages []. Optimized models for both the NCBI and the BC5CDR corpus exist and are used in this study.'},\n          {'@id': 'Par49',\n           'italic': ['et al.', 'disease-all'],\n           'xref': {'@ref-type': 'bibr', '@rid': 'CR30', '#text': '30'},\n           'ext-link': {'@xlink:href': 'https://github.com/hu-ner/huner',\n            '@ext-link-type': 'uri',\n            '#text': 'https://github.com/hu-ner/huner'},\n           '#text': 'HUNER, developed by Weber , makes use of an LSTM-CRF-based architecture that is pre-trained in an semi-supervised manner and afterwards fine-tuned on a specific corpus/entity class []. To apply HUNER for our use-case, we downloaded the  model and fine-tuned it on both the NCBI and the BC5CDR corpus, following the instructions of the authors ().'},\n          {'@id': 'Par50',\n           'xref': {'@rid': 'Tab1', '@ref-type': 'table', '#text': '1'},\n           '#text': 'An overview about all available and/or trained models can be seen in Table .'}]},\n        {'@id': 'Sec11',\n         'title': 'Evaluation Metrics',\n         'p': {'@id': 'Par51',\n          'ext-link': {'@xlink:href': 'https://github.com/sighsmile/conlleval',\n           '@ext-link-type': 'uri',\n           '#text': 'https://github.com/sighsmile/conlleval'},\n          'italic': ['B', 'I', 'O'],\n          'disp-formula': [{'@id': 'Equ1',\n            'label': '1',\n            'alternatives': {'mml:math': {'@display': 'block',\n              '@id': 'Equ1_Math',\n              'mml:mrow': {'mml:mtable': {'mml:mtr': {'mml:mtd': {'@columnalign': 'right',\n                  'mml:mrow': {'mml:mi': ['p',\n                    'r',\n                    'e',\n                    'c',\n                    'i',\n                    's',\n                    'i',\n                    'o',\n                    'n'],\n                   'mml:mo': '=',\n                   'mml:mfrac': {'mml:mrow': [{'mml:mi': {'@mathvariant': 'italic',\n                       '#text': 'TP'}},\n                     {'mml:mi': ['T', 'P', 'F', 'N'], 'mml:mo': '+'}]}}}}}}},\n             'tex-math': {'@id': 'Equ1_TeX',\n              '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\begin{aligned} precision = \\\\frac{TP}{TP + FN} \\\\end{aligned}$$\\\\end{document}'},\n             'graphic': {'@position': 'anchor',\n              '@xlink:href': '13326_2022_280_Article_Equ1.gif'}}},\n           {'@id': 'Equ2',\n            'label': '2',\n            'alternatives': {'mml:math': {'@display': 'block',\n              '@id': 'Equ2_Math',\n              'mml:mrow': {'mml:mtable': {'mml:mtr': {'mml:mtd': {'@columnalign': 'right',\n                  'mml:mrow': {'mml:mi': ['r', 'e', 'c', 'a', 'l', 'l'],\n                   'mml:mo': '=',\n                   'mml:mfrac': {'mml:mrow': [{'mml:mi': {'@mathvariant': 'italic',\n                       '#text': 'TP'}},\n                     {'mml:mi': ['T', 'P', 'F', 'P'], 'mml:mo': '+'}]}}}}}}},\n             'tex-math': {'@id': 'Equ2_TeX',\n              '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\begin{aligned} recall = \\\\frac{TP}{TP + FP} \\\\end{aligned}$$\\\\end{document}'},\n             'graphic': {'@position': 'anchor',\n              '@xlink:href': '13326_2022_280_Article_Equ2.gif'}}},\n           {'@id': 'Equ3',\n            'label': '3',\n            'alternatives': {'mml:math': {'@display': 'block',\n              '@id': 'Equ3_Math',\n              'mml:mrow': {'mml:mtable': {'mml:mtr': {'mml:mtd': {'@columnalign': 'right',\n                  'mml:mrow': {'mml:mi': ['F', 's', 'c', 'o', 'r', 'e'],\n                   'mml:mn': ['1', '2'],\n                   'mml:mo': ['-', '=', '∗'],\n                   'mml:mrow': None,\n                   'mml:mfrac': {'mml:mrow': [{'mml:mi': ['p',\n                       'r',\n                       'e',\n                       'c',\n                       'i',\n                       's',\n                       'i',\n                       'o',\n                       'n',\n                       'r',\n                       'e',\n                       'c',\n                       'a',\n                       'l',\n                       'l'],\n                      'mml:mrow': None,\n                      'mml:mo': '∗'},\n                     {'mml:mi': ['p',\n                       'r',\n                       'e',\n                       'c',\n                       'i',\n                       's',\n                       'i',\n                       'o',\n                       'n',\n                       'r',\n                       'e',\n                       'c',\n                       'a',\n                       'l',\n                       'l'],\n                      'mml:mo': '+'}]}}}}}}},\n             'tex-math': {'@id': 'Equ3_TeX',\n              '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\begin{aligned} F1-score = 2 * \\\\frac{precision * recall}{precision + recall} \\\\end{aligned}$$\\\\end{document}'},\n             'graphic': {'@position': 'anchor',\n              '@xlink:href': '13326_2022_280_Article_Equ3.gif'}}}],\n          '#text': 'We determine precision, recall and F1-score to evaluate the models. The equations are given below, where FP stands for false positive, FN for false negative and TP for true positive. To ensure consistency, we use a publicly available evaluation script (CoNLLEval script) that has been released by the Conference on Computational Natural Language Learning (CoNLL) together with a shared task. The script is available under . This requires the input data to be in the “IOB”-format where each token is labeled as  for beginning,  for inside or  for outside. Evaluation is only done on entity, not on concept level and we only take exact matches into account.'}}]}]},\n    'back': {'ack': {'title': 'Acknowledgements', 'p': 'Not applicable.'},\n     'sec': [{'@sec-type': 'author-contribution',\n       'title': 'Authors’ contributions',\n       'p': 'LL and JF both contributed to the conceptional ideas of this work. LL performed all experiments and is the primary author of the manuscript. JF participated in drafting and revising the manuscript, and both authors read and approved the final manuscript.'},\n      {'title': 'Funding',\n       'p': 'Open Access funding enabled and organized by Projekt DEAL.'},\n      {'@sec-type': 'data-availability',\n       'title': 'Availability of data and materials',\n       'p': [{'ext-link': [{'@xlink:href': 'https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/',\n           '@ext-link-type': 'uri',\n           '#text': 'https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/'},\n          {'@xlink:href': 'https://biocreative.bioinformatics.udel.edu/tasks/biocreative-v/track-3-cdr/',\n           '@ext-link-type': 'uri',\n           '#text': 'https://biocreative.bioinformatics.udel.edu/tasks/biocreative-v/track-3-cdr/'},\n          {'@xlink:href': 'https://www.scai.fraunhofer.de/en/business-research-areas/bioinformatics/downloads/download-mirna-test-corpus.html',\n           '@ext-link-type': 'uri',\n           '#text': 'https://www.scai.fraunhofer.de/en/business-research-areas/bioinformatics/downloads/download-mirna-test-corpus.html'},\n          {'@xlink:href': 'https://github.com/cambridgeltl/MTL-Bioinformatics-2016/tree/master/data',\n           '@ext-link-type': 'uri',\n           '#text': 'https://github.com/cambridgeltl/MTL-Bioinformatics-2016/tree/master/data'},\n          {'@xlink:href': 'https://github.com/zbmed/preVIEW-COVID19/tree/main/data',\n           '@ext-link-type': 'uri',\n           '#text': 'https://github.com/zbmed/preVIEW-COVID19/tree/main/data'}],\n         '#text': 'The NCBI Disease corpus and the BC5CDR corpus are both publicly available under  and , respectively. The miRNA-disease corpus has been downloaded from . We retrieved the BioNLP13-CG corpus from  and the COVID Disease corpus is available under .'},\n        'The used algorithms are publicly available under:',\n        {'inline-formula': {'@id': 'IEq15',\n          'alternatives': {'mml:math': {'@id': 'IEq15_Math', 'mml:mo': '∙'},\n           'tex-math': {'@id': 'IEq15_TeX',\n            '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\bullet$$\\\\end{document}'},\n           'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq15.gif'}}},\n         'ext-link': {'@xlink:href': 'https://github.com/naver/biobert-pretrained',\n          '@ext-link-type': 'uri',\n          '#text': 'https://github.com/naver/biobert-pretrained'},\n         '#text': 'BioBERT pre-trained models:'},\n        {'inline-formula': {'@id': 'IEq16',\n          'alternatives': {'mml:math': {'@id': 'IEq16_Math', 'mml:mo': '∙'},\n           'tex-math': {'@id': 'IEq16_TeX',\n            '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\bullet$$\\\\end{document}'},\n           'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq16.gif'}}},\n         'ext-link': {'@xlink:href': 'https://github.com/huggingface/transformers',\n          '@ext-link-type': 'uri',\n          '#text': 'https://github.com/huggingface/transformers'},\n         '#text': 'Transformers library to fine-tune BioBERT:'},\n        {'inline-formula': {'@id': 'IEq17',\n          'alternatives': {'mml:math': {'@id': 'IEq17_Math', 'mml:mo': '∙'},\n           'tex-math': {'@id': 'IEq17_TeX',\n            '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\bullet$$\\\\end{document}'},\n           'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq17.gif'}}},\n         'ext-link': {'@xlink:href': 'https://allenai.github.io/scispacy/',\n          '@ext-link-type': 'uri',\n          '#text': 'https://allenai.github.io/scispacy/'},\n         '#text': 'scispaCy library:'},\n        {'inline-formula': {'@id': 'IEq18',\n          'alternatives': {'mml:math': {'@id': 'IEq18_Math', 'mml:mo': '∙'},\n           'tex-math': {'@id': 'IEq18_TeX',\n            '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\bullet$$\\\\end{document}'},\n           'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq18.gif'}}},\n         'ext-link': {'@xlink:href': 'https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/dnorm/',\n          '@ext-link-type': 'uri',\n          '#text': 'https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/dnorm/'},\n         '#text': 'DNorm:'},\n        {'inline-formula': {'@id': 'IEq19',\n          'alternatives': {'mml:math': {'@id': 'IEq19_Math', 'mml:mo': '∙'},\n           'tex-math': {'@id': 'IEq19_TeX',\n            '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\bullet$$\\\\end{document}'},\n           'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq19.gif'}}},\n         'ext-link': {'@xlink:href': 'https://www.ncbi.nlm.nih.gov/research/bionlp/tools/taggerone/',\n          '@ext-link-type': 'uri',\n          '#text': 'https://www.ncbi.nlm.nih.gov/research/bionlp/tools/taggerone/'},\n         '#text': 'TaggerOne:'},\n        {'inline-formula': {'@id': 'IEq20',\n          'alternatives': {'mml:math': {'@id': 'IEq20_Math', 'mml:mo': '∙'},\n           'tex-math': {'@id': 'IEq20_TeX',\n            '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\bullet$$\\\\end{document}'},\n           'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq20.gif'}}},\n         'ext-link': {'@xlink:href': 'https://stanfordnlp.github.io/stanza/biomed.html',\n          '@ext-link-type': 'uri',\n          '#text': 'https://stanfordnlp.github.io/stanza/biomed.html'},\n         '#text': 'Stanza:'},\n        {'inline-formula': {'@id': 'IEq21',\n          'alternatives': {'mml:math': {'@id': 'IEq21_Math', 'mml:mo': '∙'},\n           'tex-math': {'@id': 'IEq21_TeX',\n            '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\bullet$$\\\\end{document}'},\n           'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq21.gif'}}},\n         'ext-link': {'@xlink:href': 'https://github.com/hu-ner/huner',\n          '@ext-link-type': 'uri',\n          '#text': 'https://github.com/hu-ner/huner'},\n         '#text': 'HUNER:'},\n        {'inline-formula': {'@id': 'IEq22',\n          'alternatives': {'mml:math': {'@id': 'IEq22_Math', 'mml:mo': '∙'},\n           'tex-math': {'@id': 'IEq22_TeX',\n            '#text': '\\\\documentclass[12pt]{minimal}\\n\\t\\t\\t\\t\\\\usepackage{amsmath}\\n\\t\\t\\t\\t\\\\usepackage{wasysym}\\n\\t\\t\\t\\t\\\\usepackage{amsfonts}\\n\\t\\t\\t\\t\\\\usepackage{amssymb}\\n\\t\\t\\t\\t\\\\usepackage{amsbsy}\\n\\t\\t\\t\\t\\\\usepackage{mathrsfs}\\n\\t\\t\\t\\t\\\\usepackage{upgreek}\\n\\t\\t\\t\\t\\\\setlength{\\\\oddsidemargin}{-69pt}\\n\\t\\t\\t\\t\\\\begin{document}$$\\\\bullet$$\\\\end{document}'},\n           'inline-graphic': {'@xlink:href': '13326_2022_280_Article_IEq22.gif'}}},\n         'ext-link': {'@xlink:href': 'https://github.com/sighsmile/conlleval',\n          '@ext-link-type': 'uri',\n          '#text': 'https://github.com/sighsmile/conlleval'},\n         '#text': 'Evaluation script:'}]},\n      {'@sec-type': 'ethics-statement',\n       'title': 'Declarations',\n       'sec': [{'@id': 'FPar1',\n         'title': 'Ethics approval and consent to participate',\n         'p': {'@id': 'Par52', '#text': 'Not applicable.'}},\n        {'@id': 'FPar2',\n         'title': 'Consent for publication',\n         'p': {'@id': 'Par53', '#text': 'Not applicable.'}},\n        {'@id': 'FPar3',\n         '@sec-type': 'COI-statement',\n         'title': 'Competing interests',\n         'p': {'@id': 'Par54',\n          '#text': 'The authors declare that they have no competing interests.'}}]}],\n     'ref-list': {'@id': 'Bib1',\n      'title': 'References',\n      'ref-list': {'ref': [{'@id': 'CR1',\n         'label': '1.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://n2c2.dbmi.hms.harvard.edu/',\n           '@ext-link-type': 'uri',\n           '#text': 'https://n2c2.dbmi.hms.harvard.edu/'},\n          '#text': 'School HM. N2C2: National NLP Clinical Challenges. . Accessed 20 June 2021.'}},\n        {'@id': 'CR2',\n         'label': '2.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/',\n           '@ext-link-type': 'uri',\n           '#text': 'https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/'},\n          '#text': 'Doğan RI, Leaman R, Lu Z. The NCBI Disease Corpus. . Accessed 11 July 2021.'}},\n        {'@id': 'CR3',\n         'label': '3.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': '10.1093/database/baw068',\n           '@ext-link-type': 'doi',\n           '#text': 'https://doi.org/10.1093/database/baw068'},\n          '#text': 'Li J, Sun Y, Johnson RJ, Sciaky D, Wei C-H, Leaman R, Davis AP, Mattingly CJ, Wiegers TC, Lu Z. BioCreative v CDR task corpus: a resource for chemical disease relation extraction. 2016. . Accessed 11 July 2021.'}},\n        {'@id': 'CR4',\n         'label': '4.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/Guidelines.html',\n           '@ext-link-type': 'uri',\n           '#text': 'https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/Guidelines.html'},\n          '#text': 'The NCBI Disease Corpus Guidelines. . Accessed 12 July 2021.'}},\n        {'@id': 'CR5',\n         'label': '5.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://biocreative.bioinformatics.udel.edu/media/store/files/2015/bc5_CDR_data_guidelines.pdf',\n           '@ext-link-type': 'uri',\n           '#text': 'https://biocreative.bioinformatics.udel.edu/media/store/files/2015/bc5_CDR_data_guidelines.pdf'},\n          '#text': 'The BC5CDR Corpus Guidelines. . Accessed 12 July 2021.'}},\n        {'@id': 'CR6',\n         'label': '6.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': '10.12688/f1000research.4591.3',\n           '@ext-link-type': 'doi',\n           '#text': 'https://doi.org/10.12688/f1000research.4591.3'},\n          '#text': 'Bagewadi S, Bobić T, Hofmann-Apitius M, Fluck J, Klinger R. Detecting miRNA mentions and relations in biomedical literature. 3:205. . Accessed 13 June 2022.'}},\n        {'@id': 'CR7',\n         'label': '7.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://aclanthology.org/W13-2008',\n           '@ext-link-type': 'uri',\n           '#text': 'https://aclanthology.org/W13-2008'},\n          '#text': 'Pyysalo S, Ohta T, Ananiadou S. Overview of the cancer genetics (CG) task of BioNLP shared task 2013. In: Proceedings of the BioNLP Shared Task 2013 Workshop. Sofia: Association for Computational Linguistics; 2013. p. 58–66.'}},\n        {'@id': 'CR8',\n         'label': '8.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': [{'@xlink:href': '10.3233/SHTI210124',\n            '@ext-link-type': 'doi',\n            '#text': 'https://doi.org/10.3233/SHTI210124'},\n           {'@xlink:href': 'https://ebooks.iospress.nl/doi/10.3233/SHTI210124',\n            '@ext-link-type': 'uri',\n            '#text': 'https://ebooks.iospress.nl/doi/10.3233/SHTI210124'}],\n          '#text': 'Langnickel L, Baum R, Darms J, Madan S, Fluck J. COVID-19 preVIEW: Semantic search to explore COVID-19 research preprints. In: Studies in Health Technology and Informatics. IOS Press. . . Accessed 31 May 2021.'}},\n        {'@id': 'CR9',\n         'label': '9.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://www.aclweb.org/anthology/C18-1182/',\n           '@ext-link-type': 'uri',\n           '#text': 'https://www.aclweb.org/anthology/C18-1182/'},\n          '#text': 'Yadav V, Bethard S. A survey on recent advances in named entity recognition from deep learning models. p. 2145–2158. . Accessed 29 May 2021.'}},\n        {'@id': 'CR10',\n         'label': '10.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://arxiv.org/abs/1810.04805',\n           '@ext-link-type': 'uri',\n           '#text': '1810.04805'},\n          '#text': 'Devlin J, Chang M-W, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional transformers for language understanding. . Accessed 23 Apr 2019.'}},\n        {'@id': 'CR11',\n         'label': '11.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://arxiv.org/abs/1901.08746',\n           '@ext-link-type': 'uri',\n           '#text': '1901.08746'},\n          '#text': 'Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, Kang J. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. . Accessed 23 Apr 2019.'}},\n        {'@id': 'CR12',\n         'label': '12.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': '10.32384/jeahil17484',\n           '@ext-link-type': 'doi',\n           '#text': 'https://doi.org/10.32384/jeahil17484'},\n          '#text': 'Langnickel L, Darms J, Baum R, Fluck J. preVIEW: from a fast prototype towards a sustainable semantic search system for central access to COVID-19 preprints. J EAHIL. 8–14. . Accessed 05 Oct 2021.'}},\n        {'@id': 'CR13',\n         'label': '13.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': '10.48550/ARXIV.1703.00565',\n           '@ext-link-type': 'doi',\n           '#text': 'https://doi.org/10.48550/ARXIV.1703.00565'},\n          '#text': 'Kessler JS. Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ (Version 3). arXiv. 2017. .'}},\n        {'@id': 'CR14',\n         'label': '14.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://arxiv.org/abs/1903.10676',\n           '@ext-link-type': 'uri',\n           '#text': '1903.10676'},\n          '#text': 'Beltagy I, Cohan A, Lo K. SciBERT: Pretrained contextualized embeddings for scientific text. . Accessed 23 Apr 2019.'}},\n        {'@id': 'CR15',\n         'label': '15.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': [{'@xlink:href': '10.18653/v1/W19-1909',\n            '@ext-link-type': 'doi',\n            '#text': 'https://doi.org/10.18653/v1/W19-1909'},\n           {'@xlink:href': 'https://www.aclweb.org/anthology/W19-1909',\n            '@ext-link-type': 'uri',\n            '#text': 'https://www.aclweb.org/anthology/W19-1909'}],\n          '#text': 'Alsentzer E, Murphy J, Boag W, Weng W-H, Jin D, Naumann T, McDermott M. Publicly available clinical BERT embeddings. In: Proceedings of the 2nd Clinical Natural Language Processing Workshop. Minneapolis: Association for Computational Linguistics; 2019. p. 72–78. . .'}},\n        {'@id': 'CR16',\n         'label': '16.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': '10.18653/v1/2020.aclmain.740',\n           '@ext-link-type': 'doi',\n           '#text': 'https://doi.org/10.18653/v1/2020.aclmain.740'},\n          '#text': 'Gururangan S, Marasović A, Swayamdipta S, Lo K, Beltagy I, Downey D, Smith NA. Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics. 2020. .'}},\n        {'@id': 'CR17',\n         'label': '17.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': '10.1093/database/bat080',\n           '@ext-link-type': 'doi',\n           '#text': 'https://doi.org/10.1093/database/bat080'},\n          '#text': 'Davis AP, Wiegers TC, Roberts PM, King BL, Lay JM, Lennon-Hopkins K, Sciaky D, Johnson R, Keating H, Greene N, Hernandez R, McConnell KJ, Enayetallah AE, Mattingly CJ. A CTD-pfizer collaboration: manual curation of 88,000 scientific articles text mined for drug-disease and drug-phenotype interactions. 2013;080. .'}},\n        {'@id': 'CR18',\n         'label': '18.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': [{'@xlink:href': '10.1016/S0079-7421(08)60536-8',\n            '@ext-link-type': 'doi',\n            '#text': 'https://doi.org/10.1016/S0079-7421(08)60536-8'},\n           {'@xlink:href': 'https://www.sciencedirect.com/science/article/pii/S0079742108605368',\n            '@ext-link-type': 'uri',\n            '#text': 'https://www.sciencedirect.com/science/article/pii/S0079742108605368'}],\n          '#text': 'McCloskey M, Cohen NJ. Catastrophic interference in connectionist networks: The sequential learning problem. In: Bower GH, editors. Psychology of Learning and Motivation vol. 24. Academic Press. p. 109–165. . . Accessed 12 Apr 2021.'}},\n        {'@id': 'CR19',\n         'label': '19.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://arxiv.org/abs/1902.00751',\n           '@ext-link-type': 'uri',\n           '#text': '1902.00751'},\n          '#text': 'Houlsby N, Giurgiu A, Jastrzebski S, Morrone B, de Laroussilhe Q, Gesmundo A, Attariyan M, Gelly S. Parameter-efficient transfer learning for NLP. . Accessed 12 Apr 2021.'}},\n        {'@id': 'CR20',\n         'label': '20.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://arxiv.org/abs/2005.00247',\n           '@ext-link-type': 'uri',\n           '#text': '2005.00247'},\n          '#text': 'Pfeiffer J, Kamath A, Rücklé A, Cho K, Gurevych I. AdapterFusion: Non-destructive task composition for transfer learning. . Accessed 12 Apr 2021.'}},\n        {'@id': 'CR21',\n         'label': '21.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://biocreative.bioinformatics.udel.edu/tasks/biocreative-v/track-3-cdr/',\n           '@ext-link-type': 'uri',\n           '#text': 'https://biocreative.bioinformatics.udel.edu/tasks/biocreative-v/track-3-cdr/'},\n          '#text': 'Li J, Sun Y, Johnson RJ, Sciaky D, Wei C-H, Leaman R, Davis AP, Mattingly CJ, Wiegers TC, Lu Z. BioCreative - Track 3- CDR. . Accessed 20 Apr 2021.'}},\n        {'@id': 'CR22',\n         'label': '22.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://deepai.org/machine-learning-glossary-and-terms/jaccard-index',\n           '@ext-link-type': 'uri',\n           '#text': 'https://deepai.org/machine-learning-glossary-and-terms/jaccard-index'},\n          '#text': 'DeepAI. Jaccard Index. . Accessed 11 Apr 2021.'}},\n        {'@id': 'CR23',\n         'label': '23.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://www.aclweb.org/anthology/2020.emnlp-demos.6',\n           '@ext-link-type': 'uri',\n           '#text': 'https://www.aclweb.org/anthology/2020.emnlp-demos.6'},\n          '#text': 'Wolf T, Debut L, Sanh V, Chaumond J, Delangue C, Moi A, Cistac P, Rault T, Louf R, Funtowicz M, Davison J, Shleifer S, von Platen P, Ma C, Jernite Y, Plu J, Xu C, Scao TL, Gugger S, Drame M, Lhoest Q, Rush AM. Transformers: State-of-the-art natural language processing. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Online: Association for Computational Linguistics; 2020. p. 38–45. .'}},\n        {'@id': 'CR24',\n         'label': '24.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': [{'@xlink:href': '10.5281/zenodo.1212303',\n            '@ext-link-type': 'doi',\n            '#text': 'https://doi.org/10.5281/zenodo.1212303'},\n           {'@xlink:href': 'https://doi.org/10.5281/zenodo.1212303',\n            '@ext-link-type': 'uri',\n            '#text': 'https://doi.org/10.5281/zenodo.1212303'}],\n          '#text': 'Honnibal M, Montani I, Van\\xa0Landeghem S, Boyd A. spaCy: Industrial-strength Natural Language Processing in Python. . .'}},\n        {'@id': 'CR25',\n         'label': '25.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': '10.1093/bioinformatics/btt474',\n           '@ext-link-type': 'doi',\n           '#text': 'https://doi.org/10.1093/bioinformatics/btt474'},\n          '#text': 'Leaman R, Islamaj\\xa0Dogan R, Lu Z. DNorm: disease name normalization with pairwise learning to rank. 29(22):2909–2917. .'}},\n        {'@id': 'CR26',\n         'label': '26.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': [{'@xlink:href': 'https://pubmed.ncbi.nlm.nih.gov/18229723/',\n            '@ext-link-type': 'uri',\n            '#text': 'https://pubmed.ncbi.nlm.nih.gov/18229723/'},\n           {'@xlink:href': 'http://psb.stanford.edu/psb-online/proceedings/psb08/abstracts/2008_p652.html',\n            '@ext-link-type': 'uri',\n            '#text': 'http://psb.stanford.edu/psb-online/proceedings/psb08/abstracts/2008_p652.html'}],\n          '#text': 'Leaman R, Gonzalez G. BANNER: an executable survey of advances in biomedical named entity recognition. Biocomputing. 2008:652–63.\\xa0,\\xa0.'}},\n        {'@id': 'CR27',\n         'label': '27.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': [{'@xlink:href': '10.1093/bioinformatics/btw343',\n            '@ext-link-type': 'doi',\n            '#text': 'https://doi.org/10.1093/bioinformatics/btw343'},\n           {'@xlink:href': 'https://academic.oup.com/bioinformatics/article-pdf/32/18/2839/24406872/btw343.pdf',\n            '@ext-link-type': 'uri',\n            '#text': 'https://academic.oup.com/bioinformatics/article-pdf/32/18/2839/24406872/btw343.pdf'}],\n          '#text': 'Leaman R, Lu Z. TaggerOne: joint named entity recognition and normalization with semi-Markov Models. Bioinformatics. 2016;32(18):2839–46. .'}},\n        {'@id': 'CR28',\n         'label': '28.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': 'https://nlp.stanford.edu/pubs/qi2020stanza.pdf',\n           '@ext-link-type': 'uri',\n           '#text': 'https://nlp.stanford.edu/pubs/qi2020stanza.pdf'},\n          '#text': 'Qi P, Zhang Y, Zhang Y, Bolton J, Manning CD. Stanza: A Python natural language processing toolkit for many human languages. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. 2020. . Accessed 28 June 2022.'}},\n        {'@id': 'CR29',\n         'label': '29.',\n         'mixed-citation': {'@publication-type': 'other',\n          'ext-link': {'@xlink:href': '10.1093/jamia/ocab090',\n           '@ext-link-type': 'doi',\n           '#text': 'https://doi.org/10.1093/jamia/ocab090'},\n          '#text': 'Zhang Y, Zhang Y, Qi P, Manning CD, Langlotz CP. Biomedical and clinical english model packages for the stanza python NLP library. 2022;28(9):1892–9. . Accessed 24 June 2022.'}},\n        {'@id': 'CR30',\n         'label': '30.',\n         'mixed-citation': {'@publication-type': 'other',\n          '#text': 'Weber L, Münchmeyer J, Rocktäschel T, Habibi M, Leser U. Huner: Improving biomedical ner with pretraining. Bioinformatics. 2020;36(1):295–302.'}}]}},\n     'glossary': {'title': 'Abbreviations',\n      'def-list': {'def-item': [{'term': 'BC5CDR',\n         'def': {'p': {'@id': 'Par4',\n           '#text': 'BioCreative V Chemical Disease Relation Task'}}},\n        {'term': 'BERT',\n         'def': {'p': {'@id': 'Par5',\n           '#text': 'Bidirectional Encoder Representations from Transformers'}}},\n        {'term': 'CoNLL',\n         'def': {'p': {'@id': 'Par6',\n           '#text': 'Conference on Computational Natural Language Learning'}}},\n        {'term': 'FN',\n         'def': {'p': {'@id': 'Par7', '#text': 'False negative'}}},\n        {'term': 'FP',\n         'def': {'p': {'@id': 'Par8', '#text': 'False positive'}}},\n        {'term': 'ML',\n         'def': {'p': {'@id': 'Par9', '#text': 'Machine Learning'}}},\n        {'term': 'NCBI',\n         'def': {'p': {'@id': 'Par10',\n           '#text': 'National Center for Biotechnology Information'}}},\n        {'term': 'NER',\n         'def': {'p': {'@id': 'Par11', '#text': 'Named Entity Recognition'}}},\n        {'term': 'NLP',\n         'def': {'p': {'@id': 'Par12',\n           '#text': 'National Language Processing'}}},\n        {'term': 'POS',\n         'def': {'p': {'@id': 'Par13', '#text': 'Part-of-speech'}}},\n        {'term': 'TP',\n         'def': {'p': {'@id': 'Par14', '#text': 'True positive'}}}]}},\n     'fn-group': {'fn': {'@id': 'Fn1',\n       'label': '1',\n       'p': {'@id': 'Par55',\n        'ext-link': {'@xlink:href': 'https://github.com/zbmed/preVIEW-COVID19/',\n         '@ext-link-type': 'uri',\n         '#text': 'https://github.com/zbmed/preVIEW-COVID19/'},\n        '#text': 'The script is available under'}}},\n     'notes': {'@notes-type': 'Misc',\n      'title': 'Publisher’s Note',\n      'p': 'Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.'}}}},\n  'facets': {'facet': [{'@name': 'subject',\n     'facet-value': [{'@count': '1', '#text': 'Algorithms'},\n      {'@count': '1', '#text': 'Bioinformatics'},\n      {'@count': '1', '#text': 'Combinatorial Libraries'},\n      {'@count': '1', '#text': 'Computational Biology/Bioinformatics'},\n      {'@count': '1', '#text': 'Computer Appl. in Life Sciences'},\n      {'@count': '1', '#text': 'Data Mining and Knowledge Discovery'},\n      {'@count': '1', '#text': 'Mathematics'}]},\n    {'@name': 'keyword',\n     'facet-value': [{'@count': '1', '#text': 'BERT'},\n      {'@count': '1', '#text': 'bioNLP'},\n      {'@count': '1', '#text': 'Manual Curation'},\n      {'@count': '1', '#text': 'Text mining'}]},\n    {'@name': 'pub',\n     'facet-value': {'@count': '1',\n      '#text': 'Journal of Biomedical Semantics'}},\n    {'@name': 'year', 'facet-value': {'@count': '1', '#text': '2022'}},\n    {'@name': 'country', 'facet-value': {'@count': '1', '#text': 'Germany'}},\n    {'@name': 'type', 'facet-value': {'@count': '1', '#text': 'Journal'}}]}}}"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "contrib_group = a[\"response\"][\"records\"][\"article\"][\"front\"][\"article-meta\"][\"contrib-group\"]\n",
    "all_affiliations = []\n",
    "for x in contrib_group[\"contrib\"]:\n",
    "    name = f\"{x['name']['given-names']} {x['name']['surname']}\"\n",
    "    affiliation = []\n",
    "    for aff in x[\"xref\"]:\n",
    "        if aff[\"@ref-type\"] == \"aff\":\n",
    "            ref_id = int(aff[\"@rid\"][-1])\n",
    "            affiliation.append(contrib_group[\"aff\"][ref_id-1][\"institution-wrap\"][\"institution\"][\"#text\"])\n",
    "\n",
    "    affiliations = \";\".join(affiliation)\n",
    "    all_affiliations.append((name, affiliations))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "66965"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"select p.PaperID, p.Title from Papers p where p.DOI is NULL\")\n",
    "all_papers = cursor.fetchall()\n",
    "len(all_papers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Acknowledgements\n",
      "Pedestrian Detection Inspired by Appearance Constancy and Shape Symmetry\n",
      "Real Time Fabric Defect Detection System on an Embedded DSP Platform\n",
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for idx,paper in enumerate(all_papers):\n",
    "    try:\n",
    "        if idx % 100 == 0:\n",
    "            print(idx)\n",
    "        cursor.execute(\"select distinct a.AuthorID, a.Name from Papers p,authoredBy b,Authors a where p.PaperID=%s and p.PaperID = b.PaperID and b.AuthoredByID = a.AuthorID\",[paper[0]])\n",
    "        authors = cursor.fetchall()\n",
    "\n",
    "        if not authors:\n",
    "            cursor.execute(\"UPDATE Papers p SET p.DOI='None' where p.PaperID=%s\",[paper[0]])\n",
    "            cnx.commit()\n",
    "            continue\n",
    "        first_name = authors[0][1].split()[-1]\n",
    "        doi = research_crawler.extract_doi(paper[1],first_name)\n",
    "        if doi:\n",
    "            cursor.execute(\"UPDATE Papers p SET p.DOI=%s where p.PaperID=%s\",[doi,paper[0]])\n",
    "        else:\n",
    "            cursor.execute(\"UPDATE Papers p SET p.DOI='NA' where p.PaperID=%s\",[paper[0]])\n",
    "        cnx.commit()\n",
    "    except:\n",
    "        print(paper[1])\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
