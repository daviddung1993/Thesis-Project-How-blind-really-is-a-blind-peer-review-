{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "import urllib, urllib.request\n",
    "import mysql.connector\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import uuid\n",
    "from webcrawler.researchgate import IeeeCrawler, ResearchGateCrawler, SpringerCrawler, PubMedCrawler\n",
    "import selenium as se"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## INIT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "headers = {\"x-api-key\": \"M7HSjQNeTfai6l7JUiDZB8XYc85BHnHt3R0NXSEd\"}\n",
    "# Establish database connection\n",
    "cnx = mysql.connector.connect(user='david', password='daviddung1993',\n",
    "                              host='127.0.0.1',\n",
    "                              database='computervision')\n",
    "cursor = cnx.cursor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Semantic Scholar API\n",
    "def semantic_paper_query(text):\n",
    "    link = f\"https://api.semanticscholar.org/graph/v1/paper/search?query={text}\"\n",
    "    response = requests.get(link, headers=headers).json()\n",
    "    return response\n",
    "\n",
    "def semantic_paper_details(paper_id):\n",
    "    paper_link = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}?fields=url,year,referenceCount,citationCount,publicationTypes,journal,authors,title,references.url,references.title,references.year,references.referenceCount,references.citationCount,references.authors,references.journal,references.publicationTypes,authors.name,authors.affiliations,authors.paperCount,authors.hIndex,authors.aliases\"\n",
    "    response = requests.get(paper_link, headers=headers).json()\n",
    "    return response\n",
    "\n",
    "def semantic_author_details(author_id):\n",
    "    author_link = f\"https://api.semanticscholar.org/graph/v1/author/{author_id}?fields=affiliations,name,paperCount,hIndex,aliases\"\n",
    "    response = requests.get(author_link, headers=headers).json()\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = f\"https://api.semanticscholar.org/graph/v1/paper/530a059cb48477ad1e3d4f8f4b153274c8997332/references\"\n",
    "response = semantic_paper_details(\"05c2e1ee203be217f100d2da05bdcc52004f00b6\")\n",
    "\n",
    "semantic_author_details(\"96665094\")\n",
    "response"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fetch all the papers in the category cs.CV from 2000 - 2020"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "YEAR_START = 2015\n",
    "YEAR_END = 2015\n",
    "STEP_SIZE = 10\n",
    "CATEGORY = \"cs.CV\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_arxiv_entries(year_temp, current_index, STEP_SIZE):\n",
    "    while True:\n",
    "        try:\n",
    "            arxiv_query = f'https://export.arxiv.org/api/query?search_query=cat:cs.CV+AND+submittedDate:[{year_temp}01010630+TO+{year_temp}12311645]&sortBy=submittedDate&start={current_index}&max_results={STEP_SIZE}'\n",
    "            data = urllib.request.urlopen(arxiv_query)\n",
    "            data_xml = data.read().decode('utf-8')\n",
    "            data_dict = xmltodict.parse(data_xml)\n",
    "\n",
    "            total_entries = int(data_dict['feed']['opensearch:totalResults']['#text'])\n",
    "            print(f\"{current_index}/{total_entries}\")\n",
    "            return data_dict['feed']['entry'], total_entries\n",
    "        except KeyError:\n",
    "            print(\"sleeping\")\n",
    "            time.sleep(3)\n",
    "\n",
    "def store_authors(author_information, paperID):\n",
    "    if not author_information:\n",
    "        cursor.execute(\"INSERT INTO authoredBy VALUES (%s,%s)\", [paperID, \"0\"])\n",
    "        return\n",
    "    for author in author_information:\n",
    "        try:\n",
    "            name = author[\"name\"]\n",
    "        except:\n",
    "            print(author)\n",
    "            raise KeyError\n",
    "        affiliations = author[\"affiliations\"]\n",
    "\n",
    "        # Get full name\n",
    "        if \".\" in name and author[\"aliases\"]:\n",
    "            for alias in author[\"aliases\"]:\n",
    "                if len(alias) > len(name):\n",
    "                    name = alias\n",
    "                if \".\" not in alias and len(alias.split(\" \")[0]) > 2:\n",
    "                    name = alias\n",
    "                    break\n",
    "\n",
    "        params = (author[\"authorId\"], name, author[\"paperCount\"], author[\"hIndex\"])\n",
    "        insert_author = \"INSERT INTO Authors(AuthorID, Name, PaperCount, hIndex) VALUES (%s,%s,%s,%s)\"\n",
    "        insert_authoredBy = \"INSERT INTO authoredBy VALUES (%s,%s)\"\n",
    "\n",
    "        try:\n",
    "            cursor.execute(insert_author, params)\n",
    "        except mysql.connector.IntegrityError as err:\n",
    "            pass\n",
    "        try:\n",
    "            cursor.execute(insert_authoredBy, (paperID, author[\"authorId\"]))\n",
    "        except mysql.connector.IntegrityError as err:\n",
    "            pass\n",
    "        \"\"\"\n",
    "        if affiliations:\n",
    "            for affiliation in affiliations:\n",
    "                cursor.execute(\"SELECT * FROM Affiliations a WHERE a.Name=%s\", [affiliation])\n",
    "                entry = cursor.fetchone()\n",
    "                if not entry:\n",
    "                    cursor.execute(\"INSERT INTO Affiliations (Name) VALUES (%s)\", [affiliation])\n",
    "                    lastrowid = cursor.lastrowid\n",
    "                else:\n",
    "                    lastrowid = entry[0]\n",
    "                try:\n",
    "                    cursor.execute(\"INSERT INTO affiliatedTo VALUES (%s,%s)\", [author[\"authorId\"],lastrowid])\n",
    "                except mysql.connector.IntegrityError as err:\n",
    "                    pass\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                cursor.execute(\"INSERT INTO affiliatedTo VALUES (%s,%s)\", [author[\"authorId\"],1])\n",
    "            except mysql.connector.IntegrityError as err:\n",
    "                pass\n",
    "        \"\"\"\n",
    "\n",
    "def store_paper(archive_url, paper_response, isLeaf):\n",
    "    isConference = False\n",
    "    isJournalArticle = False\n",
    "    isReview = False\n",
    "    journal = ''\n",
    "    if not paper_response['paperId']:\n",
    "        cursor.execute(\"SELECT * FROM Papers p WHERE Title=%s\", [paper_response[\"title\"]])\n",
    "        duplicate_paper = cursor.fetchall()\n",
    "        if duplicate_paper:\n",
    "            paper_response['paperId'] = duplicate_paper[0][0]\n",
    "        else:\n",
    "            paper_response['paperId'] = '11111' + uuid.uuid4().hex\n",
    "    if paper_response[\"publicationTypes\"]:\n",
    "        if \"JournalArticle\" in paper_response[\"publicationTypes\"]:\n",
    "            isJournalArticle = True\n",
    "        if \"Conference\" in paper_response[\"publicationTypes\"]:\n",
    "            isConference = True\n",
    "        if \"Review\" in paper_response[\"publicationTypes\"]:\n",
    "            isReview = True\n",
    "    if paper_response[\"journal\"]:\n",
    "        if \"name\" in paper_response[\"journal\"]:\n",
    "            journal = paper_response[\"journal\"][\"name\"]\n",
    "    params = [paper_response['paperId'], paper_response['title'], archive_url, paper_response['year'], CATEGORY, isReview, isConference, isJournalArticle,paper_response['referenceCount'], paper_response['citationCount'], journal, isLeaf, paper_response['url']]\n",
    "    insert_paper = \"INSERT INTO Papers VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    try:\n",
    "        cursor.execute(insert_paper, params)\n",
    "        return True\n",
    "    except mysql.connector.IntegrityError as err:\n",
    "        # If paper already exists check\n",
    "        if isLeaf:\n",
    "            return False\n",
    "\n",
    "        check_if_leaf = \"SELECT Leaf FROM Papers WHERE PaperID = %s\"\n",
    "        cursor.execute(check_if_leaf, [paper_response['paperId']])\n",
    "        isLeafPaper = cursor.fetchone()[0]\n",
    "        if isLeafPaper == isLeaf:\n",
    "            return False\n",
    "\n",
    "        update_leaf = \"UPDATE Papers SET Leaf = %s WHERE PaperID = %s\"\n",
    "        cursor.execute(update_leaf, (isLeaf,paper_response['paperId']))\n",
    "        return True\n",
    "\n",
    "    except Exception as err:\n",
    "        raise KeyError\n",
    "\n",
    "def store_reference(paperId, referenced_by):\n",
    "    try:\n",
    "        insert_reference = \"INSERT INTO referencedBy VALUES (%s,%s)\"\n",
    "        cursor.execute(insert_reference, (paperId, referenced_by))\n",
    "    except mysql.connector.IntegrityError as err:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(YEAR_END - YEAR_START + 1):\n",
    "    year_temp = YEAR_START + i\n",
    "    print(year_temp)\n",
    "    if year_temp == 2015:\n",
    "        current_index = 1560\n",
    "    else:\n",
    "        current_index = 0\n",
    "    var = 0\n",
    "    while True:\n",
    "        # Get title of all entries in a year from arxiv\n",
    "        entries, total_entries = fetch_arxiv_entries(year_temp, current_index, STEP_SIZE)\n",
    "        current_index += STEP_SIZE\n",
    "\n",
    "        # Fetch information for papers from semantic scholar\n",
    "        for entry in entries:\n",
    "            var += 1\n",
    "            print(var)\n",
    "            archive_link = entry[\"id\"]\n",
    "            entry_title = entry[\"title\"].replace(\"-\", \" \").replace(\"\\n\", \"\")\n",
    "            response = semantic_paper_query(entry_title)\n",
    "\n",
    "            if not response[\"total\"]:\n",
    "                continue\n",
    "            else:\n",
    "                while True:\n",
    "                    try:\n",
    "                        # Store papers' information in database\n",
    "                        paperId = response[\"data\"][0][\"paperId\"]\n",
    "                        cursor.execute(\"select * from Papers p where p.PaperID = %s\",[paperId])\n",
    "                        exist_paper = cursor.fetchall()\n",
    "                        if exist_paper and not exist_paper[0][-2]:\n",
    "                            break\n",
    "                        paper_response = semantic_paper_details(paperId)\n",
    "                        if paper_response[\"referenceCount\"] > 70 or paper_response[\"referenceCount\"] == 0 or len(paper_response[\"authors\"]) > 10:\n",
    "                            break\n",
    "                        success = store_paper(archive_link, paper_response, False)\n",
    "\n",
    "                        if not success:\n",
    "                            break\n",
    "\n",
    "                        store_authors(paper_response['authors'], paperId)\n",
    "                        # Store references' information in database\n",
    "                        for reference in paper_response[\"references\"]:\n",
    "                            store_paper(None, reference, True)\n",
    "                            store_reference(reference[\"paperId\"], paperId)\n",
    "                            if reference[\"authors\"]:\n",
    "                                for author in reference[\"authors\"]:\n",
    "                                    if not author[\"authorId\"]:\n",
    "                                        continue\n",
    "                                    author_information = semantic_author_details(author[\"authorId\"])\n",
    "                                    store_authors([author_information], reference[\"paperId\"])\n",
    "                            else:\n",
    "                                store_authors(None, reference[\"paperId\"])\n",
    "                        break\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "            cnx.commit()\n",
    "\n",
    "        if current_index > total_entries:\n",
    "            break\n",
    "    clear_output(wait=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fetch doi from researchgate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "67795"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"select p.PaperID, p.Title from Papers p where p.DOI is NULL\")\n",
    "all_papers = cursor.fetchall()\n",
    "len(all_papers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "se."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'selenium' has no attribute 'webdriver'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwebdriver\u001B[49m\u001B[38;5;241m.\u001B[39mChromeOptions()\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'selenium' has no attribute 'webdriver'"
     ]
    }
   ],
   "source": [
    "se.webdriver.ChromeOptions()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'selenium' has no attribute 'webdriver'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m research_crawler \u001B[38;5;241m=\u001B[39m \u001B[43mResearchGateCrawler\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/bachelor_thesis/webcrawler/researchgate.py:64\u001B[0m, in \u001B[0;36mResearchGateCrawler.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 64\u001B[0m     options \u001B[38;5;241m=\u001B[39m \u001B[43mse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwebdriver\u001B[49m\u001B[38;5;241m.\u001B[39mChromeOptions()\n\u001B[1;32m     65\u001B[0m     options\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mheadless\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     66\u001B[0m     options\u001B[38;5;241m.\u001B[39madd_argument(\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'selenium' has no attribute 'webdriver'"
     ]
    }
   ],
   "source": [
    "research_crawler = ResearchGateCrawler()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'research_crawler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m     11\u001B[0m first_name \u001B[38;5;241m=\u001B[39m authors[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39msplit()[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m---> 12\u001B[0m doi \u001B[38;5;241m=\u001B[39m \u001B[43mresearch_crawler\u001B[49m\u001B[38;5;241m.\u001B[39mextract_doi(paper[\u001B[38;5;241m1\u001B[39m],first_name)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m doi:\n\u001B[1;32m     14\u001B[0m     cursor\u001B[38;5;241m.\u001B[39mexecute(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUPDATE Papers p SET p.DOI=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m where p.PaperID=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,[doi,paper[\u001B[38;5;241m0\u001B[39m]])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'research_crawler' is not defined"
     ]
    }
   ],
   "source": [
    "for idx,paper in enumerate(all_papers):\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)\n",
    "    cursor.execute(\"select distinct a.AuthorID, a.Name from Papers p,authoredBy b,Authors a where p.PaperID=%s and p.PaperID = b.PaperID and b.AuthoredByID = a.AuthorID\",[paper[0]])\n",
    "    authors = cursor.fetchall()\n",
    "\n",
    "    if not authors:\n",
    "        cursor.execute(\"UPDATE Papers p SET p.DOI='None' where p.PaperID=%s\",[paper[0]])\n",
    "        cnx.commit()\n",
    "        continue\n",
    "    first_name = authors[0][1].split()[-1]\n",
    "    doi = research_crawler.extract_doi(paper[1],first_name)\n",
    "    if doi:\n",
    "        cursor.execute(\"UPDATE Papers p SET p.DOI=%s where p.PaperID=%s\",[doi,paper[0]])\n",
    "    else:\n",
    "        cursor.execute(\"UPDATE Papers p SET p.DOI='NA' where p.PaperID=%s\",[paper[0]])\n",
    "    cnx.commit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "cnx.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
