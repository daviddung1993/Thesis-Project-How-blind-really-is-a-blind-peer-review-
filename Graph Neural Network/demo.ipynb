{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.data\n",
    "import numpy as np\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch as th\n",
    "import dgl.function as fn\n",
    "import dgl.nn as dglnn\n",
    "from dgl.dataloading.negative_sampler import _BaseNegativeSampler\n",
    "from dgl import backend as b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class PerSourceUniformCustom(_BaseNegativeSampler):\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def _generate(self, g, eids, canonical_etype):\n",
    "        unique_authors = torch.unique(g.edges(etype = \"authored\")[1])\n",
    "        #print(len(unique_authors))\n",
    "        _, _, vtype = canonical_etype\n",
    "        shape = b.shape(eids)\n",
    "        dtype = b.dtype(eids)\n",
    "        ctx = b.context(eids)\n",
    "        shape = (shape[0] * self.k,)\n",
    "        src, _ = g.find_edges(eids, etype=canonical_etype)\n",
    "        src = b.repeat(src, self.k, 0)\n",
    "        dst_indexes = th.randint(0, len(unique_authors), shape, dtype=dtype, device=ctx)\n",
    "        dst = unique_authors[dst_indexes]\n",
    "        return src, dst"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    def forward(self, graph, h, etype):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
    "            return graph.edges[etype].data['score']\n",
    "\n",
    "    def returnScore(self, graph, neg_graph, h, etype):\n",
    "        return self(graph, h, etype), self(neg_graph, h, etype)\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, num_classes_papers, num_classes_authors):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_paper = nn.Embedding(num_classes_papers, 64)\n",
    "        self.embedding_author = nn.Embedding(num_classes_authors, 64)\n",
    "        #self.conv_writes = dglnn.GraphConv(64, 64, allow_zero_in_degree=True)\n",
    "        #self.conv_cites = dglnn.GraphConv(64, 64, allow_zero_in_degree=True)\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            \"writes\": dglnn.GraphConv(64, 64),\n",
    "        }, aggregate=\"stack\")\n",
    "\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            \"cites\": dglnn.GraphConv(64, 64),\n",
    "        })\n",
    "\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        classes_paper = inputs[\"paper\"]\n",
    "        classes_author = inputs[\"author\"]\n",
    "\n",
    "        # Put all classes into an embedding\n",
    "        embedded_papers = self.embedding_paper(classes_paper)\n",
    "        print(embedded_papers[0])\n",
    "        embedded_authors = self.embedding_author(classes_author)\n",
    "\n",
    "        #paper_feat = torch.cat([embedded_papers, author_agg], dim=-1)\n",
    "        #h = self.conv_cites(paper_feat)\n",
    "        h_writes = self.conv1(graph[\"writes\"], {\"author\": embedded_authors, \"paper\": 0})\n",
    "        h_authored_papers = torch.cat((h_writes, embedded_papers.unsqueeze(2)), dim=1)\n",
    "        h_cites = self.conv2(graph[\"cites\"], {\"paper\": h_authored_papers, \"author\": 0}).squeeze(1)\n",
    "        return {\"paper\": h_cites, \"author\": embedded_authors}\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, rel_names, num_classes_paper, num_classes_author):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.sage = RGCN(in_features, hidden_features, out_features, num_classes_paper, num_classes_author)\n",
    "        # Decoder\n",
    "        self.pred = HeteroDotProductPredictor()\n",
    "    def forward(self, g, x):\n",
    "        h = self.sage(g, x)\n",
    "        return h\n",
    "\n",
    "    def scores(self, g, neg_g, x, etype):\n",
    "      h = self(g, neg_g, x, etype)\n",
    "      return self.pred(g, h, etype), self.pred(neg_g, h, etype)\n",
    "\n",
    "\n",
    "def accuracy(logits, graph):\n",
    "  with torch.no_grad():\n",
    "    all_papers = torch.unique(graph.edges(etype=\"authored\")[0])\n",
    "    src, dst = graph.edges(etype=\"authored\")\n",
    "    tst = 0\n",
    "    author_logits = logits[\"author\"]\n",
    "    #print(len(all_papers))\n",
    "    for idx, index_paper in enumerate(all_papers):\n",
    "      #if idx % 25000 == 0:\n",
    "        #print(f\"{idx}/{len(all_papers)}\")\n",
    "      current_logits = logits[\"paper\"][index_paper]\n",
    "      max = torch.argmax(torch.sum(current_logits * author_logits, dim=-1))\n",
    "      filter_acc = src == index_paper\n",
    "      if max in dst[filter_acc]:\n",
    "        tst += 1\n",
    "    return tst/len(all_papers)\n",
    "\n",
    "def compute_loss_logits(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    )\n",
    "    return F.binary_cross_entropy_with_logits(scores.squeeze(1), labels)\n",
    "\n",
    "def construct_negative_graph(graph, k, etype):\n",
    "    utype, _, vtype = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    neg_src = src.repeat_interleave(k)\n",
    "    neg_dst = torch.randint(0, graph.num_nodes(vtype), (len(src) * k,))\n",
    "    return dgl.heterograph(\n",
    "        {etype: (neg_src, neg_dst)},\n",
    "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "from dgl import sum_nodes\n",
    "\n",
    "class HeteroSumPooling(nn.Module):\n",
    "\n",
    "    def __init__(self, node_type):\n",
    "        super(HeteroSumPooling, self).__init__()\n",
    "        self.node_type = node_type\n",
    "\n",
    "    def forward(self, graph, feat):\n",
    "\n",
    "        with graph.local_scope():\n",
    "            graph.nodes[self.node_type].data[\"h\"] = feat\n",
    "            readout = dgl.sum_nodes(graph, \"h\", ntype=self.node_type)\n",
    "            return readout\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Little example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "hetero_graph_example = dgl.heterograph(\n",
    "    {\n",
    "        ('paper', 'authored', 'author'): (np.array([2,0]), np.array([0,1])),\n",
    "        ('paper', 'cites', 'paper'): (np.array([4,1,1,4,1,4,6]), np.array([1,2,3,0,0,5,6])),\n",
    "        ('author', 'writes', 'paper'): (np.array([2,3,2,3,1,3]), np.array([1,1,6,6,4,4]))\n",
    "    }\n",
    ")\n",
    "\n",
    "hetero_graph_example_eval = dgl.heterograph(\n",
    "    {\n",
    "        ('paper', 'authored', 'author'): (np.array([3,5]), np.array([0,1])),\n",
    "        ('paper', 'cites', 'paper'): (np.array([0,1,1,0,1,0,6]), np.array([1,2,3,4,4,5,5])),\n",
    "        ('author', 'writes', 'paper'): (np.array([2,2,3]), np.array([0,1,1]))\n",
    "    }\n",
    ")\n",
    "\n",
    "num_papers = hetero_graph_example.number_of_nodes('paper')\n",
    "num_authors = hetero_graph_example.number_of_nodes('author')\n",
    "hetero_graph_example.nodes['paper'].data['feature'] = th.arange(num_papers).view(-1,1)\n",
    "hetero_graph_example.nodes['author'].data['feature'] = th.arange(num_authors).view(-1,1)\n",
    "author_feat = F.one_hot(th.arange(num_papers))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "hetero_graph_example = dgl.heterograph(\n",
    "    {\n",
    "        ('author', 'writes', 'paper'): (np.array([0,1]), np.array([0,0]))\n",
    "    }\n",
    ")\n",
    "num_papers = hetero_graph_example.number_of_nodes('paper')\n",
    "num_authors = hetero_graph_example.number_of_nodes('author')\n",
    "hetero_graph_example.nodes['paper'].data['feature'] = th.arange(num_papers).view(-1,1)\n",
    "hetero_graph_example.nodes['author'].data['feature'] = th.arange(num_authors).view(-1,1)\n",
    "author_feat = F.one_hot(th.arange(num_authors)).to(torch.float32)\n",
    "paper_feat = th.tensor([[123,0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0.]])"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.zeros((len(paper_feat), author_feat.shape[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1.]])"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetero_graph_example.nodes[\"author\"].data[\"h\"] = author_feat\n",
    "hetero_graph_example.nodes[\"paper\"].data[\"h\"] = paper_feat\n",
    "hetero_graph_example[\"writes\"].update_all(fn.copy_u('h', 'm'), fn.sum('m', 'h'))\n",
    "hetero_graph_example.nodes['paper'].data['h']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "g = dgl.heterograph({\n",
    "    ('user', 'follows', 'game'): ([0], [1]),\n",
    "    ('game', 'attracts', 'user'): ([0], [1])\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0.],\n        [1., 0.]])"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes['user'].data['h'] = torch.tensor([[1., 0.], [0., 1.]])\n",
    "g.nodes['game'].data['h'] = torch.tensor([[1, 0], [10, 0]])\n",
    "g[\"follows\"].update_all(fn.copy_u('h', 'm'), fn.sum('m', 'h'))\n",
    "g.nodes['game'].data['h']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "conv1 = dglnn.HeteroGraphConv({\n",
    "    \"writes\": dglnn.GraphConv(2, 2, weight=False),\n",
    "}, aggregate=\"sum\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "{'paper': tensor([[0.7071, 0.7071]], grad_fn=<SumBackward1>)}"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1(hetero_graph_example[\"writes\"], {\"author\": author_feat, \"paper\": paper_feat})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "conv1 = dglnn.HeteroGraphConv({\n",
    "    \"writes\": dglnn.GraphConv(4, 4),\n",
    "}, aggregate=\"stack\")\n",
    "\n",
    "conv2 = dglnn.HeteroGraphConv({\n",
    "    \"cites\": dglnn.GraphConv(4, 4),\n",
    "})\n",
    "\n",
    "embedding_paper = nn.Embedding(7, 4)\n",
    "embedding_author = nn.Embedding(4, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "author_feats = embedding_author(hetero_graph_example.nodes['author'].data['feature'])\n",
    "paper_feats = embedding_paper(hetero_graph_example.nodes['paper'].data['feature'])\n",
    "node_features = {'author': author_feats, 'paper': paper_feats}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([7, 1, 4])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper = conv1(hetero_graph_example[\"writes\"], node_features)[\"paper\"].squeeze(1)\n",
    "paper_feats.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([7, 2, 4])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_fea = torch.cat((paper, paper_feats), dim=1)\n",
    "paper_fea.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([7, 8])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_paper_fea = conv2(hetero_graph_example[\"cites\"], {'author': author_feats, 'paper': paper_fea})[\"paper\"]\n",
    "new_paper_fea.flatten(1).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "pred = HeteroDotProductPredictor()\n",
    "model = Model(256, 64, 64, hetero_graph_example.etypes, len(hetero_graph_example.nodes(\"paper\")), len(hetero_graph_example.nodes(\"author\")))\n",
    "author_feats = hetero_graph_example.nodes['author'].data['feature']\n",
    "paper_feats = hetero_graph_example.nodes['paper'].data['feature']\n",
    "node_features = {'author': author_feats, 'paper': paper_feats}\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "k = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0327, -0.2471,  1.3498, -0.4649,  0.5063,  1.1272, -1.4630, -0.9207,\n",
      "         -0.2087,  0.8228, -0.2701,  0.5944,  1.9127, -0.5640, -1.8044, -0.8177,\n",
      "         -0.3373, -0.3140, -0.7660, -1.8931, -1.2541, -2.7131,  0.9276, -1.8957,\n",
      "          0.0403,  0.0832,  1.2483,  0.2404, -0.0809,  1.8444,  1.1190, -1.1284,\n",
      "         -0.4637, -0.0424,  0.7864,  0.2597, -0.4501,  0.0497,  1.5300,  0.1888,\n",
      "         -1.1421, -1.5466,  0.6383, -0.7819, -0.0973,  0.9306, -1.3108, -1.1159,\n",
      "         -0.5026, -0.3738, -1.3866, -0.1051, -0.4184,  1.7215, -0.6648, -1.2275,\n",
      "          1.2156,  0.3436,  0.7285, -0.8094, -1.1248, -0.7959,  0.8455,  1.2729]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [81]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m50\u001B[39m):\n\u001B[1;32m      2\u001B[0m     negative_graph \u001B[38;5;241m=\u001B[39m construct_negative_graph(hetero_graph_example, k, (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaper\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthored\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthor\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 3\u001B[0m     h \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhetero_graph_example\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     pos_score, neg_score \u001B[38;5;241m=\u001B[39m pred\u001B[38;5;241m.\u001B[39mreturnScore(hetero_graph_example, negative_graph, h, (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaper\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthored\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthor\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      5\u001B[0m     loss \u001B[38;5;241m=\u001B[39m compute_loss_logits(pos_score\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m), neg_score\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/PycharmProjects/bachelor_thesis/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [69]\u001B[0m, in \u001B[0;36mModel.forward\u001B[0;34m(self, g, x)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, g, x):\n\u001B[0;32m---> 53\u001B[0m     h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m h\n",
      "File \u001B[0;32m~/PycharmProjects/bachelor_thesis/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [69]\u001B[0m, in \u001B[0;36mRGCN.forward\u001B[0;34m(self, graph, inputs)\u001B[0m\n\u001B[1;32m     36\u001B[0m embedded_authors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_author(classes_author)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m#paper_feat = torch.cat([embedded_papers, author_agg], dim=-1)\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m#h = self.conv_cites(paper_feat)\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m h_writes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwrites\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauthor\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43membedded_authors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpaper\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m h_authored_papers \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((h_writes, embedded_papers\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m2\u001B[39m)), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     42\u001B[0m h_cites \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(graph[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcites\u001B[39m\u001B[38;5;124m\"\u001B[39m], {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpaper\u001B[39m\u001B[38;5;124m\"\u001B[39m: h_authored_papers, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauthor\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0\u001B[39m})\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/bachelor_thesis/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/bachelor_thesis/venv2/lib/python3.10/site-packages/dgl/nn/pytorch/hetero.py:210\u001B[0m, in \u001B[0;36mHeteroGraphConv.forward\u001B[0;34m(self, g, inputs, mod_args, mod_kwargs)\u001B[0m\n\u001B[1;32m    208\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m stype \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m inputs:\n\u001B[1;32m    209\u001B[0m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m--> 210\u001B[0m         dstdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrel_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m            \u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstype\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmod_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmod_kwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m         outputs[dtype]\u001B[38;5;241m.\u001B[39mappend(dstdata)\n\u001B[1;32m    217\u001B[0m rsts \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/PycharmProjects/bachelor_thesis/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/bachelor_thesis/venv2/lib/python3.10/site-packages/dgl/nn/pytorch/conv/graphconv.py:437\u001B[0m, in \u001B[0;36mGraphConv.forward\u001B[0;34m(self, graph, feat, weight, edge_weight)\u001B[0m\n\u001B[1;32m    434\u001B[0m         rst \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mmatmul(rst, weight)\n\u001B[1;32m    436\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_norm \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mright\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mboth\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m--> 437\u001B[0m     degs \u001B[38;5;241m=\u001B[39m \u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_degrees\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeat_dst\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_norm \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mboth\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    439\u001B[0m         norm \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mpow(degs, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/bachelor_thesis/venv2/lib/python3.10/site-packages/torch/cuda/__init__.py:229\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCUDA_MODULE_LOADING\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39menviron:\n\u001B[1;32m    228\u001B[0m     os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCUDA_MODULE_LOADING\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLAZY\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 229\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001B[39;00m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;66;03m# we need to just return without initializing in that case.\u001B[39;00m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;66;03m# However, we must not let any *other* threads in!\u001B[39;00m\n\u001B[1;32m    233\u001B[0m _tls\u001B[38;5;241m.\u001B[39mis_initializing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    negative_graph = construct_negative_graph(hetero_graph_example, k, ('paper', 'authored', 'author'))\n",
    "    h = model(hetero_graph_example, node_features)\n",
    "    pos_score, neg_score = pred.returnScore(hetero_graph_example, negative_graph, h, ('paper', 'authored', 'author'))\n",
    "    loss = compute_loss_logits(pos_score.squeeze(1), neg_score.squeeze(1))\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(h, hetero_graph_example)\n",
    "            h_eval = model(hetero_graph_example_eval, node_features)\n",
    "            acc_eval = accuracy(h_eval, hetero_graph_example_eval)\n",
    "            print(acc, acc_eval)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on the complete graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "glist, label_dict = load_graphs(\"./graphs/val_graph.bin\")\n",
    "train_hetero_graph= glist[0]\n",
    "val_pos_hetero_graph = glist[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "paper_ids = val_pos_hetero_graph.nodes(\"paper\")\n",
    "paper_feats = F.one_hot(paper_ids, num_classes = len(paper_ids))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_pos_hetero_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [20]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m pred \u001B[38;5;241m=\u001B[39m HeteroDotProductPredictor()\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m Model(\u001B[38;5;241m8638\u001B[39m, \u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m256\u001B[39m, \u001B[43mval_pos_hetero_graph\u001B[49m\u001B[38;5;241m.\u001B[39metypes)\n\u001B[1;32m      3\u001B[0m author_feats \u001B[38;5;241m=\u001B[39m val_pos_hetero_graph\u001B[38;5;241m.\u001B[39mnodes[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthor\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdata[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#paper_feats = val_pos_hetero_graph.nodes['paper'].data['feature']\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'val_pos_hetero_graph' is not defined"
     ]
    }
   ],
   "source": [
    "pred = HeteroDotProductPredictor()\n",
    "model = Model(8638, 256, 256, val_pos_hetero_graph.etypes)\n",
    "author_feats = val_pos_hetero_graph.nodes['author'].data['feature']\n",
    "#paper_feats = val_pos_hetero_graph.nodes['paper'].data['feature']\n",
    "node_features = {'author': author_feats, 'paper': paper_feats}\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "k = 1\n",
    "\n",
    "for epoch in range(15000):\n",
    "    print(epoch)\n",
    "    negative_graph = construct_negative_graph(val_pos_hetero_graph, k, ('paper', 'authored', 'author'))\n",
    "    h = model(val_pos_hetero_graph, node_features)\n",
    "    pos_score, neg_score = pred.returnScore(val_pos_hetero_graph, negative_graph, h, ('paper', 'authored', 'author'))\n",
    "    loss = compute_loss_logits(pos_score.squeeze(1), neg_score.squeeze(1))\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(h, val_pos_hetero_graph)\n",
    "            print(acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6.6322],\n        [6.6322],\n        [5.6405],\n        ...,\n        [6.4707],\n        [6.4707],\n        [6.4707]], grad_fn=<GSDDMMBackward>)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1443, 1])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_score.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
