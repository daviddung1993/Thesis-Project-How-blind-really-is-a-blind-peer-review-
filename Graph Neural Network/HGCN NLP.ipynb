{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11389,
     "status": "ok",
     "timestamp": 1677487284405,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     },
     "user_tz": -60
    },
    "id": "X-oVrk2WMbHi",
    "outputId": "bf8c11f5-c98b-47bd-8bee-6175a84c2fb7"
   },
   "outputs": [],
   "source": [
    "#!pip install dgl dglgo -f https://data.dgl.ai/wheels/repo.html\n",
    "import dgl\n",
    "import torch as th\n",
    "import torch\n",
    "import numpy as np\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch.nn as nn\n",
    "import dgl.nn as dglnn\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "#from torchmetrics.classification import BinaryAUROC\n",
    "import torch.nn as nn\n",
    "from dgl.dataloading.negative_sampler import _BaseNegativeSampler\n",
    "from dgl import backend as b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1677487286244,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     },
     "user_tz": -60
    },
    "id": "7OKjsl70Me-a"
   },
   "outputs": [],
   "source": [
    "glist, label_dict = load_graphs(\"./graphs/hetero_graphs_all_authors.bin\")\n",
    "train_hetero_graph = glist[0]\n",
    "val_hetero_graph = glist[1]\n",
    "test_hetero_graph = glist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677487286996,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     },
     "user_tz": -60
    },
    "id": "xY3a7pwejU0G"
   },
   "outputs": [],
   "source": [
    "class PerSourceUniformCustom(_BaseNegativeSampler):\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def _generate(self, g, eids, canonical_etype):\n",
    "        unique_authors = torch.unique(g.edges(etype = \"authored\")[1])\n",
    "        _, _, vtype = canonical_etype\n",
    "        shape = b.shape(eids)\n",
    "        dtype = b.dtype(eids)\n",
    "        ctx = b.context(eids)\n",
    "        shape = (shape[0] * self.k,)\n",
    "        src, _ = g.find_edges(eids, etype=canonical_etype)\n",
    "        src = b.repeat(src, self.k, 0)\n",
    "        dst_indexes = th.randint(0, len(unique_authors), shape, dtype=dtype, device=ctx)\n",
    "        dst = unique_authors[dst_indexes]\n",
    "        return src, dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677487287368,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     },
     "user_tz": -60
    },
    "id": "jjiNOLmYMh61"
   },
   "outputs": [],
   "source": [
    "def construct_negative_graph(graph, k, etype):\n",
    "    utype, edge_type, vtype = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    eids = graph.edge_ids(src, dst, etype=edge_type)\n",
    "    neg_sampler = PerSourceUniformCustom(k)\n",
    "    neg_src, neg_dst = neg_sampler(graph, {edge_type: eids})[etype]\n",
    "    return dgl.heterograph(\n",
    "        {etype: (neg_src, neg_dst)},\n",
    "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677487287707,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     },
     "user_tz": -60
    },
    "id": "au2Jb4o5MnGy"
   },
   "outputs": [],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, num_classes_papers, num_classes_authors):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            \"cites\": dglnn.GraphConv(303, 512),\n",
    "        })\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear = nn.Linear(512, 303)\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        classes_paper = inputs[\"paper\"]\n",
    "        classes_author = inputs[\"author\"]\n",
    "\n",
    "        h_cites = self.conv1(graph[\"cites\"], {\"paper\": classes_paper, \"author\": classes_author})[\"paper\"]\n",
    "        h_cites = self.dropout(h_cites)\n",
    "        h_cites = F.relu(h_cites)\n",
    "\n",
    "\n",
    "        h_cites = self.linear(h_cites)\n",
    "        return {\"paper\": h_cites, \"author\": classes_author}\n",
    "    \n",
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    def forward(self, graph, h, etype):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
    "            return graph.edges[etype].data['score']\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, rel_names, num_classes_paper, num_classes_author):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.sage = RGCN(in_features, hidden_features, out_features, num_classes_paper, num_classes_author)\n",
    "        # Decoder\n",
    "        self.pred = HeteroDotProductPredictor()\n",
    "    def forward(self, g, neg_g, x, etype):\n",
    "        h = self.sage(g, x)\n",
    "        return h\n",
    "\n",
    "    def scores(self, g, neg_g, x, etype):\n",
    "        h = self(g, neg_g, x, etype)\n",
    "        return self.pred(g, h, etype), self.pred(neg_g, h, etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677487288459,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     },
     "user_tz": -60
    },
    "id": "TYXaLTytM3vC"
   },
   "outputs": [],
   "source": [
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).squeeze(1).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    # Margin loss\n",
    "    n_edges = pos_score.shape[0]\n",
    "    return (1 - pos_score + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
    "\n",
    "def compute_loss_logits(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).to(\"cuda\")\n",
    "    \n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).to(device)\n",
    "    return F.binary_cross_entropy_with_logits(scores.squeeze(1), labels)\n",
    "\n",
    "def accuracy(logits, graph):\n",
    "  with torch.no_grad():\n",
    "    all_papers = torch.unique(graph.edges(etype=\"authored\")[0])\n",
    "    src, dst = graph.edges(etype=\"authored\")\n",
    "    unique_authors = torch.unique(dst)\n",
    "    tst = 0\n",
    "    author_logits = logits[\"author\"][unique_authors]\n",
    "\n",
    "    for idx, index_paper in enumerate(all_papers):\n",
    "\n",
    "      current_logits = logits[\"paper\"][index_paper]\n",
    "      dot_product_all = torch.sum(current_logits * author_logits, dim=-1)\n",
    "      max = torch.argmax(dot_product_all)\n",
    "      max = unique_authors[max].item()\n",
    "      filter_acc = src == index_paper\n",
    "      if max in dst[filter_acc]:\n",
    "        tst += 1\n",
    "    return tst/len(all_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677487289711,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     },
     "user_tz": -60
    },
    "id": "busP_ir1M4T8"
   },
   "outputs": [],
   "source": [
    "# Load data into GPU memory\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the nlp features: Paper: SPECTER; author: publication history's title as Word2Vec\n",
    "author_feats = torch.load(\"./author_feats.pt\")\n",
    "paper_feats = torch.load(\"./paper_feats.pt\")\n",
    "paper_feats = torch.tensor(paper_feats)[:135246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 8\n",
    "loss_training_epoch = []\n",
    "loss_validation_epoch = []\n",
    "\n",
    "auc_training_epoch = []\n",
    "auc_validation_epoch = []\n",
    "\n",
    "acc_training = []\n",
    "acc_validation = []\n",
    "\n",
    "node_features = {'paper': paper_feats.to(device), \"author\": author_feats.type(torch.float32).to(device)}\n",
    "pred = HeteroDotProductPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 291881,
     "status": "error",
     "timestamp": 1677487588012,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     },
     "user_tz": -60
    },
    "id": "m49fF7jqNOVy",
    "outputId": "1964bcb1-f396-41e6-f7f0-59487e86a22e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0; Loss: 0.45162147283554077, AUC: 0.5130368387395515, Acc Train: 0.00021891418563922942; Loss 0.3108879327774048, AUC: 0.5011177517674399 Acc Evaluation: 0.0033333333333333335\n",
      "EPOCH: 200; Loss: 0.2891857922077179, AUC: 0.8054390910315407, Acc Train: 0.00032837127845884414; Loss 0.1369597464799881, AUC: 0.719358371645274 Acc Evaluation: 0.01\n",
      "EPOCH: 400; Loss: 0.26397010684013367, AUC: 0.8479597443415426, Acc Train: 0.00021891418563922942; Loss 0.09830338507890701, AUC: 0.7488341331896425 Acc Evaluation: 0.0033333333333333335\n",
      "EPOCH: 600; Loss: 0.25205519795417786, AUC: 0.8659057578210628, Acc Train: 0.000766199649737303; Loss 0.09268484264612198, AUC: 0.7637213416839196 Acc Evaluation: 0.01\n",
      "EPOCH: 800; Loss: 0.2433425486087799, AUC: 0.8801204465541044, Acc Train: 0.0024080560420315237; Loss 0.118519127368927, AUC: 0.7679949360042916 Acc Evaluation: 0.05333333333333334\n",
      "EPOCH: 1000; Loss: 0.2377735674381256, AUC: 0.8855926712703592, Acc Train: 0.0056370402802101574; Loss 0.11351606994867325, AUC: 0.7670551768784617 Acc Evaluation: 0.056666666666666664\n",
      "EPOCH: 1200; Loss: 0.23491324484348297, AUC: 0.8899219204763323, Acc Train: 0.006403239929947461; Loss 0.11678683757781982, AUC: 0.770236802851148 Acc Evaluation: 0.06666666666666667\n",
      "EPOCH: 1400; Loss: 0.23420846462249756, AUC: 0.8887667220133955, Acc Train: 0.007169439579684763; Loss 0.07928510010242462, AUC: 0.7740661359424353 Acc Evaluation: 0.06\n",
      "EPOCH: 1600; Loss: 0.228078693151474, AUC: 0.8951133150967328, Acc Train: 0.007552539404553415; Loss 0.10190096497535706, AUC: 0.7743608593400694 Acc Evaluation: 0.06\n",
      "EPOCH: 1800; Loss: 0.23158910870552063, AUC: 0.8938761086772208, Acc Train: 0.007607267950963222; Loss 0.07125772535800934, AUC: 0.7834609957790831 Acc Evaluation: 0.06666666666666667\n",
      "EPOCH: 2000; Loss: 0.22352860867977142, AUC: 0.8997554738038733, Acc Train: 0.007716725043782837; Loss 0.0863930806517601, AUC: 0.7814447863824163 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 2200; Loss: 0.2220618575811386, AUC: 0.9035047012742566, Acc Train: 0.008264010507880911; Loss 0.11035626381635666, AUC: 0.7785311098720662 Acc Evaluation: 0.08\n",
      "EPOCH: 2400; Loss: 0.2193797528743744, AUC: 0.9043691459355709, Acc Train: 0.008647110332749562; Loss 0.09043240547180176, AUC: 0.7854341627730401 Acc Evaluation: 0.07666666666666666\n",
      "EPOCH: 2600; Loss: 0.21731963753700256, AUC: 0.9071197362230681, Acc Train: 0.008975481611208405; Loss 0.09624576568603516, AUC: 0.7811014676919042 Acc Evaluation: 0.08\n",
      "EPOCH: 2800; Loss: 0.21883606910705566, AUC: 0.9105965627840003, Acc Train: 0.009468038528896673; Loss 0.12191887199878693, AUC: 0.7819718306984419 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 3000; Loss: 0.21347260475158691, AUC: 0.9119234701300131, Acc Train: 0.009632224168126095; Loss 0.10084597021341324, AUC: 0.7839163027572591 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 3200; Loss: 0.2117374837398529, AUC: 0.9128353667102567, Acc Train: 0.009960595446584938; Loss 0.08689051121473312, AUC: 0.7836283328746946 Acc Evaluation: 0.08\n",
      "EPOCH: 3400; Loss: 0.210566446185112, AUC: 0.9144377611541779, Acc Train: 0.01012478108581436; Loss 0.08219487220048904, AUC: 0.7850015776211203 Acc Evaluation: 0.07666666666666666\n",
      "EPOCH: 3600; Loss: 0.20807407796382904, AUC: 0.9168269514777915, Acc Train: 0.010507880910683012; Loss 0.08669828623533249, AUC: 0.7883957142013275 Acc Evaluation: 0.07666666666666666\n",
      "EPOCH: 3800; Loss: 0.20615379512310028, AUC: 0.9194095875887889, Acc Train: 0.010507880910683012; Loss 0.09937066584825516, AUC: 0.7834852183864658 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 4000; Loss: 0.20506691932678223, AUC: 0.9206590018754897, Acc Train: 0.011219352014010508; Loss 0.09384743869304657, AUC: 0.7874316124056249 Acc Evaluation: 0.08\n",
      "EPOCH: 4200; Loss: 0.20406632125377655, AUC: 0.9214190579446964, Acc Train: 0.011219352014010508; Loss 0.0801955834031105, AUC: 0.789948752526715 Acc Evaluation: 0.07\n",
      "EPOCH: 4400; Loss: 0.20125383138656616, AUC: 0.92373678633109, Acc Train: 0.011328809106830123; Loss 0.08713573217391968, AUC: 0.7887896392314272 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 4600; Loss: 0.20103849470615387, AUC: 0.924328304842904, Acc Train: 0.011109894921190893; Loss 0.08087120950222015, AUC: 0.7920963102875784 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 4800; Loss: 0.19881761074066162, AUC: 0.9268367080399775, Acc Train: 0.012040280210157617; Loss 0.09351322799921036, AUC: 0.7868205543621344 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 5000; Loss: 0.20039592683315277, AUC: 0.9265668088714412, Acc Train: 0.011821366024518389; Loss 0.07229083776473999, AUC: 0.7859852796183358 Acc Evaluation: 0.07666666666666666\n",
      "EPOCH: 5200; Loss: 0.19740262627601624, AUC: 0.9296588632894571, Acc Train: 0.012806479859894922; Loss 0.1037658229470253, AUC: 0.7838645258083927 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 5400; Loss: 0.1978197991847992, AUC: 0.9287326100519258, Acc Train: 0.012587565674255691; Loss 0.07264608144760132, AUC: 0.7874317024524925 Acc Evaluation: 0.07666666666666666\n",
      "EPOCH: 5600; Loss: 0.19547145068645477, AUC: 0.9317802205777906, Acc Train: 0.0126422942206655; Loss 0.10528925061225891, AUC: 0.7856892055176877 Acc Evaluation: 0.08\n",
      "EPOCH: 5800; Loss: 0.1928681582212448, AUC: 0.9319550957072679, Acc Train: 0.0126422942206655; Loss 0.08478372544050217, AUC: 0.7893855393855395 Acc Evaluation: 0.08\n",
      "EPOCH: 6000; Loss: 0.19112905859947205, AUC: 0.9337670906530965, Acc Train: 0.01406523642732049; Loss 0.08841314911842346, AUC: 0.788216911137909 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 6200; Loss: 0.1937423050403595, AUC: 0.9354072082276119, Acc Train: 0.013134851138353765; Loss 0.11339762806892395, AUC: 0.7849393252199905 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 6400; Loss: 0.19090616703033447, AUC: 0.9350390848778757, Acc Train: 0.013572679509632224; Loss 0.07631097733974457, AUC: 0.7874408272017419 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 6600; Loss: 0.19039221107959747, AUC: 0.9358038002991157, Acc Train: 0.013901050788091068; Loss 0.07230260223150253, AUC: 0.7864064588336938 Acc Evaluation: 0.07\n",
      "EPOCH: 6800; Loss: 0.18719415366649628, AUC: 0.9377301701111046, Acc Train: 0.013572679509632224; Loss 0.08578714728355408, AUC: 0.787670686839086 Acc Evaluation: 0.07666666666666666\n",
      "EPOCH: 7000; Loss: 0.18808932602405548, AUC: 0.9375164564577153, Acc Train: 0.01368213660245184; Loss 0.07497122883796692, AUC: 0.7873427661629325 Acc Evaluation: 0.08\n",
      "EPOCH: 7200; Loss: 0.18626408278942108, AUC: 0.9394902566270831, Acc Train: 0.013955779334500876; Loss 0.09712619334459305, AUC: 0.7827886158187614 Acc Evaluation: 0.07666666666666666\n",
      "EPOCH: 7400; Loss: 0.18387934565544128, AUC: 0.940799598564285, Acc Train: 0.013353765323992994; Loss 0.09447196125984192, AUC: 0.7805903316558201 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 7600; Loss: 0.18310710787773132, AUC: 0.9414513824649671, Acc Train: 0.013299036777583187; Loss 0.09278443455696106, AUC: 0.7836529456851703 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 7800; Loss: 0.18279436230659485, AUC: 0.9420678548441174, Acc Train: 0.013517950963222418; Loss 0.09164312481880188, AUC: 0.7809359915648897 Acc Evaluation: 0.09\n",
      "EPOCH: 8000; Loss: 0.18124808371067047, AUC: 0.9427580783842588, Acc Train: 0.01368213660245184; Loss 0.09030047804117203, AUC: 0.7830375053607902 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 8200; Loss: 0.18072426319122314, AUC: 0.9432421865969883, Acc Train: 0.013627408056042031; Loss 0.07896444946527481, AUC: 0.7874677512151524 Acc Evaluation: 0.07666666666666666\n",
      "EPOCH: 8400; Loss: 0.181681826710701, AUC: 0.9444731305161989, Acc Train: 0.013408493870402802; Loss 0.1032874807715416, AUC: 0.7794781928097937 Acc Evaluation: 0.08\n",
      "EPOCH: 8600; Loss: 0.18015258014202118, AUC: 0.9446506832397871, Acc Train: 0.013627408056042031; Loss 0.09639396518468857, AUC: 0.7825119918415138 Acc Evaluation: 0.08\n",
      "EPOCH: 8800; Loss: 0.17833715677261353, AUC: 0.9456165160006983, Acc Train: 0.013572679509632224; Loss 0.09339313954114914, AUC: 0.7843723000947532 Acc Evaluation: 0.08\n",
      "EPOCH: 9000; Loss: 0.17773999273777008, AUC: 0.9461523362359224, Acc Train: 0.014010507880910683; Loss 0.09469495713710785, AUC: 0.7848786636468549 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 9200; Loss: 0.17699390649795532, AUC: 0.9470965585497079, Acc Train: 0.01368213660245184; Loss 0.09258463978767395, AUC: 0.7801225081630487 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 9400; Loss: 0.17612172663211823, AUC: 0.9472831563903221, Acc Train: 0.01324430823117338; Loss 0.08232292532920837, AUC: 0.7810533226333642 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 9600; Loss: 0.17500300705432892, AUC: 0.9480232832207649, Acc Train: 0.013408493870402802; Loss 0.08213247358798981, AUC: 0.7843961925302882 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 9800; Loss: 0.1775001883506775, AUC: 0.9487262510933567, Acc Train: 0.013572679509632224; Loss 0.10722288489341736, AUC: 0.7809333802057294 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 10000; Loss: 0.1754973977804184, AUC: 0.9484797711041396, Acc Train: 0.012751751313485113; Loss 0.07299953699111938, AUC: 0.7853070766272429 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 10200; Loss: 0.1740967333316803, AUC: 0.9501941178762376, Acc Train: 0.013463222416812609; Loss 0.09956523030996323, AUC: 0.7830524531408107 Acc Evaluation: 0.08666666666666667\n",
      "EPOCH: 10400; Loss: 0.17160911858081818, AUC: 0.9504444230555292, Acc Train: 0.013463222416812609; Loss 0.0797191634774208, AUC: 0.7822701859864022 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 10600; Loss: 0.17363378405570984, AUC: 0.9501853645131491, Acc Train: 0.013846322241681261; Loss 0.06884738057851791, AUC: 0.781913120140771 Acc Evaluation: 0.08666666666666667\n",
      "EPOCH: 10800; Loss: 0.17052821815013885, AUC: 0.9515262484422695, Acc Train: 0.013955779334500876; Loss 0.08365669846534729, AUC: 0.78516960507605 Acc Evaluation: 0.07333333333333333\n",
      "EPOCH: 11000; Loss: 0.16897417604923248, AUC: 0.9525716191474206, Acc Train: 0.013517950963222418; Loss 0.08637532591819763, AUC: 0.7817479741856042 Acc Evaluation: 0.08666666666666667\n",
      "EPOCH: 11200; Loss: 0.1687316596508026, AUC: 0.9528422820536757, Acc Train: 0.013791593695271453; Loss 0.0858382135629654, AUC: 0.7837548187080412 Acc Evaluation: 0.08666666666666667\n",
      "EPOCH: 11400; Loss: 0.168611541390419, AUC: 0.9526969611307807, Acc Train: 0.014010507880910683; Loss 0.07665994018316269, AUC: 0.7817552979975018 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 11600; Loss: 0.16812463104724884, AUC: 0.9536718253200541, Acc Train: 0.013955779334500876; Loss 0.09089062362909317, AUC: 0.7816738656135747 Acc Evaluation: 0.08333333333333333\n",
      "EPOCH: 11800; Loss: 0.1675356924533844, AUC: 0.9539408079406833, Acc Train: 0.014174693520140105; Loss 0.0761682316660881, AUC: 0.7819677485737776 Acc Evaluation: 0.08666666666666667\n",
      "EPOCH: 12000; Loss: 0.168119877576828, AUC: 0.9538334035081693, Acc Train: 0.0148861646234676; Loss 0.07157701998949051, AUC: 0.783564729770551 Acc Evaluation: 0.09\n",
      "EPOCH: 12200; Loss: 0.16594339907169342, AUC: 0.9551279054859696, Acc Train: 0.01406523642732049; Loss 0.08447998017072678, AUC: 0.7827427519475336 Acc Evaluation: 0.09\n",
      "EPOCH: 12400; Loss: 0.16566382348537445, AUC: 0.9551660888333424, Acc Train: 0.01428415061295972; Loss 0.07409640401601791, AUC: 0.7824533112994652 Acc Evaluation: 0.08666666666666667\n",
      "EPOCH: 12600; Loss: 0.1643771082162857, AUC: 0.9560360870796194, Acc Train: 0.014174693520140105; Loss 0.08343246579170227, AUC: 0.7847616927658507 Acc Evaluation: 0.09333333333333334\n",
      "EPOCH: 12800; Loss: 0.1660429686307907, AUC: 0.9558495661139328, Acc Train: 0.014338879159369527; Loss 0.06968336552381516, AUC: 0.7847678459684697 Acc Evaluation: 0.09333333333333334\n",
      "EPOCH: 13000; Loss: 0.16282397508621216, AUC: 0.9567920533789709, Acc Train: 0.01428415061295972; Loss 0.0782461017370224, AUC: 0.7794205327989112 Acc Evaluation: 0.09333333333333334\n",
      "EPOCH: 13200; Loss: 0.16329750418663025, AUC: 0.956732932987167, Acc Train: 0.014503064798598949; Loss 0.08855210989713669, AUC: 0.7782795489396321 Acc Evaluation: 0.09\n",
      "EPOCH: 13400; Loss: 0.16182370483875275, AUC: 0.9573872965534101, Acc Train: 0.0148861646234676; Loss 0.08057861030101776, AUC: 0.7828102870982288 Acc Evaluation: 0.09666666666666666\n",
      "EPOCH: 13600; Loss: 0.1643865555524826, AUC: 0.9573379910522308, Acc Train: 0.014831436077057794; Loss 0.06756068766117096, AUC: 0.7835783568631802 Acc Evaluation: 0.1\n",
      "EPOCH: 13800; Loss: 0.16269829869270325, AUC: 0.9584613113594587, Acc Train: 0.01466725043782837; Loss 0.09760996699333191, AUC: 0.7788364287844537 Acc Evaluation: 0.09\n",
      "EPOCH: 14000; Loss: 0.1616469919681549, AUC: 0.9587919144451094, Acc Train: 0.014940893169877408; Loss 0.09558482468128204, AUC: 0.778412788288048 Acc Evaluation: 0.08666666666666667\n",
      "EPOCH: 14200; Loss: 0.16139230132102966, AUC: 0.9587122775903252, Acc Train: 0.014776707530647986; Loss 0.0736987292766571, AUC: 0.7800307804205933 Acc Evaluation: 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "model = Model(256, 1024, 512, train_hetero_graph.etypes, len(train_hetero_graph.nodes(\"paper\")), len(train_hetero_graph.nodes(\"author\"))).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(5000000):\n",
    "    negative_graph = construct_negative_graph(train_hetero_graph, k, ('paper', 'authored', 'author'))\n",
    "    pos_score, neg_score = model.scores(train_hetero_graph.to(device), negative_graph.to(device), node_features, ('paper', 'authored', 'author'))\n",
    "    loss = compute_loss_logits(pos_score.to(device), neg_score.to(device))\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 200 == 0:\n",
    "        with torch.no_grad():\n",
    "          logits_train = model(train_hetero_graph.to(device), negative_graph.to(device), node_features, ('paper', 'authored', 'author'))\n",
    "          acc_train = accuracy(logits_train, train_hetero_graph.to(device))\n",
    "          auc_train = compute_auc(pos_score.cpu(), neg_score.cpu())\n",
    "          loss_train = loss.item()\n",
    "\n",
    "          loss_training_epoch.append(loss_train)\n",
    "          auc_training_epoch.append(auc_train)\n",
    "\n",
    "          logits_val = model(val_hetero_graph.to(device), \"x\", node_features, ('paper', 'authored', 'author'))\n",
    "          acc_val = accuracy(logits_val, val_hetero_graph.to(device))\n",
    "\n",
    "          negative_graph = construct_negative_graph(val_hetero_graph, k, ('paper', 'authored', 'author'))\n",
    "          pos_score_eval, neg_score_eval = model.scores(val_hetero_graph.to(device), negative_graph.to(device), node_features, ('paper', 'authored', 'author'))\n",
    "          loss_val = compute_loss_logits(pos_score_eval.to(device), neg_score.to(device)).item()\n",
    "          auc_val = compute_auc(pos_score_eval.cpu(), neg_score_eval.cpu())\n",
    "\n",
    "          loss_validation_epoch.append(loss_val)\n",
    "          auc_validation_epoch.append(auc_val)\n",
    "\n",
    "          acc_training.append(acc_train)\n",
    "          acc_validation.append(acc_val)\n",
    "\n",
    "          print(f\"EPOCH: {epoch}; Loss: {loss_train}, AUC: {auc_train}, Acc Train: {acc_train}; Loss {loss_val}, AUC: {auc_val} Acc Evaluation: {acc_val}\")\n",
    "\n",
    "    \"\"\"\n",
    "    if epoch % 50 == 0:\n",
    "\n",
    "      with torch.no_grad():\n",
    "        total_list  = loss_training_epoch + loss_validation_epoch + auc_training_epoch + auc_validation_epoch + acc_training + acc_validation\n",
    "        with open(f'./drive/MyDrive/Bachelor_thesis/models/author_metrics_{epoch}_final.txt', 'w') as f:\n",
    "          for item in total_list:\n",
    "              f.write(str(item) + '\\n')\n",
    "        torch.save(model, f\"./drive/MyDrive/Bachelor_thesis/models/author_{epoch}_final.pt\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyYKZsBgLOr3"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.save(model, f\"./drive/MyDrive/Bachelor_thesis/models/author.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMoF19H/rEZH825rkWCNIgP",
   "mount_file_id": "1AykyJvR2hyZp_Pg_8MtBxP4P9oAO0iiM",
   "provenance": [
    {
     "file_id": "1TLIn9qfhnzandkuoLTv-P6Y-gqUgQ31I",
     "timestamp": 1677150611244
    }
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
