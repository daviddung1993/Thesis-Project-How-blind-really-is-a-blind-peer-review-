{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-oVrk2WMbHi",
        "outputId": "bf45b63f-49f6-414a-a2f1-fed07e6987c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels/cu117/repo.html\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.9/dist-packages (1.0.1+cu117)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (5.9.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from dgl) (3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Requirement already satisfied: dglgo in /usr/local/lib/python3.9/dist-packages (0.0.2)\n",
            "Requirement already satisfied: numpydoc>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.5.0)\n",
            "Requirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.10.6)\n",
            "Requirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.9/dist-packages (from dglgo) (6.0)\n",
            "Requirement already satisfied: autopep8>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (2.0.2)\n",
            "Requirement already satisfied: ogb>=1.3.3 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.3.5)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.9/dist-packages (from dglgo) (2022.9.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.2.2)\n",
            "Requirement already satisfied: isort>=5.10.1 in /usr/local/lib/python3.9/dist-packages (from dglgo) (6.0.0b2)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.20 in /usr/local/lib/python3.9/dist-packages (from dglgo) (0.17.21)\n",
            "Requirement already satisfied: pycodestyle>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from autopep8>=1.6.0->dglgo) (2.10.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.9/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinx>=4.2 in /usr/local/lib/python3.9/dist-packages (from numpydoc>=1.1.0->dglgo) (6.1.3)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.9/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.13.1+cu116)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.26.15)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.9/dist-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.7)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.1.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.25.1)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (63.4.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: docutils<0.20,>=0.18 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.19)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (6.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8->sphinx>=4.2->numpydoc>=1.1.0->dglgo) (3.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.9/dist-packages (0.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import dgl\n",
        "import torch as th\n",
        "import numpy as np\n",
        "from dgl import save_graphs, load_graphs\n",
        "import torch.nn as nn\n",
        "import dgl.nn as dglnn\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "from torchmetrics.classification import BinaryAUROC\n",
        "import torch.nn as nn\n",
        "from dgl.dataloading.negative_sampler import _BaseNegativeSampler\n",
        "from dgl import backend as b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7OKjsl70Me-a"
      },
      "outputs": [],
      "source": [
        "glist, label_dict = load_graphs(\"./drive/MyDrive/Bachelor_thesis/models/hetero_graphs_primary_all_features_w_test.bin\")\n",
        "train_hetero_graph = glist[0]\n",
        "val_hetero_graph = glist[1]\n",
        "test_hetero_graph = glist[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xY3a7pwejU0G"
      },
      "outputs": [],
      "source": [
        "class PerSourceUniformCustom(_BaseNegativeSampler):\n",
        "\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "\n",
        "    def _generate(self, g, eids, canonical_etype):\n",
        "        unique_authors = torch.unique(g.edges(etype = \"authored\")[1])\n",
        "        #print(len(unique_authors))\n",
        "        _, _, vtype = canonical_etype\n",
        "        shape = b.shape(eids)\n",
        "        dtype = b.dtype(eids)\n",
        "        ctx = b.context(eids)\n",
        "        shape = (shape[0] * self.k,)\n",
        "        src, _ = g.find_edges(eids, etype=canonical_etype)\n",
        "        src = b.repeat(src, self.k, 0)\n",
        "        dst_indexes = th.randint(0, len(unique_authors), shape, dtype=dtype, device=ctx)\n",
        "        dst = unique_authors[dst_indexes]\n",
        "        return src, dst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jjiNOLmYMh61"
      },
      "outputs": [],
      "source": [
        "def construct_negative_graph(graph, k, etype):\n",
        "    utype, edge_type, vtype = etype\n",
        "    src, dst = graph.edges(etype=etype)\n",
        "    eids = graph.edge_ids(src, dst, etype=edge_type)\n",
        "    #eids = torch.unique(train_hetero_graph.edges(etype=\"authored\")[0])\n",
        "    neg_sampler = PerSourceUniformCustom(k)\n",
        "    #neg_samples = dgl.dataloading.negative_sampler.PerSourceUniform(k)\n",
        "    neg_src, neg_dst = neg_sampler(graph, {edge_type: eids})[etype]\n",
        "    return dgl.heterograph(\n",
        "        {etype: (neg_src, neg_dst)},\n",
        "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "au2Jb4o5MnGy"
      },
      "outputs": [],
      "source": [
        "class HeteroDotProductPredictor(nn.Module):\n",
        "    def forward(self, graph, h, etype):\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
        "            return graph.edges[etype].data['score']\n",
        "        \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features, rel_names, num_classes_paper, num_classes_author):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.sage = RGCN(in_features, hidden_features, out_features, num_classes_paper, num_classes_author)\n",
        "        # Decoder\n",
        "        self.pred = HeteroDotProductPredictor()\n",
        "    def forward(self, g, neg_g, x, etype):\n",
        "        h = self.sage(g, x)\n",
        "        return h\n",
        "\n",
        "    def scores(self, g, neg_g, x, etype):\n",
        "      h = self(g, neg_g, x, etype)\n",
        "      return self.pred(g, h, etype), self.pred(neg_g, h, etype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n4-Wo4fIS7D2"
      },
      "outputs": [],
      "source": [
        "class RGCN(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats, num_classes_papers, num_classes_authors):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv2 = dglnn.HeteroGraphConv({\n",
        "            \"cites\": dglnn.GraphConv(num_classes_authors, 512),\n",
        "        })\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.linear = nn.Linear(512, num_classes_authors)\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        classes_paper = inputs[\"paper\"]\n",
        "        classes_author = inputs[\"author\"]\n",
        "\n",
        "        h_cites = self.conv2(graph[\"cites\"], {\"paper\": classes_paper, \"author\": classes_author})[\"paper\"].flatten(1)\n",
        "        h_cites = self.dropout(h_cites)\n",
        "        h_cites = F.relu(h_cites)\n",
        "        h_cites = self.linear(h_cites)\n",
        "\n",
        "        return {\"paper\": h_cites, \"author\": classes_author}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TYXaLTytM3vC"
      },
      "outputs": [],
      "source": [
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).squeeze(1).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "    ).numpy()\n",
        "    return roc_auc_score(labels, scores)\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    # Margin loss\n",
        "    n_edges = pos_score.shape[0]\n",
        "    return (1 - pos_score + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
        "\n",
        "def compute_loss_logits(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).to(\"cuda\")\n",
        "    \n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "    ).to(\"cuda\")\n",
        "    return F.binary_cross_entropy_with_logits(scores.squeeze(1), labels)\n",
        "\n",
        "def accuracy(logits, graph):\n",
        "  with torch.no_grad():\n",
        "    all_papers = torch.unique(graph.edges(etype=\"authored\")[0])\n",
        "    src, dst = graph.edges(etype=\"authored\")\n",
        "    unique_authors = torch.unique(dst)\n",
        "    tst = 0\n",
        "    author_logits = logits[\"author\"][unique_authors]\n",
        "\n",
        "    for idx, index_paper in enumerate(all_papers):\n",
        "\n",
        "      current_logits = logits[\"paper\"][index_paper]\n",
        "      dot_product_all = torch.sum(current_logits * author_logits, dim=-1)\n",
        "\n",
        "      max = torch.argmax(dot_product_all)\n",
        "      max = unique_authors[max].item()\n",
        "      filter_acc = src == index_paper\n",
        "      if max in dst[filter_acc]:\n",
        "        tst += 1\n",
        "    return tst/len(all_papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "busP_ir1M4T8"
      },
      "outputs": [],
      "source": [
        "# Load data into GPU memory\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Yot1jK_JyCPy"
      },
      "outputs": [],
      "source": [
        "# Sum Pooling Genders\n",
        "train_hetero_graph.nodes[\"gender\"].data[\"h\"] = train_hetero_graph.nodes('gender').type(torch.float32)\n",
        "train_hetero_graph.nodes[\"author\"].data[\"h\"] = th.zeros(len(train_hetero_graph.nodes(\"author\")))\n",
        "train_hetero_graph[\"gendered\"].update_all(fn.copy_u('h', 'm'), fn.max('m', 'h'))\n",
        "author_genders = train_hetero_graph.nodes[\"author\"].data[\"h\"].view(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WjH8wf2MyGf_"
      },
      "outputs": [],
      "source": [
        "# Sum Pooling Countries\n",
        "country_feats = F.one_hot(train_hetero_graph.nodes('country')).type(torch.float32)\n",
        "train_hetero_graph.nodes[\"country\"].data[\"h\"] = country_feats\n",
        "train_hetero_graph.nodes[\"affiliation\"].data[\"h\"] = th.zeros((len(train_hetero_graph.nodes(\"affiliation\")), country_feats.shape[0]))\n",
        "train_hetero_graph[\"contains\"].update_all(fn.copy_u('h', 'm'), fn.max('m', 'h'))\n",
        "affiliation_countries = train_hetero_graph.nodes[\"affiliation\"].data[\"h\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iVlswu6lyHKl"
      },
      "outputs": [],
      "source": [
        "# Sum Pooling Affiliations\n",
        "affiliation_feats = F.one_hot(train_hetero_graph.nodes('affiliation')).type(torch.float32)\n",
        "train_hetero_graph.nodes[\"affiliation\"].data[\"h\"] = torch.concat([affiliation_feats, affiliation_countries], dim=1)\n",
        "train_hetero_graph.nodes[\"author\"].data[\"h\"] = th.zeros((len(train_hetero_graph.nodes(\"author\")), country_feats.shape[0]))\n",
        "train_hetero_graph[\"affiliated\"].update_all(fn.copy_u('h', 'm'), fn.max('m', 'h'))\n",
        "author_affiliation_country = train_hetero_graph.nodes[\"author\"].data[\"h\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3Wc1xZTWyLAS"
      },
      "outputs": [],
      "source": [
        "# Sum Pooling Authors\n",
        "author_feats = F.one_hot(train_hetero_graph.nodes['author'].data['feature']).type(torch.float32)\n",
        "author_feats = torch.concat([author_feats, author_genders, author_affiliation_country], dim=1)\n",
        "train_hetero_graph.nodes[\"author\"].data[\"h\"] = author_feats \n",
        "train_hetero_graph.nodes[\"paper\"].data[\"h\"] = th.zeros((len(train_hetero_graph.nodes['paper'].data['feature']), author_feats.shape[0]))\n",
        "train_hetero_graph[\"writes\"].update_all(fn.copy_u('h', 'm'), fn.max('m', 'h'))\n",
        "paper_feats = train_hetero_graph.nodes[\"paper\"].data[\"h\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-V9PTnAdPavU"
      },
      "outputs": [],
      "source": [
        "author_feats = F.one_hot(train_hetero_graph.nodes['author'].data['feature']).type(torch.float32)\n",
        "train_hetero_graph.nodes[\"author\"].data[\"h\"] = author_feats\n",
        "train_hetero_graph.nodes[\"paper\"].data[\"h\"] = th.zeros((len(train_hetero_graph.nodes['paper'].data['feature']), author_feats.shape[0]))\n",
        "train_hetero_graph[\"writes\"].update_all(fn.copy_u('h', 'm'), fn.max('m', 'h'))\n",
        "paper_feats = train_hetero_graph.nodes[\"paper\"].data[\"h\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rs0h9m7mNNe9"
      },
      "outputs": [],
      "source": [
        "node_features = {'paper': paper_feats.to(device), \"author\": author_feats.to(device)}\n",
        "\n",
        "\n",
        "k = 8\n",
        "loss_training_epoch = []\n",
        "loss_validation_epoch = []\n",
        "\n",
        "auc_training_epoch = []\n",
        "auc_validation_epoch = []\n",
        "\n",
        "acc_training = []\n",
        "acc_validation = []\n",
        "\n",
        "pred = HeteroDotProductPredictor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m49fF7jqNOVy",
        "outputId": "d47c931b-3a81-491f-b332-c01f98291655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 0; Loss: 0.6933674216270447, AUC: 0.5058396841721274, Acc Train: 0.005870020964360587; Loss 0.6934388279914856, AUC: 0.5120361111111111 Acc Evaluation: 0.006666666666666667\n",
            "EPOCH: 10; Loss: 0.6593655347824097, AUC: 0.7704891794013069, Acc Train: 0.13584905660377358; Loss 0.6532668471336365, AUC: 0.5977361111111111 Acc Evaluation: 0.04\n",
            "EPOCH: 20; Loss: 0.5308005213737488, AUC: 0.6927981378197944, Acc Train: 0.033962264150943396; Loss 0.48865777254104614, AUC: 0.5649972222222223 Acc Evaluation: 0.01\n",
            "EPOCH: 30; Loss: 0.3809870779514313, AUC: 0.6061314711531277, Acc Train: 0.012578616352201259; Loss 0.262660413980484, AUC: 0.5373951388888889 Acc Evaluation: 0.006666666666666667\n",
            "EPOCH: 40; Loss: 0.3369716703891754, AUC: 0.6365892040135543, Acc Train: 0.009643605870020965; Loss 0.14426401257514954, AUC: 0.5321 Acc Evaluation: 0.006666666666666667\n",
            "EPOCH: 50; Loss: 0.32721319794654846, AUC: 0.6996721516817637, Acc Train: 0.020545073375262055; Loss 0.12499365210533142, AUC: 0.5433416666666666 Acc Evaluation: 0.006666666666666667\n",
            "EPOCH: 60; Loss: 0.3128502368927002, AUC: 0.7439567263953166, Acc Train: 0.05450733752620545; Loss 0.14009730517864227, AUC: 0.5512638888888889 Acc Evaluation: 0.02\n",
            "EPOCH: 70; Loss: 0.2976321578025818, AUC: 0.8004419656395448, Acc Train: 0.09811320754716982; Loss 0.149277001619339, AUC: 0.5792708333333334 Acc Evaluation: 0.02666666666666667\n",
            "EPOCH: 80; Loss: 0.2818225026130676, AUC: 0.8579794114156877, Acc Train: 0.12117400419287212; Loss 0.1456286460161209, AUC: 0.5949166666666668 Acc Evaluation: 0.03\n",
            "EPOCH: 90; Loss: 0.26375266909599304, AUC: 0.9043240202347832, Acc Train: 0.19077568134171907; Loss 0.1361415833234787, AUC: 0.6340291666666666 Acc Evaluation: 0.03666666666666667\n",
            "EPOCH: 100; Loss: 0.24339482188224792, AUC: 0.9374153624373155, Acc Train: 0.3014675052410902; Loss 0.12815307080745697, AUC: 0.6712069444444444 Acc Evaluation: 0.09\n",
            "EPOCH: 110; Loss: 0.22124849259853363, AUC: 0.9619196563954485, Acc Train: 0.4494758909853249; Loss 0.1207280308008194, AUC: 0.6985270833333332 Acc Evaluation: 0.12666666666666668\n",
            "EPOCH: 120; Loss: 0.1992989480495453, AUC: 0.9779250886700157, Acc Train: 0.5685534591194968; Loss 0.11400279402732849, AUC: 0.7245069444444445 Acc Evaluation: 0.17666666666666667\n",
            "EPOCH: 130; Loss: 0.17706361413002014, AUC: 0.988396336291198, Acc Train: 0.670020964360587; Loss 0.10604988038539886, AUC: 0.7459590277777779 Acc Evaluation: 0.21\n",
            "EPOCH: 140; Loss: 0.15623068809509277, AUC: 0.993728381876596, Acc Train: 0.7534591194968554; Loss 0.09881816059350967, AUC: 0.7768493055555555 Acc Evaluation: 0.2633333333333333\n",
            "EPOCH: 150; Loss: 0.13617509603500366, AUC: 0.9967276039537818, Acc Train: 0.820125786163522; Loss 0.09131687134504318, AUC: 0.8011013888888889 Acc Evaluation: 0.29\n",
            "EPOCH: 160; Loss: 0.11769513040781021, AUC: 0.9984111256147568, Acc Train: 0.8729559748427673; Loss 0.08432585746049881, AUC: 0.81211875 Acc Evaluation: 0.32666666666666666\n",
            "EPOCH: 170; Loss: 0.10196822881698608, AUC: 0.9988799999120991, Acc Train: 0.9115303983228511; Loss 0.07862190157175064, AUC: 0.8180965277777777 Acc Evaluation: 0.37333333333333335\n",
            "EPOCH: 180; Loss: 0.08833629637956619, AUC: 0.9990259593282614, Acc Train: 0.9312368972746331; Loss 0.07370895147323608, AUC: 0.8258590277777778 Acc Evaluation: 0.39666666666666667\n",
            "EPOCH: 190; Loss: 0.07626727968454361, AUC: 0.9991462406989878, Acc Train: 0.949685534591195; Loss 0.069155253469944, AUC: 0.8298361111111111 Acc Evaluation: 0.41333333333333333\n",
            "EPOCH: 200; Loss: 0.06618005037307739, AUC: 0.9992229012565431, Acc Train: 0.9626834381551362; Loss 0.06539749354124069, AUC: 0.8306993055555555 Acc Evaluation: 0.41\n",
            "EPOCH: 210; Loss: 0.0577714629471302, AUC: 0.9992505131214043, Acc Train: 0.9756813417190776; Loss 0.06245807558298111, AUC: 0.8362548611111111 Acc Evaluation: 0.44\n",
            "EPOCH: 220; Loss: 0.05048818141222, AUC: 0.9994462354249348, Acc Train: 0.979454926624738; Loss 0.05986510217189789, AUC: 0.8383111111111111 Acc Evaluation: 0.44333333333333336\n",
            "EPOCH: 230; Loss: 0.045060139149427414, AUC: 0.9993106263377416, Acc Train: 0.9861635220125786; Loss 0.058248214423656464, AUC: 0.8439243055555555 Acc Evaluation: 0.44333333333333336\n",
            "EPOCH: 240; Loss: 0.040582045912742615, AUC: 0.9991516905537317, Acc Train: 0.9911949685534591; Loss 0.05722196772694588, AUC: 0.8475645833333333 Acc Evaluation: 0.44333333333333336\n",
            "EPOCH: 250; Loss: 0.034861091524362564, AUC: 0.9995568696737558, Acc Train: 0.9916142557651991; Loss 0.05434035882353783, AUC: 0.8479340277777777 Acc Evaluation: 0.45\n",
            "EPOCH: 260; Loss: 0.03287320211529732, AUC: 0.9991821591972891, Acc Train: 0.9928721174004193; Loss 0.055112242698669434, AUC: 0.8481979166666667 Acc Evaluation: 0.4533333333333333\n",
            "EPOCH: 270; Loss: 0.02893115021288395, AUC: 0.9994557616831261, Acc Train: 0.9932914046121594; Loss 0.05329045653343201, AUC: 0.8498770833333332 Acc Evaluation: 0.45666666666666667\n",
            "EPOCH: 280; Loss: 0.025975113734602928, AUC: 0.9995023381634869, Acc Train: 0.9920335429769392; Loss 0.05275944620370865, AUC: 0.8476368055555557 Acc Evaluation: 0.4533333333333333\n",
            "EPOCH: 290; Loss: 0.02466086484491825, AUC: 0.9992619731990208, Acc Train: 0.9953878406708595; Loss 0.05308426916599274, AUC: 0.8537215277777779 Acc Evaluation: 0.47333333333333333\n",
            "EPOCH: 300; Loss: 0.024014031514525414, AUC: 0.9991260454711268, Acc Train: 0.9949685534591195; Loss 0.054096613079309464, AUC: 0.8529951388888889 Acc Evaluation: 0.46\n",
            "EPOCH: 310; Loss: 0.021757857874035835, AUC: 0.9991784343973735, Acc Train: 0.9953878406708595; Loss 0.053380850702524185, AUC: 0.8583402777777778 Acc Evaluation: 0.45666666666666667\n",
            "EPOCH: 320; Loss: 0.019489513710141182, AUC: 0.9993409081919228, Acc Train: 0.9970649895178197; Loss 0.05228261649608612, AUC: 0.8570284722222222 Acc Evaluation: 0.4633333333333333\n",
            "EPOCH: 330; Loss: 0.018396232277154922, AUC: 0.9994194146680204, Acc Train: 0.9953878406708595; Loss 0.05256348475813866, AUC: 0.8596680555555555 Acc Evaluation: 0.47\n",
            "EPOCH: 340; Loss: 0.017541252076625824, AUC: 0.9993572028181023, Acc Train: 0.9962264150943396; Loss 0.052789755165576935, AUC: 0.8563694444444444 Acc Evaluation: 0.4666666666666667\n",
            "EPOCH: 350; Loss: 0.0178186297416687, AUC: 0.9991082675175471, Acc Train: 0.9966457023060796; Loss 0.05441812798380852, AUC: 0.8594159722222223 Acc Evaluation: 0.47\n",
            "EPOCH: 360; Loss: 0.016775768250226974, AUC: 0.9991899274378211, Acc Train: 0.9966457023060796; Loss 0.05423833429813385, AUC: 0.8609993055555556 Acc Evaluation: 0.47333333333333333\n",
            "EPOCH: 370; Loss: 0.014879131689667702, AUC: 0.9993941541517783, Acc Train: 0.9949685534591195; Loss 0.05303623154759407, AUC: 0.8625736111111111 Acc Evaluation: 0.47\n",
            "EPOCH: 380; Loss: 0.01356494054198265, AUC: 0.9995530240101262, Acc Train: 0.9958071278825996; Loss 0.05279792100191116, AUC: 0.8580180555555555 Acc Evaluation: 0.47\n",
            "EPOCH: 390; Loss: 0.012557652778923512, AUC: 0.9996199055944517, Acc Train: 0.9962264150943396; Loss 0.05245150998234749, AUC: 0.8597201388888889 Acc Evaluation: 0.4766666666666667\n",
            "EPOCH: 400; Loss: 0.014342174865305424, AUC: 0.9992263513661994, Acc Train: 0.9970649895178197; Loss 0.055107127875089645, AUC: 0.86255625 Acc Evaluation: 0.47\n",
            "EPOCH: 410; Loss: 0.011376244947314262, AUC: 0.9996576260608537, Acc Train: 0.9974842767295597; Loss 0.053091805428266525, AUC: 0.8616375000000001 Acc Evaluation: 0.4866666666666667\n",
            "EPOCH: 420; Loss: 0.012037532404065132, AUC: 0.9994750779021575, Acc Train: 0.9979035639412998; Loss 0.05421977862715721, AUC: 0.8609715277777777 Acc Evaluation: 0.48\n",
            "EPOCH: 430; Loss: 0.01182536780834198, AUC: 0.999445378391326, Acc Train: 0.9970649895178197; Loss 0.05490313470363617, AUC: 0.8624444444444443 Acc Evaluation: 0.48\n",
            "EPOCH: 440; Loss: 0.013357745483517647, AUC: 0.9992115840178615, Acc Train: 0.9974842767295597; Loss 0.05710544064640999, AUC: 0.8662006944444445 Acc Evaluation: 0.49\n",
            "EPOCH: 450; Loss: 0.01227650512009859, AUC: 0.9991971572854449, Acc Train: 0.9966457023060796; Loss 0.05656687915325165, AUC: 0.8679756944444443 Acc Evaluation: 0.4866666666666667\n",
            "EPOCH: 460; Loss: 0.01136951893568039, AUC: 0.9993101758457164, Acc Train: 0.9966457023060796; Loss 0.05649571120738983, AUC: 0.8656874999999999 Acc Evaluation: 0.47\n",
            "EPOCH: 470; Loss: 0.013118762522935867, AUC: 0.9989241261553472, Acc Train: 0.9962264150943396; Loss 0.05850525572896004, AUC: 0.8708020833333333 Acc Evaluation: 0.48\n",
            "EPOCH: 480; Loss: 0.01083201915025711, AUC: 0.9993868034404405, Acc Train: 0.9974842767295597; Loss 0.05669250339269638, AUC: 0.867075 Acc Evaluation: 0.47333333333333333\n",
            "EPOCH: 490; Loss: 0.010070727206766605, AUC: 0.9993806723538539, Acc Train: 0.9970649895178197; Loss 0.05619541555643082, AUC: 0.8706097222222222 Acc Evaluation: 0.46\n",
            "EPOCH: 500; Loss: 0.01004350371658802, AUC: 0.9993743874407218, Acc Train: 0.9974842767295597; Loss 0.05689140781760216, AUC: 0.8685152777777778 Acc Evaluation: 0.4866666666666667\n",
            "EPOCH: 510; Loss: 0.010870276018977165, AUC: 0.9992319989979299, Acc Train: 0.9974842767295597; Loss 0.05821908265352249, AUC: 0.8681777777777777 Acc Evaluation: 0.47\n",
            "EPOCH: 520; Loss: 0.010593349114060402, AUC: 0.9993323818062751, Acc Train: 0.9979035639412998; Loss 0.05841651186347008, AUC: 0.8679881944444444 Acc Evaluation: 0.4766666666666667\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5e52a9b0e7f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mlogits_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_hetero_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'paper'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'authored'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'author'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_hetero_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m           \u001b[0mauc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-902a0e664871>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(logits, graph)\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mdot_product_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_logits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mauthor_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_product_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0mmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_authors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0mfilter_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mindex_paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = Model(256, 1024, 512, train_hetero_graph.etypes, len(train_hetero_graph.nodes(\"paper\")), author_feats.shape[1]).to(device)\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "for epoch in range(5000000):\n",
        "    negative_graph = construct_negative_graph(train_hetero_graph, k, ('paper', 'authored', 'author'))\n",
        "    pos_score, neg_score = model.scores(train_hetero_graph.to(device), negative_graph.to(device), node_features, ('paper', 'authored', 'author'))\n",
        "    loss = compute_loss_logits(pos_score.to(device), neg_score.to(device))\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    if epoch % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "          logits_train = model(train_hetero_graph.to(device), negative_graph.to(device), node_features, ('paper', 'authored', 'author'))\n",
        "          acc_train = accuracy(logits_train, train_hetero_graph.to(device))\n",
        "          auc_train = compute_auc(pos_score.cpu(), neg_score.cpu())\n",
        "          loss_train = loss.item()\n",
        "\n",
        "          loss_training_epoch.append(loss_train)\n",
        "          auc_training_epoch.append(auc_train)\n",
        "\n",
        "          logits_val = model(val_hetero_graph.to(device), \"\", node_features, ('paper', 'authored', 'author'))\n",
        "          acc_val = accuracy(logits_val, val_hetero_graph.to(device))\n",
        "\n",
        "          negative_graph = construct_negative_graph(val_hetero_graph, k, ('paper', 'authored', 'author'))\n",
        "          pos_score_eval, neg_score_eval = model.scores(val_hetero_graph.to(device), negative_graph.to(device), node_features, ('paper', 'authored', 'author'))\n",
        "          loss_val = compute_loss_logits(pos_score_eval.to(device), neg_score.to(device)).item()\n",
        "          auc_val = compute_auc(pos_score_eval.cpu(), neg_score_eval.cpu())\n",
        "\n",
        "          loss_validation_epoch.append(loss_val)\n",
        "          auc_validation_epoch.append(auc_val)\n",
        "\n",
        "          acc_training.append(acc_train)\n",
        "          acc_validation.append(acc_val)\n",
        "\n",
        "          print(f\"EPOCH: {epoch}; Loss: {loss_train}, AUC: {auc_train}, Acc Train: {acc_train}; Loss {loss_val}, AUC: {auc_val} Acc Evaluation: {acc_val}\")\n",
        "    \"\"\"\n",
        "    if epoch % 50 == 0:\n",
        "      with torch.no_grad():\n",
        "        total_list  = loss_training_epoch + loss_validation_epoch + auc_training_epoch + auc_validation_epoch + acc_training + acc_validation\n",
        "        with open(f'./drive/MyDrive/Bachelor_thesis/models/author_metrics_{epoch}_final.txt', 'w') as f:\n",
        "          for item in total_list:\n",
        "              f.write(str(item) + '\\n')\n",
        "        torch.save(model, f\"./drive/MyDrive/Bachelor_thesis/models/author_{epoch}_final.pt\")\n",
        "    \"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
