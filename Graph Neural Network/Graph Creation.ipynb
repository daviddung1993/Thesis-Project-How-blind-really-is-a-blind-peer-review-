{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at C:\\Users\\david/.cache\\huggingface\\hub\\models--allenai--scibert_scivocab_uncased\\snapshots\\24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\david/.cache\\huggingface\\hub\\models--allenai--scibert_scivocab_uncased\\snapshots\\24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\david/.cache\\huggingface\\hub\\models--allenai--scibert_scivocab_uncased\\snapshots\\24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\david/.cache\\huggingface\\hub\\models--allenai--scibert_scivocab_uncased\\snapshots\\24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\david/.cache\\huggingface\\hub\\models--allenai--scibert_scivocab_uncased\\snapshots\\24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96bfe002eca74343881f9541a1a60f78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\david/.cache\\huggingface\\hub\\models--allenai--scibert_scivocab_uncased\\snapshots\\24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at allenai/scibert_scivocab_uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import mysql.connector\n",
    "import dgl.data\n",
    "import numpy as np\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch as th\n",
    "import gensim\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import requests\n",
    "from transformers import *\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "input_text = \"This is an example sentence.\"\n",
    "tokenized_input = tokenizer.encode_plus(input_text, return_tensors='pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.4281,  1.1507,  1.0390,  ...,  0.5818, -0.7117,  0.4247],\n         [-0.0830,  0.4637, -0.3874,  ...,  0.2196,  0.0861,  0.1827],\n         [ 0.9171,  0.1888, -0.6332,  ..., -1.0889,  0.5068,  0.2355],\n         ...,\n         [ 1.1826,  0.8551,  0.9354,  ...,  0.7910, -0.6270,  0.3596],\n         [ 1.2706,  1.2989,  1.0110,  ..., -0.5780, -1.8531,  0.3310],\n         [-0.3739,  0.8233,  0.6964,  ...,  0.2347, -0.6886,  0.3500]]],\n       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2122, -0.1372,  0.8959,  0.9986,  0.2182,  0.9992,  0.2944, -1.0000,\n          0.3152, -0.8880,  0.0150,  0.1978,  0.2651,  0.9643, -0.0364, -0.0407,\n         -0.2893, -0.1392, -0.9857, -0.9939, -0.0296,  0.2299,  0.5828,  0.1879,\n         -0.1929,  0.0944, -0.9982,  0.0736, -0.1445, -0.0243,  0.1224, -0.8223,\n         -0.1183, -0.3029,  0.5714,  0.2225,  0.9997, -0.1818,  0.2227,  0.9620,\n         -0.3864,  0.3054, -0.0241, -0.1188,  0.1441, -0.1537, -0.3257, -0.1348,\n         -0.9791, -0.8640,  0.4555, -0.1016, -0.1712,  0.9941,  0.9955, -0.1701,\n         -0.0404,  0.1355, -0.9705, -0.6622,  0.0549, -0.9944,  0.1001,  0.5797,\n          0.0319, -0.1291, -0.2363, -0.0745,  0.2500,  0.3934,  0.9999,  0.2383,\n          0.1263,  0.2064,  0.9959, -0.0286, -0.0514, -0.3007,  0.3879, -0.0639,\n          0.1377,  0.1024,  0.1902, -0.9993, -0.1093, -0.2601, -0.3121, -0.2185,\n          0.9756, -0.9677, -0.4127, -0.3717, -0.2885, -0.1018, -0.4527, -0.1122,\n         -0.0508,  0.5115, -0.0791, -0.3399, -0.0299,  0.3023, -0.1419, -0.3593,\n          0.0928, -0.0452,  0.0856, -0.2195, -0.3576, -0.1793, -0.1875,  0.0352,\n          0.0986, -0.0745, -0.2115, -0.3441,  0.9950,  0.2077, -0.0212,  0.3299,\n          0.1857,  0.9841,  0.9835, -0.2365, -0.1444, -0.1087, -0.4400,  0.4539,\n         -0.0530,  0.2569, -0.3022,  0.2960, -0.9996,  0.0106, -0.0187,  0.1846,\n          0.1511, -0.2913,  0.9903, -0.0580, -0.3604, -0.4293,  0.1104,  0.1497,\n         -0.3014, -0.9966,  0.9950,  0.0024,  0.2106,  0.1645, -0.1480,  0.1077,\n         -0.2906,  1.0000,  0.4430, -0.0600,  0.2743,  0.9118,  0.8211,  0.8463,\n         -0.0050, -0.1416,  0.0441, -0.3050,  0.1922,  0.9901,  0.1815,  0.9513,\n         -0.9823, -0.0882, -0.0989,  0.8640,  0.2320, -0.1624, -0.9882,  0.0758,\n         -0.0675, -0.2080, -0.9165,  0.9857, -0.2253,  0.9840, -0.0696,  0.2731,\n          0.0321, -0.7757, -0.0590,  0.2566, -0.0518,  0.3140,  0.1306,  0.3697,\n         -0.2026,  0.0885, -1.0000,  0.1970,  0.0281, -0.2628, -0.0960,  0.0859,\n          0.2338, -0.9854,  0.1034, -0.3374,  0.2150,  0.2429, -0.1357,  0.3921,\n         -0.9998, -0.0243,  0.3894, -0.9761,  0.1188, -0.0883,  0.5495, -0.1142,\n          0.5090, -0.9537,  0.1198,  0.1492,  0.0517,  0.6131, -0.0081,  0.0429,\n          0.6896, -0.8088, -0.2267,  0.3780, -0.3314, -0.8055, -0.0179, -1.0000,\n         -0.1862,  0.6933, -0.2737,  0.1706,  0.1993,  0.3492, -0.2597,  0.0075,\n          0.3506,  0.9966, -0.2528, -0.9479, -0.0341,  0.9998,  0.0311, -0.0623,\n         -0.9754,  0.2043,  0.0059, -0.5506, -0.9780, -0.2632, -0.1343, -0.5132,\n          0.9976, -0.9690,  0.8807, -0.0989, -0.0854,  0.7098, -0.9106, -0.0153,\n         -0.0527, -0.1048, -0.8972,  0.8202, -0.1733,  0.3892, -0.1924, -0.9994,\n         -0.9300,  0.4305, -0.1968, -0.8030, -0.4441, -0.7063,  0.2707, -0.1326,\n          0.0176, -0.0946,  0.1438, -0.1029, -0.2761,  0.0716,  0.1691, -0.3405,\n         -0.2524,  0.1842,  0.9998,  0.9957, -0.0368, -0.5791, -0.4680,  0.6673,\n         -0.3273,  0.9902,  0.3567,  0.9440,  0.0430,  0.5444,  0.1541, -0.7701,\n         -0.9761, -0.2048, -0.5386,  0.2835, -0.1739, -0.9592, -0.9978,  0.1925,\n         -0.0815,  0.5300, -0.1686,  0.9176,  0.1335, -0.0825,  0.9963, -0.8628,\n         -0.2319, -0.1871, -0.0840,  0.0434,  0.9783, -0.2319, -0.1392, -0.7390,\n         -0.9993, -0.0650, -0.2225, -0.7130,  0.9786,  0.2041, -0.0320, -0.2326,\n          0.9559, -0.0631, -0.9358,  0.2413, -0.1100,  0.4119,  0.1278, -0.3066,\n          0.1381, -0.4969, -0.2908, -0.0108, -0.1939, -0.2343, -0.0837,  0.0183,\n          0.4509, -0.1302,  0.2950, -0.1367,  0.0420, -0.5587, -0.1746,  0.0561,\n         -0.2903,  0.0239,  0.1407, -0.8646, -0.3832,  0.3079, -0.0798, -0.1400,\n          0.1462,  0.2380,  0.1911, -0.3693,  0.2804,  0.2609,  0.9815,  0.9417,\n          0.0341,  0.4416, -0.3303,  0.0303,  0.1902, -0.1328, -0.3528, -0.1052,\n          0.4310,  0.0801, -0.2078, -0.0840,  0.9090,  0.9399,  0.1867,  0.1135,\n         -0.1538, -0.5600,  0.5139,  0.1440,  0.2820,  0.9962, -0.0603, -0.2132,\n         -0.9997, -0.1962,  0.1362,  0.4103, -0.4241, -0.2279,  0.9668, -0.9154,\n          0.0433, -0.0574, -0.0476, -0.2768,  0.1652, -0.0160,  0.7049, -0.2374,\n         -0.0197,  0.0765, -0.2837,  0.0867,  0.0857, -0.4472, -0.1871,  0.9483,\n         -0.3548, -0.3434, -0.0968,  0.2012,  0.0868,  0.0223,  0.2969,  0.8792,\n         -0.9887,  0.9931, -0.9662,  0.4176, -0.0778,  0.2305, -0.0294, -0.4113,\n         -0.2621, -0.3005, -0.9784,  0.1008,  0.1399,  0.0729, -0.0793,  0.0938,\n         -0.9947, -0.0859, -0.7045, -0.1582,  0.2215,  0.9590, -0.2055,  0.0642,\n          0.2847, -0.9961,  0.0500,  0.1546, -0.0859, -0.0574,  0.0358,  0.9913,\n         -0.2089, -0.9945,  0.1043, -0.2199,  0.0820,  0.2836,  0.9888, -0.4558,\n         -0.5672,  0.1870,  0.6532, -0.2444, -0.1358, -0.3072, -0.1443, -0.7325,\n         -0.4734, -0.3360,  0.3092, -0.1197,  0.2326,  0.0121,  0.0237, -0.9994,\n         -0.2137, -0.1218, -0.9972,  0.2459, -0.2432, -0.2756,  0.0343,  0.0069,\n          0.1131, -0.0279, -0.3568,  0.0235, -0.9950, -0.9940,  0.9994, -0.0232,\n         -0.4317, -0.8861, -0.9858, -0.3605,  0.9977, -0.0694, -0.8739, -0.1418,\n          0.9473,  0.0869,  0.2201, -0.0608, -0.1719,  0.0447,  0.1112,  0.0396,\n         -0.3965, -0.0262,  0.9994,  0.4886, -0.2110,  0.0463, -0.3347,  1.0000,\n          0.9167, -0.2967, -0.9957, -0.2067, -0.0174,  0.2883, -0.3158,  0.4290,\n          0.4655, -0.5837, -0.9586, -0.2502,  0.1091,  0.8711,  0.4218, -0.8263,\n          0.0966,  0.0478, -0.9998, -0.7102,  0.2526, -0.0619,  0.0113, -0.0035,\n          0.0504,  0.6975,  0.5859, -0.2947, -0.1892,  0.4114, -0.4383,  0.9900,\n         -0.4882,  0.3330, -0.1307,  0.2341,  0.9997,  0.4025, -0.1410,  0.9956,\n         -0.2667,  0.0987, -0.3870, -0.3507,  0.2126,  0.9167,  0.8780,  0.1485,\n          0.1582,  0.4279,  0.0978, -0.1401,  0.9464,  0.9997,  0.9991, -0.6097,\n          0.1546, -0.0344, -0.3174, -0.0772,  0.3306,  0.1697,  0.0424,  0.9185,\n          0.9894, -0.0894,  0.1633, -0.5437,  0.0526,  0.2885, -0.2298,  0.1045,\n         -0.2191, -0.2272,  0.9947, -0.1520, -0.0397,  0.5440, -0.1470, -0.2109,\n          0.1178, -0.0318, -0.9994,  0.1083,  0.2159, -0.0255,  0.0077,  0.9986,\n          0.0543,  0.0540,  0.9786, -0.1606,  0.3154, -0.8461, -0.1140, -0.3854,\n         -0.0016, -0.2084,  0.9835, -0.9949, -0.0630,  0.9934, -0.9999, -0.0920,\n          0.0804,  0.3165,  0.4053, -0.7244, -0.5479,  0.2791, -0.2070, -0.9910,\n          0.9883, -0.9990,  0.0446,  0.2791,  0.2374, -0.9890,  0.2115,  0.2018,\n         -0.5547,  0.4214, -0.0208,  0.9484,  0.9794, -0.3771, -0.1589, -0.3726,\n         -0.1070, -0.1355, -0.0104, -0.9435, -0.3226,  0.5121,  0.1241, -0.0794,\n         -0.1782,  0.7879, -0.1455, -0.8334, -0.3979,  0.2096, -0.0943,  0.9921,\n         -0.2182, -0.9277,  0.2160,  0.9950, -0.9280, -0.0545, -0.3081,  0.1296,\n          0.7432, -0.9980,  0.1968, -0.2622, -0.3556, -0.0512, -0.9120,  0.2976,\n          0.4964, -0.9968,  0.2888,  0.2417, -0.1405,  0.0652,  0.9941, -0.0610,\n         -0.4110,  0.2169, -0.9559, -0.0177,  0.1670,  0.9999,  0.8470, -0.3403,\n          0.2163,  0.2457, -0.1606, -0.9514, -0.0822,  0.2946, -0.0644,  0.4268,\n          0.5910, -0.1724, -0.0302,  0.1144, -0.9993, -0.0016, -0.9789, -0.9983,\n         -0.3199, -0.1517,  0.9630,  0.2454,  0.2561, -0.9987,  0.0265,  0.1944,\n         -0.0422, -0.9978, -0.1457,  0.0362,  0.3107, -0.0403,  0.9591,  0.9498,\n          0.1429, -0.0956,  0.0531,  0.3745, -0.0138,  0.9997, -0.0071,  0.5039,\n          0.0979,  0.9968,  0.0530,  0.1850,  0.1108,  0.1002, -0.4968,  0.9804,\n          0.2094,  0.1002, -0.1251,  0.3788,  0.0263,  0.9980, -0.3321, -0.3659,\n         -0.9930,  0.1896,  0.5042, -0.0898, -0.1556, -0.0708,  0.8117, -0.3957]],\n       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**tokenized_input)\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Connect to database"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user='david', password='daviddung1993',\n",
    "                          host='127.0.0.1',\n",
    "                          database='computervision')\n",
    "cursor = cnx.cursor()\n",
    "headers = {\"x-api-key\": \"M7HSjQNeTfai6l7JUiDZB8XYc85BHnHt3R0NXSEd\"}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "test_papers = []\n",
    "with open(r'./test_papers.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        x = line[:-1]\n",
    "        test_papers.append(x)\n",
    "in_params_test = ','.join(['%s'] * len(test_papers))\n",
    "\n",
    "train_papers = []\n",
    "with open(r'./train_papers.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        x = line[:-1]\n",
    "        train_papers.append(x)\n",
    "\n",
    "total_papers = train_papers + test_papers\n",
    "in_params_train = ','.join(['%s'] * len(train_papers))\n",
    "\n",
    "val_papers = []\n",
    "with open(r'./val_papers.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        x = line[:-1]\n",
    "        val_papers.append(x)\n",
    "\n",
    "in_params_val = ','.join(['%s'] * len(val_papers))\n",
    "in_params = ','.join(['%s'] * len(train_papers + test_papers))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch Data primary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def remap(x, mapping):\n",
    "    return mapping.get(x, x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cursor.execute(\"select b.ReferenceID, b.ReferencedByID from referencedBy b, Papers p where b.ReferencedByID in (%s) and b.ReferenceID = p.PaperID and p.`primary author` in (select AuthorID from affiliatedTo) and b.ReferenceID in (select PaperID from Papers) and b.ReferencedByID in (select PaperID from Papers)\" % in_params, total_papers)\n",
    "paper_edges = np.array(cursor.fetchall())\n",
    "all_papers = np.unique(paper_edges)\n",
    "\n",
    "remapped_papers = {all_papers[i]: i  for i in range(len(all_papers))}\n",
    "vec_remap = np.vectorize(remap, otypes=[str])\n",
    "paper_edges = vec_remap(paper_edges, remapped_papers)\n",
    "\n",
    "all_papers_list = all_papers.tolist()\n",
    "all_params = ','.join(['%s'] * len(all_papers_list))\n",
    "\n",
    "cursor.execute(\"select p.PaperID, p.`primary author`, a.Gender, p.Title from Papers p, Authors a where p.PaperID in (%s) and p.`primary author` in (select AuthorID from affiliatedTo) and p.`primary author` = a.AuthorID\" % all_params, all_papers_list)\n",
    "author_edges = np.array(cursor.fetchall())\n",
    "\n",
    "all_authors = np.unique(author_edges[:,1])\n",
    "remapped_authors = {all_authors[i]: i  for i in range(len(all_authors))}\n",
    "\n",
    "author_edges[:,1] = vec_remap(author_edges[:,1], remapped_authors)\n",
    "author_edges[:,0] = vec_remap(author_edges[:,0], remapped_papers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create features for each node"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model_path = './GoogleNews-vectors-negative300.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def title_to_vec(title):\n",
    "    title = title.replace(\"-\", \" \")\n",
    "    tokens = nltk.word_tokenize(title)\n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    vectors = []\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec = model[word.lower()]\n",
    "            vectors.append(vec)\n",
    "        except KeyError:\n",
    "            #print(word)\n",
    "            continue\n",
    "    title_vector = None\n",
    "    try:\n",
    "        title_vector = sum(vectors) / len(vectors)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    return title_vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_3248\\1550066203.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  paper_feats = torch.tensor(paper_feats)\n"
     ]
    }
   ],
   "source": [
    "all_papers_info = pd.DataFrame(author_edges)\n",
    "all_papers_info[0] = all_papers_info[0].astype(int)\n",
    "all_papers_info = all_papers_info.sort_values(0)\n",
    "paper_feats = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for title in all_papers_info[3]:\n",
    "    title_vec = title_to_vec(title)\n",
    "    paper_feats.append(title_vec)\n",
    "paper_feats = torch.tensor(paper_feats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "headers = {\"x-api-key\": \"M7HSjQNeTfai6l7JUiDZB8XYc85BHnHt3R0NXSEd\"}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def request_author_information(authors):\n",
    "    resp = requests.post(\"https://api.semanticscholar.org/graph/v1/author/batch?fields=papers.title\", headers=headers, json={\"ids\": authors}).json()\n",
    "    return resp\n",
    "\n",
    "def request_author_individual_dfinformation(authors):\n",
    "    resp = requests.post(\"https://api.semanticscholar.org/graph/v1/author/batch?fields=papers.title\", headers=headers, json={\"ids\": authors}).json()\n",
    "    return resp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/18318\n",
      "100\n",
      "100/18318\n",
      "100\n",
      "200/18318\n",
      "100\n",
      "300/18318\n",
      "100\n",
      "400/18318\n",
      "100\n",
      "500/18318\n",
      "100\n",
      "600/18318\n",
      "100\n",
      "700/18318\n",
      "100\n",
      "800/18318\n",
      "100\n",
      "zero_vector\n",
      "900/18318\n",
      "100\n",
      "1000/18318\n",
      "100\n",
      "zero_vector\n",
      "zero_vector\n",
      "1100/18318\n",
      "100\n",
      "zero_vector\n",
      "zero_vector\n",
      "1200/18318\n",
      "100\n",
      "zero_vector\n",
      "zero_vector\n",
      "1300/18318\n",
      "100\n",
      "zero_vector\n",
      "zero_vector\n",
      "1400/18318\n",
      "100\n",
      "zero_vector\n",
      "1500/18318\n",
      "100\n",
      "1600/18318\n",
      "100\n",
      "1700/18318\n",
      "100\n",
      "zero_vector\n",
      "1800/18318\n",
      "100\n",
      "1900/18318\n",
      "100\n",
      "2000/18318\n",
      "100\n",
      "zero_vector\n",
      "2100/18318\n",
      "100\n",
      "2200/18318\n",
      "100\n",
      "2300/18318\n",
      "100\n",
      "2400/18318\n",
      "100\n",
      "2500/18318\n",
      "100\n",
      "zero_vector\n",
      "2600/18318\n",
      "100\n",
      "zero_vector\n",
      "2700/18318\n",
      "100\n",
      "zero_vector\n",
      "2800/18318\n",
      "100\n",
      "2900/18318\n",
      "100\n",
      "3000/18318\n",
      "100\n",
      "3100/18318\n",
      "100\n",
      "3200/18318\n",
      "100\n",
      "3300/18318\n",
      "100\n",
      "3400/18318\n",
      "100\n",
      "3500/18318\n",
      "100\n",
      "3600/18318\n",
      "100\n",
      "zero_vector\n",
      "zero_vector\n",
      "zero_vector\n",
      "zero_vector\n",
      "zero_vector\n",
      "3700/18318\n",
      "100\n",
      "zero_vector\n",
      "zero_vector\n",
      "zero_vector\n",
      "3800/18318\n",
      "100\n",
      "zero_vector\n",
      "3900/18318\n",
      "100\n",
      "zero_vector\n",
      "4000/18318\n",
      "100\n",
      "zero_vector\n",
      "4100/18318\n",
      "100\n",
      "zero_vector\n",
      "4200/18318\n",
      "100\n",
      "4300/18318\n",
      "100\n",
      "4400/18318\n",
      "100\n",
      "4500/18318\n",
      "100\n",
      "4600/18318\n",
      "100\n",
      "4700/18318\n",
      "100\n",
      "zero_vector\n",
      "4800/18318\n",
      "100\n",
      "4900/18318\n",
      "100\n",
      "5000/18318\n",
      "100\n",
      "5100/18318\n",
      "100\n",
      "5200/18318\n",
      "100\n",
      "5300/18318\n",
      "100\n",
      "5400/18318\n",
      "100\n",
      "5500/18318\n",
      "100\n",
      "5600/18318\n",
      "100\n",
      "5700/18318\n",
      "100\n",
      "5800/18318\n",
      "100\n",
      "5900/18318\n",
      "100\n",
      "6000/18318\n",
      "100\n",
      "6100/18318\n",
      "100\n",
      "6200/18318\n",
      "100\n",
      "6300/18318\n",
      "100\n",
      "6400/18318\n",
      "100\n",
      "6500/18318\n",
      "100\n",
      "zero_vector\n",
      "6600/18318\n",
      "100\n",
      "6700/18318\n",
      "100\n",
      "6800/18318\n",
      "100\n",
      "6900/18318\n",
      "100\n",
      "7000/18318\n",
      "100\n",
      "7100/18318\n",
      "100\n",
      "7200/18318\n",
      "100\n",
      "7300/18318\n",
      "100\n",
      "7400/18318\n",
      "100\n",
      "7500/18318\n",
      "100\n",
      "7600/18318\n",
      "100\n",
      "7700/18318\n",
      "100\n",
      "7800/18318\n",
      "100\n",
      "7900/18318\n",
      "100\n",
      "8000/18318\n",
      "100\n",
      "8100/18318\n",
      "100\n",
      "8200/18318\n",
      "100\n",
      "8300/18318\n",
      "100\n",
      "8400/18318\n",
      "100\n",
      "8500/18318\n",
      "100\n",
      "8600/18318\n",
      "100\n",
      "8700/18318\n",
      "100\n",
      "8800/18318\n",
      "100\n",
      "8900/18318\n",
      "100\n",
      "9000/18318\n",
      "100\n",
      "9100/18318\n",
      "100\n",
      "9200/18318\n",
      "100\n",
      "9300/18318\n",
      "100\n",
      "9400/18318\n",
      "100\n",
      "9500/18318\n",
      "100\n",
      "9600/18318\n",
      "100\n",
      "9700/18318\n",
      "100\n",
      "9800/18318\n",
      "100\n",
      "9900/18318\n",
      "100\n",
      "10000/18318\n",
      "100\n",
      "10100/18318\n",
      "100\n",
      "10200/18318\n",
      "100\n",
      "10300/18318\n",
      "100\n",
      "10400/18318\n",
      "100\n",
      "10500/18318\n",
      "100\n",
      "10600/18318\n",
      "100\n",
      "10700/18318\n",
      "100\n",
      "10800/18318\n",
      "100\n",
      "10900/18318\n",
      "100\n",
      "11000/18318\n",
      "100\n",
      "11100/18318\n",
      "100\n",
      "11200/18318\n",
      "100\n",
      "11300/18318\n",
      "100\n",
      "11400/18318\n",
      "100\n",
      "11500/18318\n",
      "100\n",
      "11600/18318\n",
      "100\n",
      "11700/18318\n",
      "100\n",
      "11800/18318\n",
      "100\n",
      "11900/18318\n",
      "100\n",
      "12000/18318\n",
      "100\n",
      "12100/18318\n",
      "100\n",
      "12200/18318\n",
      "100\n",
      "12300/18318\n",
      "100\n",
      "12400/18318\n",
      "100\n",
      "12500/18318\n",
      "100\n",
      "12600/18318\n",
      "100\n",
      "12700/18318\n",
      "100\n",
      "12800/18318\n",
      "100\n",
      "12900/18318\n",
      "100\n",
      "13000/18318\n",
      "100\n",
      "13100/18318\n",
      "100\n",
      "13200/18318\n",
      "100\n",
      "13300/18318\n",
      "100\n",
      "13400/18318\n",
      "100\n",
      "13500/18318\n",
      "100\n",
      "13600/18318\n",
      "100\n",
      "13700/18318\n",
      "100\n",
      "13800/18318\n",
      "100\n",
      "13900/18318\n",
      "100\n",
      "14000/18318\n",
      "100\n",
      "14100/18318\n",
      "100\n",
      "14200/18318\n",
      "100\n",
      "14300/18318\n",
      "100\n",
      "14400/18318\n",
      "100\n",
      "14500/18318\n",
      "100\n",
      "14600/18318\n",
      "100\n",
      "14700/18318\n",
      "100\n",
      "14800/18318\n",
      "100\n",
      "14900/18318\n",
      "100\n",
      "15000/18318\n",
      "100\n",
      "15100/18318\n",
      "100\n",
      "15200/18318\n",
      "100\n",
      "15300/18318\n",
      "100\n",
      "15400/18318\n",
      "100\n",
      "15500/18318\n",
      "100\n",
      "zero_vector\n",
      "zero_vector\n",
      "zero_vector\n",
      "15600/18318\n",
      "100\n",
      "zero_vector\n",
      "zero_vector\n",
      "15700/18318\n",
      "100\n",
      "15800/18318\n",
      "100\n",
      "zero_vector\n",
      "zero_vector\n",
      "zero_vector\n",
      "15900/18318\n",
      "100\n",
      "16000/18318\n",
      "100\n",
      "16100/18318\n",
      "100\n",
      "16200/18318\n",
      "100\n",
      "16300/18318\n",
      "100\n",
      "16400/18318\n",
      "100\n",
      "16500/18318\n",
      "100\n",
      "16600/18318\n",
      "100\n",
      "16700/18318\n",
      "100\n",
      "16800/18318\n",
      "100\n",
      "16900/18318\n",
      "100\n",
      "17000/18318\n",
      "100\n",
      "17100/18318\n",
      "100\n",
      "17200/18318\n",
      "100\n",
      "17300/18318\n",
      "100\n",
      "17400/18318\n",
      "100\n",
      "17500/18318\n",
      "100\n",
      "17600/18318\n",
      "100\n",
      "17700/18318\n",
      "100\n",
      "17800/18318\n",
      "100\n",
      "17900/18318\n",
      "100\n",
      "18000/18318\n",
      "100\n",
      "18100/18318\n",
      "100\n",
      "18200/18318\n",
      "100\n",
      "18300/18318\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "index = 0\n",
    "start = 100\n",
    "author_feats = []\n",
    "while start*index <= len(all_authors):\n",
    "    print(f\"{start*index}/{len(all_authors)}\")\n",
    "    batch_authors = all_authors[start*index: (start*index)+start]\n",
    "    index += 1\n",
    "    while True:\n",
    "        response_batch = request_author_information(batch_authors.tolist())\n",
    "        if \"message\" not in response_batch:\n",
    "            break\n",
    "        time.sleep(2)\n",
    "    print(len(response_batch))\n",
    "    #print(response_batch)\n",
    "    for response in response_batch:\n",
    "        if not response:\n",
    "            author_hist = np.zeros(300)\n",
    "            author_feats.append(author_hist)\n",
    "            continue\n",
    "\n",
    "        author_papers = response[\"papers\"]\n",
    "        #print(author_papers)\n",
    "        author_hist = []\n",
    "        for paper in author_papers:\n",
    "            paperID = paper[\"paperId\"]\n",
    "            if paperID in test_papers or paperID in train_papers:\n",
    "                #paperID in train_papers or\n",
    "                continue\n",
    "            title = paper[\"title\"]\n",
    "            title_vect = title_to_vec(title)\n",
    "            if title_vect is not None:\n",
    "                author_hist.append(title_vect)\n",
    "        if len(author_hist) != 0:\n",
    "            author_hist = np.mean(np.array(author_hist), axis=0)\n",
    "        else:\n",
    "            author_hist = np.zeros(300)\n",
    "            print(\"zero_vector\")\n",
    "        author_feats.append(author_hist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "author_feats_vec = torch.tensor(author_feats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([18318, 300])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_feats_vec.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "link = f\"https://api.semanticscholar.org/graph/v1/paper/search?query={text}\"\n",
    "response = requests.get(link, headers=headers).json()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "cursor.execute(\"select distinct p.`primary author` from Papers p where p.PaperID in (%s)\" % in_params, total_papers)\n",
    "authors_in_question = np.array(cursor.fetchall()).flatten()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch the Gender"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "all_params_gender = ','.join(['%s'] * len(all_authors))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "cursor.execute(\"select distinct AuthorID, Gender from Authors a where a.AuthorID in (%s)\" % all_params_gender, all_authors.tolist())\n",
    "gender_edges = np.array(cursor.fetchall())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "gender_edges[:,0] = vec_remap(gender_edges[:,0], remapped_authors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch the affiliation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "cursor.execute(\"select p.PaperID, p.`primary author`, b.AffiliationID, b.Country from Papers p, affiliatedTo af, Affiliations b where p.PaperID in (%s) and p.`primary author` in (select AuthorID from affiliatedTo) and p.`primary author` = af.AuthorID and af.affiliatedTo = b.AffiliationID\" % all_params, all_papers_list)\n",
    "author_info = np.array(cursor.fetchall())\n",
    "\n",
    "all_affiliations = np.unique(author_info[:,2])\n",
    "remapped_affiliations = {all_affiliations[i]: i  for i in range(len(all_affiliations))}\n",
    "\n",
    "all_countries = np.unique(author_info[:,3])\n",
    "remapped_countries = {all_countries[i]: i  for i in range(len(all_countries))}\n",
    "\n",
    "author_info[:,2] = vec_remap(author_info[:,2], remapped_affiliations)\n",
    "author_info[:,3] = vec_remap(author_info[:,3], remapped_countries)\n",
    "author_info[:,1] = vec_remap(author_info[:,1], remapped_authors)\n",
    "author_info[:,0] = vec_remap(author_info[:,0], remapped_papers)\n",
    "\n",
    "affiliation_edges = author_info[:,[2,1]]\n",
    "affiliation_edges = np.unique(affiliation_edges, axis=0)\n",
    "\n",
    "country_edges = author_info[:,[3,2]]\n",
    "country_edges = np.unique(country_edges, axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fetch data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cursor.execute(\"select * from referencedBy b where b.ReferenceID in (select PaperID from Papers) and b.ReferencedByID in (select PaperID from Papers)\")\n",
    "paper_edges = np.array(cursor.fetchall())\n",
    "all_papers = np.unique(paper_edges)\n",
    "remapped_papers = {all_papers[i]: i  for i in range(len(all_papers))}\n",
    "vec_remap = np.vectorize(remap, otypes=[str])\n",
    "paper_edges = vec_remap(paper_edges, remapped_papers)\n",
    "\n",
    "cursor.execute(\"select * from authoredBy where PaperID in (select PaperID from Papers) and (PaperID in (select ReferenceID from referencedBy) or PaperID in (select ReferencedByID from referencedBy)) and PaperID in (select p.PaperID from Papers p where p.Leaf = FALSE) and AuthoredByID in (select a.AuthorID from affiliatedTo a)\")\n",
    "\n",
    "author_edges = np.array(cursor.fetchall())\n",
    "\n",
    "all_authors = np.unique(author_edges[:,1])\n",
    "remapped_authors = {all_authors[i]: i  for i in range(len(all_authors))}\n",
    "\n",
    "author_edges[:,1] = vec_remap(author_edges[:,1], remapped_authors)\n",
    "author_edges[:,0] = vec_remap(author_edges[:,0], remapped_papers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "cursor.execute(\"select distinct b.AuthoredByID from Papers p, authoredBy b where p.Leaf = False and p.PaperID in (%s) and p.PaperID = b.PaperID and b.AuthoredByID in (select a.AuthorID from affiliatedTo a)\" % in_params, train_papers+test_papers)\n",
    "authors_in_question = np.array(cursor.fetchall()).flatten()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paper data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we use only paper information, we remove all other \"authoredBy\" edges"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "remapped_test_papers = th.tensor([remapped_papers[idx] for idx in test_papers])\n",
    "remapped_val_papers = th.tensor([remapped_papers[idx] for idx in val_papers])\n",
    "remapped_train_papers = th.tensor([remapped_papers[idx] for idx in train_papers])\n",
    "remapped_authors_in_question = th.tensor([remapped_authors[idx] for idx in authors_in_question])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0146,  0.0525, -0.0199,  ..., -0.0717,  0.0053, -0.0091],\n        [-0.0028,  0.0341,  0.0362,  ..., -0.0184,  0.0457, -0.0389],\n        [-0.0012, -0.0004,  0.0246,  ..., -0.0462, -0.0197,  0.0109],\n        ...,\n        [ 0.0262,  0.0078, -0.0416,  ..., -0.0869, -0.0445, -0.0357],\n        [-0.0312,  0.0735,  0.0188,  ..., -0.0209,  0.0594,  0.0109],\n        [ 0.0610,  0.0380, -0.0386,  ..., -0.0682, -0.0064, -0.0540]],\n       dtype=torch.float64)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_feats_vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "tensors_in_question = torch.index_select(author_feats_vec,0,remapped_authors_in_question)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [],
   "source": [
    "only_zeros = [idx for idx, tensor in enumerate(author_feats_vec) if (tensor == 0).all()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(only_zeros)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(6511)"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remapped_authors_in_question[442]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [
    {
     "data": {
      "text/plain": "'2062795769'"
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(remapped_authors)[6511]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "hetero_graph = dgl.heterograph(\n",
    "    {\n",
    "        ('paper', 'authored', 'author'): (author_edges[:,0].astype(int), author_edges[:,1].astype(int)),\n",
    "        ('author', \"writes\", \"paper\"): (author_edges[:,1].astype(int), author_edges[:,0].astype(int)),\n",
    "        ('paper', 'cites', 'paper'): (paper_edges[:,0].astype(int), paper_edges[:,1].astype(int)),\n",
    "        ('gender', 'gendered', 'author'): (gender_edges[:,1].astype(int), gender_edges[:,0].astype(int)),\n",
    "        ('paper', 'authored_gender', 'gender'): (author_edges[:,0].astype(int), author_edges[:,2].astype(int)),\n",
    "        ('paper', 'authored_affiliation', 'affiliation'): (author_info[:,0].astype(int), author_info[:,2].astype(int)),\n",
    "        ('affiliation', 'affiliated', 'author'): (affiliation_edges[:,0].astype(int), affiliation_edges[:,1].astype(int)),\n",
    "        ('paper', 'authored_country', 'country'): (author_info[:,0].astype(int), author_info[:,3].astype(int)),\n",
    "        ('country', 'contains', 'affiliation'): (country_edges[:,0].astype(int), country_edges[:,1].astype(int))\n",
    "    }\n",
    ")\n",
    "hetero_graph.nodes['author'].data['feature'] = author_feats_vec\n",
    "hetero_graph.nodes['paper'].data['feature'] = paper_feats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nedges = hetero_graph.edges(etype=\"authored\")\\nauthor_mask = ~torch.isin(edges[1], remapped_authors_in_question)\\npaper_edges = edges[0][author_mask]\\nauthor_edges = edges[1][author_mask]\\nauthor_ids_remove = hetero_graph.edge_ids(paper_edges, author_edges, etype=\"authored\")\\nhetero_graph = dgl.remove_edges(hetero_graph, author_ids_remove, etype=\"authored\")\\n'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "edges = hetero_graph.edges(etype=\"authored\")\n",
    "author_mask = ~torch.isin(edges[1], remapped_authors_in_question)\n",
    "paper_edges = edges[0][author_mask]\n",
    "author_edges = edges[1][author_mask]\n",
    "author_ids_remove = hetero_graph.edge_ids(paper_edges, author_edges, etype=\"authored\")\n",
    "hetero_graph = dgl.remove_edges(hetero_graph, author_ids_remove, etype=\"authored\")\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split into Training, Validation, Test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 2384, ('paper', 'authored_affiliation', 'affiliation'): 36285, ('paper', 'authored_country', 'country'): 36285, ('paper', 'authored_gender', 'gender'): 36099, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = hetero_graph.edges(etype=\"authored\")\n",
    "\n",
    "train_mask = ~torch.isin(edges[0], remapped_train_papers)\n",
    "train_src = edges[0][train_mask]\n",
    "train_dst = edges[1][train_mask]\n",
    "\n",
    "train_ids = hetero_graph.edge_ids(train_src, train_dst, etype=\"authored\")\n",
    "train_hetero_graph = dgl.remove_edges(hetero_graph, train_ids, etype=\"authored\")\n",
    "\n",
    "train_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 2384, ('paper', 'authored_affiliation', 'affiliation'): 36285, ('paper', 'authored_country', 'country'): 36285, ('paper', 'authored_gender', 'gender'): 2384, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = train_hetero_graph.edges(etype=\"authored_gender\")\n",
    "\n",
    "train_mask = ~torch.isin(edges[0], remapped_train_papers)\n",
    "train_src = edges[0][train_mask]\n",
    "train_dst = edges[1][train_mask]\n",
    "\n",
    "train_ids = train_hetero_graph.edge_ids(train_src, train_dst, etype=\"authored_gender\")\n",
    "train_hetero_graph = dgl.remove_edges(train_hetero_graph, train_ids, etype=\"authored_gender\")\n",
    "\n",
    "train_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 2384, ('paper', 'authored_affiliation', 'affiliation'): 2384, ('paper', 'authored_country', 'country'): 36285, ('paper', 'authored_gender', 'gender'): 2384, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = train_hetero_graph.edges(etype=\"authored_affiliation\")\n",
    "\n",
    "train_mask = ~torch.isin(edges[0], remapped_train_papers)\n",
    "train_src = edges[0][train_mask]\n",
    "train_dst = edges[1][train_mask]\n",
    "\n",
    "train_ids = train_hetero_graph.edge_ids(train_src, train_dst, etype=\"authored_affiliation\")\n",
    "train_hetero_graph = dgl.remove_edges(train_hetero_graph, train_ids, etype=\"authored_affiliation\")\n",
    "\n",
    "train_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 2384, ('paper', 'authored_affiliation', 'affiliation'): 2384, ('paper', 'authored_country', 'country'): 2467, ('paper', 'authored_gender', 'gender'): 2384, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = train_hetero_graph.edges(etype=\"authored_country\")\n",
    "\n",
    "train_mask = ~torch.isin(edges[0], remapped_train_papers)\n",
    "train_src = edges[0][train_mask]\n",
    "train_dst = edges[1][train_mask]\n",
    "\n",
    "train_ids = train_hetero_graph.edge_ids(train_src, train_dst, etype=\"authored_country\")\n",
    "train_hetero_graph = dgl.remove_edges(train_hetero_graph, train_ids, etype=\"authored_country\")\n",
    "\n",
    "train_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 300, ('paper', 'authored_affiliation', 'affiliation'): 36285, ('paper', 'authored_country', 'country'): 36285, ('paper', 'authored_gender', 'gender'): 36099, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = hetero_graph.edges(etype=\"authored\")\n",
    "val_mask = ~torch.isin(edges[0], remapped_val_papers)\n",
    "val_src = edges[0][val_mask]\n",
    "val_dst = edges[1][val_mask]\n",
    "\n",
    "val_ids = hetero_graph.edge_ids(val_src, val_dst, etype=\"authored\")\n",
    "val_hetero_graph = dgl.remove_edges(hetero_graph, val_ids, etype=\"authored\")\n",
    "val_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 300, ('paper', 'authored_affiliation', 'affiliation'): 36285, ('paper', 'authored_country', 'country'): 36285, ('paper', 'authored_gender', 'gender'): 300, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = val_hetero_graph.edges(etype=\"authored_gender\")\n",
    "val_mask = ~torch.isin(edges[0], remapped_val_papers)\n",
    "val_src = edges[0][val_mask]\n",
    "val_dst = edges[1][val_mask]\n",
    "\n",
    "val_ids = val_hetero_graph.edge_ids(val_src, val_dst, etype=\"authored_gender\")\n",
    "val_hetero_graph = dgl.remove_edges(val_hetero_graph, val_ids, etype=\"authored_gender\")\n",
    "val_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 300, ('paper', 'authored_affiliation', 'affiliation'): 300, ('paper', 'authored_country', 'country'): 36285, ('paper', 'authored_gender', 'gender'): 300, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = val_hetero_graph.edges(etype=\"authored_affiliation\")\n",
    "val_mask = ~torch.isin(edges[0], remapped_val_papers)\n",
    "val_src = edges[0][val_mask]\n",
    "val_dst = edges[1][val_mask]\n",
    "\n",
    "val_ids = val_hetero_graph.edge_ids(val_src, val_dst, etype=\"authored_affiliation\")\n",
    "val_hetero_graph = dgl.remove_edges(val_hetero_graph, val_ids, etype=\"authored_affiliation\")\n",
    "val_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 300, ('paper', 'authored_affiliation', 'affiliation'): 300, ('paper', 'authored_country', 'country'): 383, ('paper', 'authored_gender', 'gender'): 300, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = val_hetero_graph.edges(etype=\"authored_country\")\n",
    "val_mask = ~torch.isin(edges[0], remapped_val_papers)\n",
    "val_src = edges[0][val_mask]\n",
    "val_dst = edges[1][val_mask]\n",
    "\n",
    "val_ids = val_hetero_graph.edge_ids(val_src, val_dst, etype=\"authored_country\")\n",
    "val_hetero_graph = dgl.remove_edges(val_hetero_graph, val_ids, etype=\"authored_country\")\n",
    "val_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 1005, ('paper', 'authored_affiliation', 'affiliation'): 36285, ('paper', 'authored_country', 'country'): 36285, ('paper', 'authored_gender', 'gender'): 36099, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = hetero_graph.edges(etype=\"authored\")\n",
    "val_mask = ~torch.isin(edges[0], remapped_test_papers)\n",
    "val_src = edges[0][val_mask]\n",
    "val_dst = edges[1][val_mask]\n",
    "\n",
    "val_ids = hetero_graph.edge_ids(val_src, val_dst, etype=\"authored\")\n",
    "test_hetero_graph = dgl.remove_edges(hetero_graph, val_ids, etype=\"authored\")\n",
    "test_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 1005, ('paper', 'authored_affiliation', 'affiliation'): 36285, ('paper', 'authored_country', 'country'): 36285, ('paper', 'authored_gender', 'gender'): 1005, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = test_hetero_graph.edges(etype=\"authored_gender\")\n",
    "val_mask = ~torch.isin(edges[0], remapped_test_papers)\n",
    "val_src = edges[0][val_mask]\n",
    "val_dst = edges[1][val_mask]\n",
    "\n",
    "val_ids = test_hetero_graph.edge_ids(val_src, val_dst, etype=\"authored_gender\")\n",
    "test_hetero_graph = dgl.remove_edges(test_hetero_graph, val_ids, etype=\"authored_gender\")\n",
    "test_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 1005, ('paper', 'authored_affiliation', 'affiliation'): 1005, ('paper', 'authored_country', 'country'): 36285, ('paper', 'authored_gender', 'gender'): 1005, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = test_hetero_graph.edges(etype=\"authored_affiliation\")\n",
    "val_mask = ~torch.isin(edges[0], remapped_test_papers)\n",
    "val_src = edges[0][val_mask]\n",
    "val_dst = edges[1][val_mask]\n",
    "\n",
    "val_ids = test_hetero_graph.edge_ids(val_src, val_dst, etype=\"authored_affiliation\")\n",
    "test_hetero_graph = dgl.remove_edges(test_hetero_graph, val_ids, etype=\"authored_affiliation\")\n",
    "test_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes={'affiliation': 2342, 'author': 18318, 'country': 88, 'gender': 2, 'paper': 36099},\n      num_edges={('affiliation', 'affiliated', 'author'): 18422, ('author', 'writes', 'paper'): 36099, ('country', 'contains', 'affiliation'): 2342, ('gender', 'gendered', 'author'): 18318, ('paper', 'authored', 'author'): 1005, ('paper', 'authored_affiliation', 'affiliation'): 1005, ('paper', 'authored_country', 'country'): 1088, ('paper', 'authored_gender', 'gender'): 1005, ('paper', 'cites', 'paper'): 138804},\n      metagraph=[('affiliation', 'author', 'affiliated'), ('author', 'paper', 'writes'), ('paper', 'author', 'authored'), ('paper', 'affiliation', 'authored_affiliation'), ('paper', 'country', 'authored_country'), ('paper', 'gender', 'authored_gender'), ('paper', 'paper', 'cites'), ('country', 'affiliation', 'contains'), ('gender', 'author', 'gendered')])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = test_hetero_graph.edges(etype=\"authored_country\")\n",
    "val_mask = ~torch.isin(edges[0], remapped_test_papers)\n",
    "val_src = edges[0][val_mask]\n",
    "val_dst = edges[1][val_mask]\n",
    "\n",
    "val_ids = test_hetero_graph.edge_ids(val_src, val_dst, etype=\"authored_country\")\n",
    "test_hetero_graph = dgl.remove_edges(test_hetero_graph, val_ids, etype=\"authored_country\")\n",
    "test_hetero_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "save_graphs(\"./graphs/hetero_graphs_primary_word2vec_w_zeros.bin\", [train_hetero_graph, val_hetero_graph, test_hetero_graph])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
