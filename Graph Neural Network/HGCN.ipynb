{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1TLIn9qfhnzandkuoLTv-P6Y-gqUgQ31I",
     "timestamp": 1677150611244
    }
   ],
   "mount_file_id": "1AykyJvR2hyZp_Pg_8MtBxP4P9oAO0iiM",
   "authorship_tag": "ABX9TyMoF19H/rEZH825rkWCNIgP"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "premium"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-oVrk2WMbHi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1677487284405,
     "user_tz": -60,
     "elapsed": 11389,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     }
    },
    "outputId": "bf8c11f5-c98b-47bd-8bee-6175a84c2fb7"
   },
   "outputs": [],
   "source": [
    "#!pip install dgl dglgo -f https://data.dgl.ai/wheels/repo.html\n",
    "import dgl\n",
    "import torch as th\n",
    "import torch\n",
    "import numpy as np\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch.nn as nn\n",
    "import dgl.nn as dglnn\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "#from torchmetrics.classification import BinaryAUROC\n",
    "import torch.nn as nn\n",
    "from dgl.dataloading.negative_sampler import _BaseNegativeSampler\n",
    "from dgl import backend as b\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "glist, label_dict = load_graphs(\"./graphs/hetero_graphs_primary_word2vec_w_zeros.bin\")\n",
    "train_hetero_graph = glist[0]\n",
    "val_hetero_graph = glist[1]\n",
    "test_hetero_graph = glist[2]"
   ],
   "metadata": {
    "id": "7OKjsl70Me-a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1677487286244,
     "user_tz": -60,
     "elapsed": 2,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     }
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class PerSourceUniformCustom(_BaseNegativeSampler):\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def _generate(self, g, eids, canonical_etype):\n",
    "        unique_authors = torch.unique(g.edges(etype = \"authored\")[1])\n",
    "        #print(len(unique_authors))\n",
    "        _, _, vtype = canonical_etype\n",
    "        shape = b.shape(eids)\n",
    "        dtype = b.dtype(eids)\n",
    "        ctx = b.context(eids)\n",
    "        shape = (shape[0] * self.k,)\n",
    "        src, _ = g.find_edges(eids, etype=canonical_etype)\n",
    "        src = b.repeat(src, self.k, 0)\n",
    "        dst_indexes = th.randint(0, len(unique_authors), shape, dtype=dtype, device=ctx)\n",
    "        dst = unique_authors[dst_indexes]\n",
    "        return src, dst"
   ],
   "metadata": {
    "id": "xY3a7pwejU0G",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1677487286996,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def construct_negative_graph(graph, k, etype):\n",
    "    utype, edge_type, vtype = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    eids = graph.edge_ids(src, dst, etype=edge_type)\n",
    "    #eids = torch.unique(train_hetero_graph.edges(etype=\"authored\")[0])\n",
    "    neg_sampler = PerSourceUniformCustom(k)\n",
    "    #neg_sampler = dgl.dataloading.negative_sampler.PerSourceUniform(k)\n",
    "    neg_src, neg_dst = neg_sampler(graph, {edge_type: eids})[etype]\n",
    "    return dgl.heterograph(\n",
    "        {etype: (neg_src, neg_dst)},\n",
    "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})"
   ],
   "metadata": {
    "id": "jjiNOLmYMh61",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1677487287368,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, num_classes_papers, num_classes_authors):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            \"writes\": dglnn.GraphConv(2731, 512),\n",
    "        }, aggregate=\"stack\")\n",
    "\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            \"cites\": dglnn.GraphConv(2731, 512),\n",
    "        })\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear = nn.Linear(512, 2731)\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        classes_paper = inputs[\"paper\"]\n",
    "        classes_author = inputs[\"author\"]\n",
    "\n",
    "        #h_writes = self.conv1(graph[\"writes\"], {\"paper\": classes_paper, \"author\": classes_author})[\"paper\"]\n",
    "        h_cites = self.conv2(graph[\"cites\"], {\"paper\": classes_paper, \"author\": classes_author})[\"paper\"]\n",
    "        #h_cites = self.dropout(h_cites)\n",
    "        h_cites = F.relu(h_cites)\n",
    "\n",
    "        #h_cites = torch.cat([classes_paper, h_cites], dim=1)\n",
    "        \"\"\"\n",
    "        h_cites = self.conv2(graph[\"cites\"], {\"paper\": classes_paper, \"author\": classes_author})[\"paper\"].flatten(1)\n",
    "        h_cites = self.dropout(h_cites)\n",
    "        h_cites = F.relu(h_cites)\n",
    "        h_cites = self.linear(h_cites)\n",
    "        \"\"\"\n",
    "        h_cites = self.linear(h_cites)\n",
    "        return {\"paper\": h_cites, \"author\": classes_author}\n",
    "    \n",
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    def forward(self, graph, h, etype):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
    "            return graph.edges[etype].data['score']\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, rel_names, num_classes_paper, num_classes_author):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.sage = RGCN(in_features, hidden_features, out_features, num_classes_paper, num_classes_author)\n",
    "        # Decoder\n",
    "        self.pred = HeteroDotProductPredictor()\n",
    "    def forward(self, g, neg_g, x, etype):\n",
    "        h = self.sage(g, x)\n",
    "        return h\n",
    "\n",
    "    def scores(self, g, neg_g, x, etype):\n",
    "      h = self(g, neg_g, x, etype)\n",
    "      return self.pred(g, h, etype), self.pred(neg_g, h, etype)"
   ],
   "metadata": {
    "id": "au2Jb4o5MnGy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1677487287707,
     "user_tz": -60,
     "elapsed": 3,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     }
    }
   },
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).squeeze(1).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    # Margin loss\n",
    "    n_edges = pos_score.shape[0]\n",
    "    return (1 - pos_score + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
    "\n",
    "def compute_loss_logits(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).to(\"cuda\")\n",
    "    \n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).to(device)\n",
    "    return F.binary_cross_entropy_with_logits(scores.squeeze(1), labels)\n",
    "\n",
    "def accuracy(logits, graph):\n",
    "  with torch.no_grad():\n",
    "    all_papers = torch.unique(graph.edges(etype=\"authored\")[0])\n",
    "    src, dst = graph.edges(etype=\"authored\")\n",
    "    unique_authors = torch.unique(dst)\n",
    "    tst = 0\n",
    "    author_logits = logits[\"author\"][unique_authors]\n",
    "\n",
    "    for idx, index_paper in enumerate(all_papers):\n",
    "      #if idx % 25000 == 0:\n",
    "      #  print(f\"{idx}/{len(all_papers)}\")\n",
    "      current_logits = logits[\"paper\"][index_paper]\n",
    "      dot_product_all = torch.sum(current_logits * author_logits, dim=-1)\n",
    "\n",
    "      #not_in_authors = torch.where(torch.logical_not(torch.isin(torch.arange(len(dot_product_all.to(device))).to(device), unique_authors.to(device))))\n",
    "      #dot_product_all[not_in_authors] = -10\n",
    "\n",
    "      max = torch.argmax(dot_product_all)\n",
    "      max = unique_authors[max].item()\n",
    "      filter_acc = src == index_paper\n",
    "      if max in dst[filter_acc]:\n",
    "        tst += 1\n",
    "    return tst/len(all_papers)"
   ],
   "metadata": {
    "id": "TYXaLTytM3vC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1677487288459,
     "user_tz": -60,
     "elapsed": 3,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     }
    }
   },
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data into GPU memory\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "id": "busP_ir1M4T8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1677487289711,
     "user_tz": -60,
     "elapsed": 3,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     }
    }
   },
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# Sum Pooling Genders\n",
    "train_hetero_graph.nodes[\"gender\"].data[\"h\"] = train_hetero_graph.nodes('gender').type(torch.float32)\n",
    "train_hetero_graph.nodes[\"author\"].data[\"h\"] = th.zeros(len(train_hetero_graph.nodes(\"author\")))\n",
    "train_hetero_graph[\"gendered\"].update_all(fn.copy_u('h', 'm'), fn.max('m', 'h'))\n",
    "author_genders = train_hetero_graph.nodes[\"author\"].data[\"h\"].view(-1,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Sum Pooling Countries\n",
    "country_feats = F.one_hot(train_hetero_graph.nodes('country')).type(torch.float32)\n",
    "train_hetero_graph.nodes[\"country\"].data[\"h\"] = country_feats\n",
    "train_hetero_graph.nodes[\"affiliation\"].data[\"h\"] = th.zeros((len(train_hetero_graph.nodes(\"affiliation\")), country_feats.shape[0]))\n",
    "train_hetero_graph[\"contains\"].update_all(fn.copy_u('h', 'm'), fn.max('m', 'h'))\n",
    "affiliation_countries = train_hetero_graph.nodes[\"affiliation\"].data[\"h\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# Sum Pooling Affiliations\n",
    "affiliation_feats = F.one_hot(train_hetero_graph.nodes('affiliation')).type(torch.float32)\n",
    "train_hetero_graph.nodes[\"affiliation\"].data[\"h\"] = torch.concat([affiliation_feats, affiliation_countries], dim=1)\n",
    "train_hetero_graph.nodes[\"author\"].data[\"h\"] = th.zeros((len(train_hetero_graph.nodes(\"author\")), country_feats.shape[0]))\n",
    "train_hetero_graph[\"affiliated\"].update_all(fn.copy_u('h', 'm'), fn.max('m', 'h'))\n",
    "author_affiliation_country = train_hetero_graph.nodes[\"author\"].data[\"h\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "author_feats = train_hetero_graph.nodes['author'].data['feature'].type(torch.float32)\n",
    "author_feats = torch.concat([author_feats, author_genders, author_affiliation_country], dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "#author_feats = train_hetero_graph.nodes['author'].data['feature'].type(torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "#author_feats = train_hetero_graph.nodes['author'].data['feature']\n",
    "train_hetero_graph.nodes[\"author\"].data[\"h\"] = author_feats\n",
    "train_hetero_graph.nodes[\"paper\"].data[\"h\"] = th.zeros((len(train_hetero_graph.nodes['paper'].data['feature']), author_feats.shape[0]))\n",
    "train_hetero_graph[\"writes\"].update_all(fn.copy_u('h', 'm'), fn.mean('m', 'h'))\n",
    "paper_feats = train_hetero_graph.nodes[\"paper\"].data[\"h\"].type(torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "#paper_feats = train_hetero_graph.nodes['paper'].data['feature']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "user_feats_train = train_hetero_graph.nodes['author'].data['feature']\n",
    "item_feats_train = train_hetero_graph.nodes['paper'].data['feature']\n",
    "node_features_train = {'author': user_feats_train.to(device), 'paper': item_feats_train.to(device)}\n",
    "\"\"\"\n",
    "#author_feats = train_hetero_graph.nodes['author'].data['feature'].type(torch.float32)\n",
    "#author_feats = torch.concat([author_feats, author_genders, author_affiliation_country], dim=1)\n",
    "#paper_feats = train_hetero_graph.nodes['paper'].data['feature']\n",
    "\n",
    "node_features = {'paper': paper_feats.to(device), \"author\": author_feats.type(torch.float32).to(device)}"
   ],
   "metadata": {
    "id": "rs0h9m7mNNe9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1677487296143,
     "user_tz": -60,
     "elapsed": 2384,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     }
    }
   },
   "execution_count": 97,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([36099, 2731])"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features[\"paper\"].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "k = 8\n",
    "loss_training_epoch = []\n",
    "loss_validation_epoch = []\n",
    "\n",
    "auc_training_epoch = []\n",
    "auc_validation_epoch = []\n",
    "\n",
    "acc_training = []\n",
    "acc_validation = []\n",
    "\n",
    "pred = HeteroDotProductPredictor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = Model(256, 1024, 512, train_hetero_graph.etypes, len(train_hetero_graph.nodes(\"paper\")), len(train_hetero_graph.nodes(\"author\"))).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(5000000):\n",
    "    negative_graph = construct_negative_graph(train_hetero_graph, k, ('paper', 'authored', 'author'))\n",
    "    pos_score, neg_score = model.scores(train_hetero_graph.to(device), negative_graph.to(device), node_features, ('paper', 'authored', 'author'))\n",
    "    loss = compute_loss_logits(pos_score.to(device), neg_score.to(device))\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 50 == 0:\n",
    "        with torch.no_grad():\n",
    "          logits_train = model(train_hetero_graph.to(device), negative_graph.to(device), node_features, ('paper', 'authored', 'author'))\n",
    "          acc_train = accuracy(logits_train, train_hetero_graph.to(device))\n",
    "          auc_train = compute_auc(pos_score.cpu(), neg_score.cpu())\n",
    "          loss_train = loss.item()\n",
    "\n",
    "          loss_training_epoch.append(loss_train)\n",
    "          auc_training_epoch.append(auc_train)\n",
    "\n",
    "          logits_val = model(val_hetero_graph.to(device), \"x\", node_features, ('paper', 'authored', 'author'))\n",
    "          acc_val = accuracy(logits_val, val_hetero_graph.to(device))\n",
    "\n",
    "          negative_graph = construct_negative_graph(val_hetero_graph, k, ('paper', 'authored', 'author'))\n",
    "          pos_score_eval, neg_score_eval = model.scores(val_hetero_graph.to(device), negative_graph.to(device), node_features, ('paper', 'authored', 'author'))\n",
    "          loss_val = compute_loss_logits(pos_score_eval.to(device), neg_score.to(device)).item()\n",
    "          auc_val = compute_auc(pos_score_eval.cpu(), neg_score_eval.cpu())\n",
    "\n",
    "          loss_validation_epoch.append(loss_val)\n",
    "          auc_validation_epoch.append(auc_val)\n",
    "\n",
    "          acc_training.append(acc_train)\n",
    "          acc_validation.append(acc_val)\n",
    "\n",
    "          print(f\"EPOCH: {epoch}; Loss: {loss_train}, AUC: {auc_train}, Acc Train: {acc_train}; Loss {loss_val}, AUC: {auc_val} Acc Evaluation: {acc_val}\")\n",
    "\n",
    "    \"\"\"\n",
    "    if epoch % 50 == 0:\n",
    "\n",
    "      with torch.no_grad():\n",
    "        total_list  = loss_training_epoch + loss_validation_epoch + auc_training_epoch + auc_validation_epoch + acc_training + acc_validation\n",
    "        with open(f'./drive/MyDrive/Bachelor_thesis/models/author_metrics_{epoch}_final.txt', 'w') as f:\n",
    "          for item in total_list:\n",
    "              f.write(str(item) + '\\n')\n",
    "        torch.save(model, f\"./drive/MyDrive/Bachelor_thesis/models/author_{epoch}_final.pt\")\n",
    "    \"\"\""
   ],
   "metadata": {
    "id": "m49fF7jqNOVy",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1677487588012,
     "user_tz": -60,
     "elapsed": 291881,
     "user": {
      "displayName": "David Le",
      "userId": "02178050067745828665"
     }
    },
    "outputId": "1964bcb1-f396-41e6-f7f0-59487e86a22e"
   },
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0; Loss: 0.7121787667274475, AUC: 0.5082325789097338, Acc Train: 0.0012583892617449664; Loss 0.721087634563446, AUC: 0.5047201388888889 Acc Evaluation: 0.0033333333333333335\n",
      "EPOCH: 50; Loss: 0.34297725558280945, AUC: 0.6056159975550087, Acc Train: 0.01552013422818792; Loss 0.16357916593551636, AUC: 0.5434965277777777 Acc Evaluation: 0.01\n",
      "EPOCH: 100; Loss: 0.28469377756118774, AUC: 0.8340620126204901, Acc Train: 0.06501677852348993; Loss 0.13837355375289917, AUC: 0.7309215277777777 Acc Evaluation: 0.02666666666666667\n",
      "EPOCH: 150; Loss: 0.21881690621376038, AUC: 0.9288082594463651, Acc Train: 0.1950503355704698; Loss 0.11247862875461578, AUC: 0.8153958333333334 Acc Evaluation: 0.14666666666666667\n",
      "EPOCH: 200; Loss: 0.16750603914260864, AUC: 0.9665566382496847, Acc Train: 0.30956375838926176; Loss 0.09374386072158813, AUC: 0.8464368055555554 Acc Evaluation: 0.20666666666666667\n",
      "EPOCH: 250; Loss: 0.13086068630218506, AUC: 0.9826726467135489, Acc Train: 0.39093959731543626; Loss 0.08320832252502441, AUC: 0.8579868055555555 Acc Evaluation: 0.24333333333333335\n",
      "EPOCH: 300; Loss: 0.1055167093873024, AUC: 0.9895883112317576, Acc Train: 0.4509228187919463; Loss 0.08170799165964127, AUC: 0.8629576388888889 Acc Evaluation: 0.26666666666666666\n",
      "EPOCH: 350; Loss: 0.08549640327692032, AUC: 0.9936233671026925, Acc Train: 0.5058724832214765; Loss 0.07744048535823822, AUC: 0.8710993055555556 Acc Evaluation: 0.2833333333333333\n",
      "EPOCH: 400; Loss: 0.07111435383558273, AUC: 0.9957631742904318, Acc Train: 0.5453020134228188; Loss 0.07082334905862808, AUC: 0.8636173611111111 Acc Evaluation: 0.29333333333333333\n",
      "EPOCH: 450; Loss: 0.06164130941033363, AUC: 0.9967965354178865, Acc Train: 0.584731543624161; Loss 0.06807149201631546, AUC: 0.8612020833333334 Acc Evaluation: 0.30666666666666664\n",
      "EPOCH: 500; Loss: 0.05310501158237457, AUC: 0.9975668303757432, Acc Train: 0.610738255033557; Loss 0.06936225295066833, AUC: 0.866067361111111 Acc Evaluation: 0.32\n",
      "EPOCH: 550; Loss: 0.04571528732776642, AUC: 0.9981985432807081, Acc Train: 0.6430369127516778; Loss 0.0681564062833786, AUC: 0.8674034722222222 Acc Evaluation: 0.3233333333333333\n",
      "EPOCH: 600; Loss: 0.04341975972056389, AUC: 0.9977672695979347, Acc Train: 0.6568791946308725; Loss 0.07499425858259201, AUC: 0.8672659722222221 Acc Evaluation: 0.32666666666666666\n",
      "EPOCH: 650; Loss: 0.036813780665397644, AUC: 0.9984878368900894, Acc Train: 0.6749161073825504; Loss 0.06993574649095535, AUC: 0.869670138888889 Acc Evaluation: 0.33\n",
      "EPOCH: 700; Loss: 0.03642948344349861, AUC: 0.9982134219918303, Acc Train: 0.6870805369127517; Loss 0.07783593237400055, AUC: 0.8664763888888889 Acc Evaluation: 0.32666666666666666\n",
      "EPOCH: 750; Loss: 0.03310641273856163, AUC: 0.9984318960153822, Acc Train: 0.697986577181208; Loss 0.07801112532615662, AUC: 0.8677750000000001 Acc Evaluation: 0.33\n",
      "EPOCH: 800; Loss: 0.02853933349251747, AUC: 0.9988816223790595, Acc Train: 0.7080536912751678; Loss 0.07405515760183334, AUC: 0.8633624999999999 Acc Evaluation: 0.33\n",
      "EPOCH: 850; Loss: 0.026939544826745987, AUC: 0.9988626968344614, Acc Train: 0.7156040268456376; Loss 0.07814966887235641, AUC: 0.8614347222222223 Acc Evaluation: 0.3333333333333333\n",
      "EPOCH: 900; Loss: 0.02802422270178795, AUC: 0.9986564182954877, Acc Train: 0.7235738255033557; Loss 0.08333912491798401, AUC: 0.8647916666666666 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 950; Loss: 0.028512654826045036, AUC: 0.9984051407277543, Acc Train: 0.7340604026845637; Loss 0.09001670777797699, AUC: 0.860778472222222 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 1000; Loss: 0.024555601179599762, AUC: 0.9988016424337587, Acc Train: 0.7458053691275168; Loss 0.08361703157424927, AUC: 0.8614333333333334 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 1050; Loss: 0.022163402289152145, AUC: 0.9990109121105186, Acc Train: 0.7449664429530202; Loss 0.08666934818029404, AUC: 0.8647770833333333 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 1100; Loss: 0.02397671714425087, AUC: 0.9988153664777206, Acc Train: 0.7537751677852349; Loss 0.09446399658918381, AUC: 0.8601798611111111 Acc Evaluation: 0.35\n",
      "EPOCH: 1150; Loss: 0.021659506484866142, AUC: 0.9989026923055268, Acc Train: 0.7583892617449665; Loss 0.08879715949296951, AUC: 0.8645680555555556 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 1200; Loss: 0.019283251836895943, AUC: 0.9990749466521779, Acc Train: 0.7676174496644296; Loss 0.08405240625143051, AUC: 0.86863125 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 1250; Loss: 0.020871881395578384, AUC: 0.9987834096894566, Acc Train: 0.7667785234899329; Loss 0.09269501268863678, AUC: 0.8636270833333335 Acc Evaluation: 0.35\n",
      "EPOCH: 1300; Loss: 0.01866856776177883, AUC: 0.9992203577365603, Acc Train: 0.772231543624161; Loss 0.09368083626031876, AUC: 0.8636395833333333 Acc Evaluation: 0.35\n",
      "EPOCH: 1350; Loss: 0.01861836574971676, AUC: 0.9990147939915431, Acc Train: 0.7797818791946308; Loss 0.09170588105916977, AUC: 0.8635298611111111 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 1400; Loss: 0.020588412880897522, AUC: 0.9985194747702807, Acc Train: 0.785234899328859; Loss 0.09769876301288605, AUC: 0.861223611111111 Acc Evaluation: 0.34\n",
      "EPOCH: 1450; Loss: 0.01836642064154148, AUC: 0.9990973691887471, Acc Train: 0.7848154362416108; Loss 0.1017257422208786, AUC: 0.8622875000000001 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 1500; Loss: 0.015511061064898968, AUC: 0.9992315305159396, Acc Train: 0.7919463087248322; Loss 0.09050241857767105, AUC: 0.8617423611111111 Acc Evaluation: 0.33666666666666667\n",
      "EPOCH: 1550; Loss: 0.01913539506494999, AUC: 0.998834193050848, Acc Train: 0.7957214765100671; Loss 0.10001671314239502, AUC: 0.8621812499999999 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 1600; Loss: 0.016678988933563232, AUC: 0.9991616896479888, Acc Train: 0.7986577181208053; Loss 0.09964869916439056, AUC: 0.8612041666666665 Acc Evaluation: 0.33666666666666667\n",
      "EPOCH: 1650; Loss: 0.01732720620930195, AUC: 0.9988347978765033, Acc Train: 0.8003355704697986; Loss 0.10463361442089081, AUC: 0.8612722222222222 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 1700; Loss: 0.016855888068675995, AUC: 0.9991839362352765, Acc Train: 0.8041107382550335; Loss 0.10079707205295563, AUC: 0.8722187499999999 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 1750; Loss: 0.016935355961322784, AUC: 0.9990768491037848, Acc Train: 0.8045302013422819; Loss 0.10751157999038696, AUC: 0.8591034722222223 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 1800; Loss: 0.01544143445789814, AUC: 0.9991823636885726, Acc Train: 0.8091442953020134; Loss 0.10591990500688553, AUC: 0.8660215277777777 Acc Evaluation: 0.33666666666666667\n",
      "EPOCH: 1850; Loss: 0.01642225868999958, AUC: 0.9989712685380163, Acc Train: 0.8091442953020134; Loss 0.10786949843168259, AUC: 0.8676604166666666 Acc Evaluation: 0.3333333333333333\n",
      "EPOCH: 1900; Loss: 0.01575283333659172, AUC: 0.9990458490397391, Acc Train: 0.8158557046979866; Loss 0.1064387857913971, AUC: 0.8662048611111111 Acc Evaluation: 0.35\n",
      "EPOCH: 1950; Loss: 0.015354311093688011, AUC: 0.9990937512316449, Acc Train: 0.8158557046979866; Loss 0.11037707328796387, AUC: 0.8651736111111111 Acc Evaluation: 0.34\n",
      "EPOCH: 2000; Loss: 0.014737638644874096, AUC: 0.9992053690571371, Acc Train: 0.8179530201342282; Loss 0.10626426339149475, AUC: 0.86011875 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 2050; Loss: 0.014023842290043831, AUC: 0.9992650378572474, Acc Train: 0.8200503355704698; Loss 0.10890518128871918, AUC: 0.8643798611111111 Acc Evaluation: 0.34\n",
      "EPOCH: 2100; Loss: 0.012796026654541492, AUC: 0.9992097897828363, Acc Train: 0.8259228187919463; Loss 0.10576868057250977, AUC: 0.8639916666666667 Acc Evaluation: 0.3333333333333333\n",
      "EPOCH: 2150; Loss: 0.014575181528925896, AUC: 0.9990408564788749, Acc Train: 0.8301174496644296; Loss 0.11142838001251221, AUC: 0.8610791666666667 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 2200; Loss: 0.01503079291433096, AUC: 0.9990730771910612, Acc Train: 0.8334731543624161; Loss 0.11764290183782578, AUC: 0.8639368055555556 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 2250; Loss: 0.014724264852702618, AUC: 0.9990615525131188, Acc Train: 0.8410234899328859; Loss 0.1155349537730217, AUC: 0.8684965277777779 Acc Evaluation: 0.34\n",
      "EPOCH: 2300; Loss: 0.01531240250915289, AUC: 0.9991080471107721, Acc Train: 0.8447986577181208; Loss 0.11751848459243774, AUC: 0.8653659722222221 Acc Evaluation: 0.35\n",
      "EPOCH: 2350; Loss: 0.015778690576553345, AUC: 0.998671857844945, Acc Train: 0.847734899328859; Loss 0.11929643154144287, AUC: 0.8622798611111112 Acc Evaluation: 0.3333333333333333\n",
      "EPOCH: 2400; Loss: 0.013189977034926414, AUC: 0.999138871225536, Acc Train: 0.8468959731543624; Loss 0.11297038942575455, AUC: 0.8671666666666666 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 2450; Loss: 0.013441413640975952, AUC: 0.9991516825325999, Acc Train: 0.8515100671140939; Loss 0.11597302556037903, AUC: 0.8644708333333332 Acc Evaluation: 0.32666666666666666\n",
      "EPOCH: 2500; Loss: 0.013745426200330257, AUC: 0.9990735500547554, Acc Train: 0.8552852348993288; Loss 0.11871282756328583, AUC: 0.8610263888888888 Acc Evaluation: 0.34\n",
      "EPOCH: 2550; Loss: 0.011504143476486206, AUC: 0.9993017672697738, Acc Train: 0.8598993288590604; Loss 0.11649801582098007, AUC: 0.8615263888888889 Acc Evaluation: 0.35\n",
      "EPOCH: 2600; Loss: 0.013212570920586586, AUC: 0.999266676384932, Acc Train: 0.8590604026845637; Loss 0.12060920149087906, AUC: 0.8654819444444444 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 2650; Loss: 0.012944820336997509, AUC: 0.9990828313793579, Acc Train: 0.8624161073825504; Loss 0.1182238981127739, AUC: 0.859295138888889 Acc Evaluation: 0.33666666666666667\n",
      "EPOCH: 2700; Loss: 0.014346607029438019, AUC: 0.9989948457417459, Acc Train: 0.8691275167785235; Loss 0.12428314238786697, AUC: 0.8664236111111111 Acc Evaluation: 0.35\n",
      "EPOCH: 2750; Loss: 0.012590702623128891, AUC: 0.9991652636177706, Acc Train: 0.8682885906040269; Loss 0.12318878620862961, AUC: 0.8665958333333332 Acc Evaluation: 0.34\n",
      "EPOCH: 2800; Loss: 0.013004519045352936, AUC: 0.9990686344717017, Acc Train: 0.8716442953020134; Loss 0.12413273006677628, AUC: 0.8648486111111111 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 2850; Loss: 0.014445684850215912, AUC: 0.9988131231243806, Acc Train: 0.8762583892617449; Loss 0.12570054829120636, AUC: 0.8631611111111112 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 2900; Loss: 0.010685029439628124, AUC: 0.9993588518148113, Acc Train: 0.8800335570469798; Loss 0.11860596388578415, AUC: 0.8695187499999999 Acc Evaluation: 0.3333333333333333\n",
      "EPOCH: 2950; Loss: 0.013246140442788601, AUC: 0.9989727641069096, Acc Train: 0.8838087248322147; Loss 0.12438497692346573, AUC: 0.8657368055555557 Acc Evaluation: 0.35\n",
      "EPOCH: 3000; Loss: 0.011995035223662853, AUC: 0.9991937454077238, Acc Train: 0.8859060402684564; Loss 0.12558311223983765, AUC: 0.866186111111111 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 3050; Loss: 0.011790628544986248, AUC: 0.9992608040776598, Acc Train: 0.886744966442953; Loss 0.12556307017803192, AUC: 0.8671270833333333 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 3100; Loss: 0.012505077756941319, AUC: 0.9991644718460035, Acc Train: 0.8863255033557047; Loss 0.12721887230873108, AUC: 0.8671243055555555 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 3150; Loss: 0.01303116511553526, AUC: 0.9990975011507084, Acc Train: 0.8888422818791947; Loss 0.12849754095077515, AUC: 0.8611986111111111 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 3200; Loss: 0.011256594210863113, AUC: 0.9991832434349804, Acc Train: 0.8913590604026845; Loss 0.12765862047672272, AUC: 0.8678034722222222 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 3250; Loss: 0.01069971825927496, AUC: 0.9993138857765416, Acc Train: 0.8947147651006712; Loss 0.1270633041858673, AUC: 0.8672624999999999 Acc Evaluation: 0.35\n",
      "EPOCH: 3300; Loss: 0.011066162027418613, AUC: 0.9993954272717164, Acc Train: 0.8980704697986577; Loss 0.12442265450954437, AUC: 0.8685993055555555 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 3350; Loss: 0.01106500718742609, AUC: 0.9992999088054875, Acc Train: 0.8980704697986577; Loss 0.13388149440288544, AUC: 0.8624520833333333 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 3400; Loss: 0.012031342834234238, AUC: 0.9991507368052115, Acc Train: 0.8993288590604027; Loss 0.13727611303329468, AUC: 0.8639583333333334 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 3450; Loss: 0.010332777164876461, AUC: 0.9993395963653102, Acc Train: 0.9005872483221476; Loss 0.13068319857120514, AUC: 0.8623569444444443 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 3500; Loss: 0.012639563530683517, AUC: 0.9989062992657989, Acc Train: 0.902265100671141; Loss 0.13195545971393585, AUC: 0.86421875 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 3550; Loss: 0.010644047521054745, AUC: 0.9993403331529267, Acc Train: 0.9043624161073825; Loss 0.13498297333717346, AUC: 0.8693111111111111 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 3600; Loss: 0.011939738877117634, AUC: 0.9991041102455971, Acc Train: 0.9060402684563759; Loss 0.1349932700395584, AUC: 0.8646930555555555 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 3650; Loss: 0.011525051668286324, AUC: 0.9991509017576629, Acc Train: 0.9098154362416108; Loss 0.13677982985973358, AUC: 0.8638062499999999 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 3700; Loss: 0.009667198173701763, AUC: 0.9994285827144611, Acc Train: 0.9110738255033557; Loss 0.13588401675224304, AUC: 0.8656395833333332 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 3750; Loss: 0.008795191533863544, AUC: 0.9995448741927448, Acc Train: 0.9106543624161074; Loss 0.13511057198047638, AUC: 0.8656722222222222 Acc Evaluation: 0.35\n",
      "EPOCH: 3800; Loss: 0.010294265113770962, AUC: 0.9992197089235845, Acc Train: 0.9123322147651006; Loss 0.13678458333015442, AUC: 0.8637374999999999 Acc Evaluation: 0.3433333333333333\n",
      "EPOCH: 3850; Loss: 0.013539067469537258, AUC: 0.9989024173847744, Acc Train: 0.9114932885906041; Loss 0.14555981755256653, AUC: 0.86541875 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 3900; Loss: 0.011437642388045788, AUC: 0.9992303208646288, Acc Train: 0.9156879194630873; Loss 0.14243954420089722, AUC: 0.8641673611111111 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 3950; Loss: 0.012075169011950493, AUC: 0.9989358917355918, Acc Train: 0.9161073825503355; Loss 0.14202116429805756, AUC: 0.8616402777777777 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 4000; Loss: 0.009562228806316853, AUC: 0.9992325862116289, Acc Train: 0.9177852348993288; Loss 0.13766896724700928, AUC: 0.8683826388888889 Acc Evaluation: 0.34\n",
      "EPOCH: 4050; Loss: 0.010276701301336288, AUC: 0.9991978032380298, Acc Train: 0.9177852348993288; Loss 0.139798104763031, AUC: 0.8700715277777779 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 4100; Loss: 0.008626438677310944, AUC: 0.9994702387068712, Acc Train: 0.9177852348993288; Loss 0.1386558711528778, AUC: 0.8686548611111111 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 4150; Loss: 0.009959499351680279, AUC: 0.999260485169587, Acc Train: 0.9207214765100671; Loss 0.13710318505764008, AUC: 0.8692902777777778 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 4200; Loss: 0.009788794443011284, AUC: 0.9993669014944428, Acc Train: 0.9228187919463087; Loss 0.13602055609226227, AUC: 0.8627159722222222 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 4250; Loss: 0.011474736966192722, AUC: 0.9990515563945599, Acc Train: 0.9228187919463087; Loss 0.14342890679836273, AUC: 0.8620458333333332 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 4300; Loss: 0.011109400540590286, AUC: 0.9991101035180002, Acc Train: 0.9203020134228188; Loss 0.14499472081661224, AUC: 0.8685409722222223 Acc Evaluation: 0.37\n",
      "EPOCH: 4350; Loss: 0.009938874281942844, AUC: 0.9992520725945622, Acc Train: 0.9249161073825504; Loss 0.13993625342845917, AUC: 0.8656743055555555 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 4400; Loss: 0.008641508407890797, AUC: 0.9995368355099433, Acc Train: 0.9265939597315436; Loss 0.1396673172712326, AUC: 0.8654395833333334 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 4450; Loss: 0.009629608131945133, AUC: 0.999440393309986, Acc Train: 0.9307885906040269; Loss 0.1438603550195694, AUC: 0.8628520833333333 Acc Evaluation: 0.36\n",
      "EPOCH: 4500; Loss: 0.008795748464763165, AUC: 0.9995221877322531, Acc Train: 0.9291107382550335; Loss 0.1375218778848648, AUC: 0.8704659722222221 Acc Evaluation: 0.35\n",
      "EPOCH: 4550; Loss: 0.009153785184025764, AUC: 0.9994098331191444, Acc Train: 0.9303691275167785; Loss 0.13873904943466187, AUC: 0.8689833333333333 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 4600; Loss: 0.009278565645217896, AUC: 0.9993590057704327, Acc Train: 0.9320469798657718; Loss 0.1425650268793106, AUC: 0.8660847222222223 Acc Evaluation: 0.36\n",
      "EPOCH: 4650; Loss: 0.00839739479124546, AUC: 0.9994028831225226, Acc Train: 0.9307885906040269; Loss 0.1377403289079666, AUC: 0.8649472222222223 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 4700; Loss: 0.011964037083089352, AUC: 0.9988726929530201, Acc Train: 0.9375; Loss 0.15199919044971466, AUC: 0.8623194444444444 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 4750; Loss: 0.009532407857477665, AUC: 0.9992934756598802, Acc Train: 0.9362416107382551; Loss 0.14973551034927368, AUC: 0.8616256944444445 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 4800; Loss: 0.011791746132075787, AUC: 0.9989051665922988, Acc Train: 0.9366610738255033; Loss 0.14917297661304474, AUC: 0.8704749999999999 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 4850; Loss: 0.009530428797006607, AUC: 0.9992874823874769, Acc Train: 0.9337248322147651; Loss 0.14695891737937927, AUC: 0.8672194444444443 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 4900; Loss: 0.009296024218201637, AUC: 0.9994501035109624, Acc Train: 0.9379194630872483; Loss 0.14416693150997162, AUC: 0.8667499999999999 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 4950; Loss: 0.010794118046760559, AUC: 0.9991441057166626, Acc Train: 0.9404362416107382; Loss 0.15039271116256714, AUC: 0.8678777777777777 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 5000; Loss: 0.011461547575891018, AUC: 0.9990112090249312, Acc Train: 0.9404362416107382; Loss 0.1542680859565735, AUC: 0.8643965277777779 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 5050; Loss: 0.007625145837664604, AUC: 0.9995397716635793, Acc Train: 0.9433724832214765; Loss 0.1465637981891632, AUC: 0.8686729166666666 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 5100; Loss: 0.008189725689589977, AUC: 0.9995016786441208, Acc Train: 0.9437919463087249; Loss 0.1478450894355774, AUC: 0.8641951388888889 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 5150; Loss: 0.010193007066845894, AUC: 0.999165516544863, Acc Train: 0.9471476510067114; Loss 0.15051977336406708, AUC: 0.8642402777777778 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 5200; Loss: 0.010141799226403236, AUC: 0.9993395743716499, Acc Train: 0.947986577181208; Loss 0.15005065500736237, AUC: 0.8690541666666666 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 5250; Loss: 0.010962879285216331, AUC: 0.9989723132368755, Acc Train: 0.9471476510067114; Loss 0.15060697495937347, AUC: 0.8672368055555555 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 5300; Loss: 0.009195597842335701, AUC: 0.9994389527252432, Acc Train: 0.947986577181208; Loss 0.1489846259355545, AUC: 0.8649145833333333 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 5350; Loss: 0.007451697252690792, AUC: 0.9995239142345784, Acc Train: 0.9488255033557047; Loss 0.15027333796024323, AUC: 0.8665340277777777 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 5400; Loss: 0.009556539356708527, AUC: 0.9993277197888046, Acc Train: 0.951761744966443; Loss 0.155279740691185, AUC: 0.8685645833333333 Acc Evaluation: 0.35\n",
      "EPOCH: 5450; Loss: 0.008895459584891796, AUC: 0.9992659725878057, Acc Train: 0.9513422818791947; Loss 0.14569096267223358, AUC: 0.8723208333333333 Acc Evaluation: 0.3466666666666667\n",
      "EPOCH: 5500; Loss: 0.007391365710645914, AUC: 0.9995998363495733, Acc Train: 0.950503355704698; Loss 0.15116745233535767, AUC: 0.8711923611111111 Acc Evaluation: 0.35\n",
      "EPOCH: 5550; Loss: 0.008092904463410378, AUC: 0.9994185975927323, Acc Train: 0.9534395973154363; Loss 0.1567716896533966, AUC: 0.8712770833333333 Acc Evaluation: 0.36\n",
      "EPOCH: 5600; Loss: 0.008216642774641514, AUC: 0.9993331962101932, Acc Train: 0.9546979865771812; Loss 0.1500823050737381, AUC: 0.8689243055555556 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 5650; Loss: 0.01018619630485773, AUC: 0.9991733572847226, Acc Train: 0.9546979865771812; Loss 0.15661559998989105, AUC: 0.8734381944444445 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 5700; Loss: 0.010670549236238003, AUC: 0.999045266207744, Acc Train: 0.9538590604026845; Loss 0.14920412003993988, AUC: 0.8678368055555555 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 5750; Loss: 0.007224694360047579, AUC: 0.9994254596147134, Acc Train: 0.9559563758389261; Loss 0.1438116878271103, AUC: 0.8673229166666666 Acc Evaluation: 0.35333333333333333\n",
      "EPOCH: 5800; Loss: 0.008845552802085876, AUC: 0.9993495265028884, Acc Train: 0.9551174496644296; Loss 0.15623033046722412, AUC: 0.868172222222222 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 5850; Loss: 0.008361217565834522, AUC: 0.9993965269547261, Acc Train: 0.9563758389261745; Loss 0.15492434799671173, AUC: 0.8737895833333332 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 5900; Loss: 0.010162471793591976, AUC: 0.9990967643630918, Acc Train: 0.9563758389261745; Loss 0.15259921550750732, AUC: 0.8717159722222222 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 5950; Loss: 0.007647085934877396, AUC: 0.9994125823266689, Acc Train: 0.9555369127516778; Loss 0.15231695771217346, AUC: 0.8706395833333335 Acc Evaluation: 0.37333333333333335\n",
      "EPOCH: 6000; Loss: 0.009488101117312908, AUC: 0.9992490154757949, Acc Train: 0.9588926174496645; Loss 0.15877017378807068, AUC: 0.8703958333333334 Acc Evaluation: 0.37333333333333335\n",
      "EPOCH: 6050; Loss: 0.007418603170663118, AUC: 0.9995764240982952, Acc Train: 0.9630872483221476; Loss 0.1537681519985199, AUC: 0.8734652777777778 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 6100; Loss: 0.00804185215383768, AUC: 0.9994264163389318, Acc Train: 0.9588926174496645; Loss 0.15677501261234283, AUC: 0.8674868055555555 Acc Evaluation: 0.36\n",
      "EPOCH: 6150; Loss: 0.00977952778339386, AUC: 0.9992059848796225, Acc Train: 0.9609899328859061; Loss 0.15426461398601532, AUC: 0.8714930555555557 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 6200; Loss: 0.008649707771837711, AUC: 0.9993257183657267, Acc Train: 0.9605704697986577; Loss 0.15614190697669983, AUC: 0.8711520833333335 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 6250; Loss: 0.010176212526857853, AUC: 0.999220445711201, Acc Train: 0.9630872483221476; Loss 0.16249875724315643, AUC: 0.8660472222222222 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 6300; Loss: 0.00838794931769371, AUC: 0.9993207258048624, Acc Train: 0.9630872483221476; Loss 0.15590719878673553, AUC: 0.8682680555555555 Acc Evaluation: 0.36\n",
      "EPOCH: 6350; Loss: 0.008103398606181145, AUC: 0.9993564984931704, Acc Train: 0.9635067114093959; Loss 0.15753485262393951, AUC: 0.8679222222222222 Acc Evaluation: 0.36\n",
      "EPOCH: 6400; Loss: 0.008843127638101578, AUC: 0.9993456226282037, Acc Train: 0.9660234899328859; Loss 0.157274529337883, AUC: 0.8679868055555555 Acc Evaluation: 0.37\n",
      "EPOCH: 6450; Loss: 0.011401426047086716, AUC: 0.9989332854868588, Acc Train: 0.9681208053691275; Loss 0.16483460366725922, AUC: 0.8673861111111111 Acc Evaluation: 0.37666666666666665\n",
      "EPOCH: 6500; Loss: 0.00875769555568695, AUC: 0.999358928792622, Acc Train: 0.9672818791946308; Loss 0.1583479791879654, AUC: 0.8680270833333333 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 6550; Loss: 0.008240954950451851, AUC: 0.9992588796323927, Acc Train: 0.9677013422818792; Loss 0.15727269649505615, AUC: 0.8699444444444446 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 6600; Loss: 0.006280091125518084, AUC: 0.9996144291431129, Acc Train: 0.9697986577181208; Loss 0.14976635575294495, AUC: 0.8704923611111111 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 6650; Loss: 0.007320497650653124, AUC: 0.9995022174887955, Acc Train: 0.9697986577181208; Loss 0.15699920058250427, AUC: 0.8686694444444445 Acc Evaluation: 0.37666666666666665\n",
      "EPOCH: 6700; Loss: 0.007433735299855471, AUC: 0.9995148418497477, Acc Train: 0.9689597315436241; Loss 0.15651607513427734, AUC: 0.8713326388888889 Acc Evaluation: 0.38\n",
      "EPOCH: 6750; Loss: 0.00909888744354248, AUC: 0.9992780691009133, Acc Train: 0.9697986577181208; Loss 0.16091494262218475, AUC: 0.8700451388888889 Acc Evaluation: 0.3566666666666667\n",
      "EPOCH: 6800; Loss: 0.007606413681060076, AUC: 0.9995215499161073, Acc Train: 0.9718959731543624; Loss 0.15712881088256836, AUC: 0.8684944444444445 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 6850; Loss: 0.007074314635246992, AUC: 0.9994120544788242, Acc Train: 0.9693791946308725; Loss 0.15529049932956696, AUC: 0.8650513888888889 Acc Evaluation: 0.36333333333333334\n",
      "EPOCH: 6900; Loss: 0.008300668559968472, AUC: 0.9993854421499876, Acc Train: 0.9693791946308725; Loss 0.15961958467960358, AUC: 0.8678625 Acc Evaluation: 0.36666666666666664\n",
      "EPOCH: 6950; Loss: 0.008189478889107704, AUC: 0.9993297432055426, Acc Train: 0.9706375838926175; Loss 0.16155733168125153, AUC: 0.8667673611111111 Acc Evaluation: 0.37333333333333335\n",
      "EPOCH: 7000; Loss: 0.008248578757047653, AUC: 0.9992791797807531, Acc Train: 0.9714765100671141; Loss 0.16310784220695496, AUC: 0.8707333333333332 Acc Evaluation: 0.36\n",
      "EPOCH: 7050; Loss: 0.009492002427577972, AUC: 0.9991993427942435, Acc Train: 0.9718959731543624; Loss 0.1630074679851532, AUC: 0.8704499999999998 Acc Evaluation: 0.36333333333333334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[100], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m negative_graph \u001B[38;5;241m=\u001B[39m construct_negative_graph(train_hetero_graph, k, (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaper\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthored\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthor\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m      7\u001B[0m pos_score, neg_score \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mscores(train_hetero_graph\u001B[38;5;241m.\u001B[39mto(device), negative_graph\u001B[38;5;241m.\u001B[39mto(device), node_features, (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaper\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthored\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthor\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m----> 8\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_loss_logits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpos_score\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneg_score\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     10\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "Cell \u001B[1;32mIn[81], line 16\u001B[0m, in \u001B[0;36mcompute_loss_logits\u001B[1;34m(pos_score, neg_score)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_loss_logits\u001B[39m(pos_score, neg_score):\n\u001B[0;32m     14\u001B[0m     scores \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([pos_score, neg_score])\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 16\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpos_score\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneg_score\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mbinary_cross_entropy_with_logits(scores\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m), labels)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    " torch.no_grad():\n",
    "  torch.save(model, f\"./drive/MyDrive/Bachelor_thesis/models/author.pt\")"
   ],
   "metadata": {
    "id": "uyYKZsBgLOr3"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
