{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import EdgeWeightNorm, GraphConv,RelGraphConv, SAGEConv\n",
    "from dgl.data import DGLDataset\n",
    "import mysql.connector\n",
    "import dgl.data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dgl import save_graphs, load_graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from Datasets import PaperDataset\n",
    "from Models import GraphClassificationModelCrossEntropy, GraphClassificationModelBinaryCrossEntropy\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import itertools\n",
    "import torch as th\n",
    "import dgl.function as fn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import dgl.nn as dglnn\n",
    "import random\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user='david', password='daviddung1993',\n",
    "                          host='127.0.0.1',\n",
    "                          database='computervision')\n",
    "cursor = cnx.cursor()\n",
    "headers = {\"x-api-key\": \"M7HSjQNeTfai6l7JUiDZB8XYc85BHnHt3R0NXSEd\"}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "test_papers = []\n",
    "with open(r'./test_papers.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        x = line[:-1]\n",
    "        test_papers.append(x)\n",
    "\n",
    "train_papers = []\n",
    "with open(r'./train_papers.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        x = line[:-1]\n",
    "        train_papers.append(x)\n",
    "\n",
    "total_papers = train_papers + test_papers\n",
    "in_params_train = ','.join(['%s'] * len(train_papers+test_papers))\n",
    "\n",
    "val_papers = []\n",
    "with open(r'./val_papers.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        x = line[:-1]\n",
    "        val_papers.append(x)\n",
    "in_params_val = ','.join(['%s'] * len(val_papers))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remap(x, mapping):\n",
    "    return mapping.get(x, x)\n",
    "\n",
    "cursor.execute(\"select * from referencedBy b where b.ReferenceID in (select PaperID from Papers) and b.ReferencedByID in (select PaperID from Papers)\")\n",
    "paper_edges = np.array(cursor.fetchall())\n",
    "all_papers = np.unique(paper_edges)\n",
    "remapped_papers = {all_papers[i]: i  for i in range(len(all_papers))}\n",
    "vec_remap = np.vectorize(remap, otypes=[str])\n",
    "paper_edges = vec_remap(paper_edges, remapped_papers)\n",
    "\n",
    "cursor.execute(\"select * from authoredBy where PaperID in (select PaperID from Papers) and (PaperID in (select ReferenceID from referencedBy) or PaperID in (select ReferencedByID from referencedBy))\")\n",
    "author_edges = np.array(cursor.fetchall())\n",
    "all_authors = np.unique(author_edges[:,1])\n",
    "remapped_authors = {all_authors[i]: i  for i in range(len(all_authors))}\n",
    "\n",
    "author_edges[:,1] = vec_remap(author_edges[:,1], remapped_authors)\n",
    "author_edges[:,0] = vec_remap(author_edges[:,0], remapped_papers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "6424"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"select distinct b.AuthoredByID from Papers p, authoredBy b where p.PaperID in (%s) and p.PaperID = b.PaperID\" % in_params_train, total_papers)\n",
    "train_author_ids = [x[0] for x in cursor.fetchall()]\n",
    "len(train_author_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "node_types = [\"paper\", \"author\"]\n",
    "edge_types = [\"cited\", \"authored\"]\n",
    "\n",
    "hetero_graph = dgl.heterograph(\n",
    "    {\n",
    "        ('paper', 'authored', 'author'): (author_edges[:,0].astype(int), author_edges[:,1].astype(int)),\n",
    "        ('paper', 'cites', 'paper'): (paper_edges[:,0].astype(int), paper_edges[:,1].astype(int))\n",
    "    }\n",
    ")\n",
    "hetero_graph.nodes['paper'].data['feature'] = th.rand(hetero_graph.number_of_nodes('paper'), 1)\n",
    "hetero_graph.nodes['author'].data['feature'] = th.rand(hetero_graph.number_of_nodes('author'), 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def cartesian_product(A, B):\n",
    "    for a in A:\n",
    "        for b in B:\n",
    "            yield (a, b)\n",
    "\n",
    "def construct_negative_graph(graph, k, etype):\n",
    "    utype, _, vtype = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    neg_src = src.repeat_interleave(k)\n",
    "    neg_dst = torch.randint(0, graph.num_nodes(vtype), (len(src) * k,))\n",
    "    return dgl.heterograph(\n",
    "        {etype: (neg_src, neg_dst)},\n",
    "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})\n",
    "\n",
    "def construct_negative_edge(graph, paper, etype):\n",
    "    utype, _, vtype = etype\n",
    "    dst = graph.predecessors(paper, etype=etype)\n",
    "    neg_src = paper.repeat_interleave(graph.num_nodes(vtype) - len(dst))\n",
    "\n",
    "    neg_mask = ~torch.isin(graph.nodes(vtype), dst)\n",
    "    neg_dst = torch.masked_select(graph.nodes(vtype), neg_mask)\n",
    "    return dgl.heterograph(\n",
    "        {etype: (neg_src, neg_dst)},\n",
    "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})\n",
    "\n",
    "def construct_negative_graph_v2(graph, k, etype):\n",
    "    utype, edge_type, vtype = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    eids = graph.edge_ids(src, dst, etype=edge_type)\n",
    "\n",
    "    neg_sampler = dgl.dataloading.negative_sampler.PerSourceUniform(k)\n",
    "    neg_src, neg_dst = neg_sampler(graph, {edge_type: eids})[etype]\n",
    "    return dgl.heterograph(\n",
    "        {etype: (neg_src, neg_dst)},\n",
    "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})\n",
    "\n",
    "def construct_complete_negative_graph(graph, etype):\n",
    "    utype, edge_type, vtype = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    all_src_nodes = torch.unique(src)\n",
    "    all_author_nodes = graph.nodes(vtype)\n",
    "    neg_graph = dgl.heterograph({etype: ([], [])}, {ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})\n",
    "    src_dst_pairs = list(zip(src.tolist(), dst.tolist()))\n",
    "    dataset = TensorDataset(all_author_nodes)\n",
    "    dataloader = DataLoader(dataset, batch_size=2500, shuffle=False)\n",
    "\n",
    "    for batch_idx, author_batch in enumerate(dataloader):\n",
    "        print(f\"{batch_idx}/{len(dataloader)}\")\n",
    "        complete_edges_batch = torch.cartesian_prod(all_src_nodes, author_batch[0])\n",
    "        complete_edges_tuples = [(complete_edges_batch[i][0].item(), complete_edges_batch[i][1].item()) for i in range(complete_edges_batch.shape[0])]\n",
    "        filtered_mask = ~torch.tensor([True if tuple in src_dst_pairs else False for tuple in complete_edges_tuples])\n",
    "\n",
    "        filtered_edges = complete_edges_batch[filtered_mask]\n",
    "        neg_src = filtered_edges[:,0]\n",
    "        neg_dst = filtered_edges[:,1]\n",
    "        neg_graph.add_edges(neg_src, neg_dst, etype='authored')\n",
    "\n",
    "    return neg_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='max')\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='max')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h\n",
    "\n",
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    def forward(self, graph, h, etype):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
    "            return graph.edges[etype].data['score']\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, rel_names):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.sage = RGCN(in_features, hidden_features, out_features, rel_names)\n",
    "        # Decoder\n",
    "        self.pred = HeteroDotProductPredictor()\n",
    "    def forward(self, g, neg_g, x, etype):\n",
    "        h = self.sage(g, x)\n",
    "        return self.pred(g, h, etype), self.pred(neg_g, h, etype)\n",
    "\n",
    "\n",
    "# Metrics\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    # Margin loss\n",
    "    n_edges = pos_score.shape[0]\n",
    "    #print(neg_score.view(n_edges, -1).shape)\n",
    "    return (1 - pos_score + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
    "\n",
    "def compute_loss_asymmetric(pos_score, neg_score, pos_mapping, neg_mapping):\n",
    "    # Margin loss\n",
    "    #n_edges = pos_score.shape[0]\n",
    "    total_list = []\n",
    "\n",
    "    for node in torch.unique(pos_mapping):\n",
    "        pos_node_indices = (pos_mapping == node).nonzero(as_tuple=True)[0]\n",
    "        neg_node_indices = (neg_mapping == node).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        pos_edges_score = torch.index_select(pos_score, 0, pos_node_indices).mean()\n",
    "        neg_edges = torch.index_select(neg_score, 0, neg_node_indices)\n",
    "\n",
    "        node_score = (1-pos_edges_score+neg_edges).clamp(min=0).mean()\n",
    "        total_list.append(node_score)\n",
    "\n",
    "    total_loss = torch.tensor(total_list).mean()\n",
    "    return total_loss\n",
    "    #return (1 - pos_score + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
    "\n",
    "def compute_loss_asymmetric_edges(pos_score, neg_score, pos_mapping, neg_mapping):\n",
    "    total_list = []\n",
    "\n",
    "    for idx, node in enumerate(pos_mapping):\n",
    "        #pos_node_indices = (pos_mapping == node).nonzero(as_tuple=True)[0]\n",
    "        neg_node_indices = (neg_mapping == node).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        neg_edges = torch.index_select(neg_score, 0, neg_node_indices)\n",
    "        current_pos_score = pos_score[idx]\n",
    "\n",
    "        node_score = (1-current_pos_score+neg_edges).clamp(min=0).mean()\n",
    "        total_list.append(node_score)\n",
    "\n",
    "    total_loss = torch.tensor(total_list).mean()\n",
    "    return total_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "remapped_test_papers = th.tensor([remapped_papers[idx] for idx in test_papers])\n",
    "remapped_val_papers = th.tensor([remapped_papers[idx] for idx in val_papers])\n",
    "remapped_train_test_author_ids = th.tensor([remapped_authors[idx] for idx in train_author_ids])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Remove all Test Papers\n",
    "train_hetero_graph = dgl.remove_nodes(hetero_graph, remapped_test_papers, ntype=\"paper\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "val_test_hetero_graph = dgl.heterograph({\n",
    "    etype: hetero_graph.edges(etype=etype)\n",
    "    for etype in hetero_graph.canonical_etypes\n",
    "}, num_nodes_dict={\n",
    "    ntype: hetero_graph.number_of_nodes(ntype=ntype)\n",
    "    for ntype in hetero_graph.ntypes\n",
    "})\n",
    "\n",
    "val_test_hetero_graph.nodes['author'].data['feature'] = hetero_graph.nodes['author'].data['feature']\n",
    "val_test_hetero_graph.nodes['paper'].data['feature'] = hetero_graph.nodes['paper'].data['feature']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "author_mask = ~torch.isin(val_test_hetero_graph.nodes(\"author\"),remapped_train_test_author_ids)\n",
    "not_author_in_question = torch.masked_select(val_test_hetero_graph.nodes(\"author\"), author_mask)\n",
    "val_positive_hetero_graph = dgl.remove_nodes(val_test_hetero_graph, not_author_in_question, ntype=\"author\")\n",
    "\n",
    "u, v = val_positive_hetero_graph[\"authored\"].edges()\n",
    "mask = ~torch.isin(u, remapped_val_papers)\n",
    "not_pos_val_u, not_pos_val_v = torch.masked_select(u, mask), torch.masked_select(v, mask)\n",
    "not_in_val_pos_ids = val_positive_hetero_graph.edge_ids(not_pos_val_u, not_pos_val_v, etype=\"authored\")\n",
    "val_positive_hetero_graph.remove_edges(not_in_val_pos_ids, etype=\"authored\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3\n",
      "1/3\n",
      "2/3\n"
     ]
    }
   ],
   "source": [
    "#a = val_positive_hetero_graph.edges(etype=\"authored\")\n",
    "val_negative_hetero_graph = construct_complete_negative_graph(val_positive_hetero_graph, ('paper', 'authored', 'author'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Model(1, 40, 40, train_hetero_graph.etypes)\n",
    "author_feats = train_hetero_graph.nodes['author'].data['feature']\n",
    "paper_feats = train_hetero_graph.nodes['paper'].data['feature']\n",
    "node_features = {'author': author_feats, 'paper': paper_feats}\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "k = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
